{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# default parameters\n",
    "batch_size = 64  # input batch size\n",
    "image_size = 64  # height / width of input image to network\n",
    "nz = 100 # size of latent z vector\n",
    "ngf = 32\n",
    "ndf = 32\n",
    "niter = 25 # number of epochs\n",
    "lr = 0.0002 # learning rate\n",
    "beta1 = 0.5 # beta1 for adam\n",
    "outf = 'output_images'\n",
    "workers = 2\n",
    "ngpu = 1\n",
    "nc = 3 # number of channels\n",
    "netG_weights = '' # pre-defined model for generator\n",
    "netD_weights = '' # pre-defined model for discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(outf):\n",
    "    os.makedirs(outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "CPU times: user 796 ms, sys: 300 ms, total: 1.1 s\n",
      "Wall time: 1.19 s\n",
      "CPU times: user 456 ms, sys: 232 ms, total: 688 ms\n",
      "Wall time: 741 ms\n"
     ]
    }
   ],
   "source": [
    "path_to_data = '/efs/data/CIFAR'\n",
    "%time dataset = dset.CIFAR10(root=path_to_data, download=True, \\\n",
    "                            transform=transforms.Compose([ \\\n",
    "                            transforms.Scale(image_size), \\\n",
    "                            transforms.ToTensor(), \\\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \\\n",
    "                        ]))\n",
    "%time raw_dataset = dset.CIFAR10(root=path_to_data, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 64 ms, total: 12.1 s\n",
      "Wall time: 12.1 s\n",
      "CPU times: user 1.24 s, sys: 44 ms, total: 1.28 s\n",
      "Wall time: 1.28 s\n",
      "CPU times: user 260 ms, sys: 12 ms, total: 272 ms\n",
      "Wall time: 259 ms\n"
     ]
    }
   ],
   "source": [
    "%time cat_idx = [i for i, img in enumerate(dataset) if img[1] == 3]\n",
    "%time cat_dataset = [dataset[i] for i in cat_idx]\n",
    "%time cat_raw_dataset = [raw_dataset[i] for i in cat_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(cat_dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cust weights initialization called on generator and discriminator networks\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generator network\n",
    "class _netG(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netG, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution                                                                                                                                                                               \n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4                                                                                                                                                                                        \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8                                                                                                                                                                                        \n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16                                                                                                                                                                                      \n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32                                                                                                                                                                                        \n",
    "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 32 x 32                                                                                                                                                                                                                    \n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# discriminator network\n",
    "class _netD(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netD, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64                                                                                                                                                                                            \n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32                                                                                                                                                                                        \n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16                                                                                                                                                                                      \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8                                                                                                                                                                                        \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4                                                                                                                                                                                        \n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG (\n",
      "  (main): Sequential (\n",
      "    (0): ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): ReLU (inplace)\n",
      "    (9): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (11): ReLU (inplace)\n",
      "    (12): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = _netG(ngpu)\n",
    "netG.apply(weights_init)\n",
    "if netG_weights != '':\n",
    "    netG.load_state_dict(torch.load(netG_weights))\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netD (\n",
      "  (main): Sequential (\n",
      "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU (0.2, inplace)\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): LeakyReLU (0.2, inplace)\n",
      "    (5): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): LeakyReLU (0.2, inplace)\n",
      "    (8): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (10): LeakyReLU (0.2, inplace)\n",
      "    (11): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netD = _netD(ngpu)\n",
    "netD.apply(weights_init)\n",
    "if netD_weights != '':\n",
    "    netD.load_state_dict(torch.load(netD_weights))\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tensors\n",
    "input = torch.FloatTensor(batch_size, 3, image_size, image_size)\n",
    "noise = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "fixed_noise = Variable(torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1))\n",
    "label = torch.FloatTensor(batch_size)\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda enabled\n"
     ]
    }
   ],
   "source": [
    "# switch to cuda if on GPU\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda enabled')\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    criterion.cuda()\n",
    "    input, label = input.cuda(), label.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup optimizer                                                                                                                                                                                                                                 \n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test sample\n",
    "test_dataloader = torch.utils.data.DataLoader(cat_dataset, batch_size=1,\n",
    "                                              shuffle=False, num_workers=1)\n",
    "test_data_iter = iter(test_dataloader)\n",
    "img_id = 9\n",
    "for _ in range(img_id+1):\n",
    "    test_sample = next(test_data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Unnormalize(img):\n",
    "    return ((img*0.5+0.5)*255).astype(np.uint8) # using 0.5 for mean and std (as from Normalize call above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f625e0c5898>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiIA4L4QI+IiIg4IPj/AROjYCQtQeiPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f625fd1f128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot original raw image against normalized image\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.asarray(cat_raw_dataset[img_id][0]))\n",
    "plt.subplot(122)\n",
    "plt.imshow(Unnormalize(test_sample[0].numpy()[0].transpose(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# single pass though networks\n",
    "netD.zero_grad()\n",
    "real_cpu, _ = test_sample\n",
    "batch_size = real_cpu.size(0)\n",
    "if torch.cuda.is_available():\n",
    "    real_cpu = real_cpu.cuda()\n",
    "input.resize_as_(real_cpu).copy_(real_cpu)\n",
    "label.resize_(batch_size).fill_(real_label)\n",
    "inputv = Variable(input)\n",
    "labelv = Variable(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = netD(inputv)\n",
    "errD_real = criterion(output, labelv)\n",
    "errD_real.backward()\n",
    "D_x = output.data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 100, 1, 1])\n",
      "torch.Size([64, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(fixed_noise.size())\n",
    "fake = netG(fixed_noise)\n",
    "print(fake.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][0/79] Loss_D: 1.5453 Loss_G: 2.4096 D(x): 0.5283 D(G(z)): 0.5429 / 0.1045\n",
      "[0/25][1/79] Loss_D: 1.2950 Loss_G: 2.3445 D(x): 0.5258 D(G(z)): 0.4032 / 0.1154\n",
      "[0/25][2/79] Loss_D: 1.1288 Loss_G: 2.3723 D(x): 0.6039 D(G(z)): 0.4110 / 0.1103\n",
      "[0/25][3/79] Loss_D: 0.9703 Loss_G: 2.5692 D(x): 0.6471 D(G(z)): 0.3698 / 0.0883\n",
      "[0/25][4/79] Loss_D: 0.7985 Loss_G: 2.9328 D(x): 0.7545 D(G(z)): 0.3624 / 0.0672\n",
      "[0/25][5/79] Loss_D: 0.7876 Loss_G: 3.1075 D(x): 0.7368 D(G(z)): 0.3348 / 0.0562\n",
      "[0/25][6/79] Loss_D: 0.7124 Loss_G: 3.1788 D(x): 0.7372 D(G(z)): 0.2845 / 0.0491\n",
      "[0/25][7/79] Loss_D: 0.7920 Loss_G: 3.3055 D(x): 0.7849 D(G(z)): 0.3819 / 0.0446\n",
      "[0/25][8/79] Loss_D: 0.7892 Loss_G: 3.4928 D(x): 0.7258 D(G(z)): 0.3173 / 0.0363\n",
      "[0/25][9/79] Loss_D: 0.6415 Loss_G: 3.7976 D(x): 0.7845 D(G(z)): 0.3001 / 0.0274\n",
      "[0/25][10/79] Loss_D: 0.6704 Loss_G: 3.7814 D(x): 0.7284 D(G(z)): 0.2585 / 0.0284\n",
      "[0/25][11/79] Loss_D: 0.8130 Loss_G: 3.7310 D(x): 0.6963 D(G(z)): 0.2826 / 0.0286\n",
      "[0/25][12/79] Loss_D: 0.6319 Loss_G: 4.3116 D(x): 0.8277 D(G(z)): 0.3238 / 0.0174\n",
      "[0/25][13/79] Loss_D: 0.5011 Loss_G: 4.6525 D(x): 0.8458 D(G(z)): 0.2510 / 0.0132\n",
      "[0/25][14/79] Loss_D: 0.4069 Loss_G: 4.6356 D(x): 0.8220 D(G(z)): 0.1636 / 0.0124\n",
      "[0/25][15/79] Loss_D: 0.4655 Loss_G: 4.6405 D(x): 0.8429 D(G(z)): 0.2200 / 0.0124\n",
      "[0/25][16/79] Loss_D: 0.4223 Loss_G: 4.8135 D(x): 0.8448 D(G(z)): 0.2029 / 0.0103\n",
      "[0/25][17/79] Loss_D: 0.4637 Loss_G: 4.9049 D(x): 0.8198 D(G(z)): 0.1964 / 0.0099\n",
      "[0/25][18/79] Loss_D: 0.4612 Loss_G: 4.7740 D(x): 0.7801 D(G(z)): 0.1568 / 0.0106\n",
      "[0/25][19/79] Loss_D: 0.4172 Loss_G: 4.8945 D(x): 0.8435 D(G(z)): 0.1720 / 0.0095\n",
      "[0/25][20/79] Loss_D: 0.3173 Loss_G: 5.3712 D(x): 0.9078 D(G(z)): 0.1727 / 0.0063\n",
      "[0/25][21/79] Loss_D: 0.3227 Loss_G: 5.2343 D(x): 0.8651 D(G(z)): 0.1372 / 0.0071\n",
      "[0/25][22/79] Loss_D: 0.2311 Loss_G: 5.6924 D(x): 0.9550 D(G(z)): 0.1573 / 0.0049\n",
      "[0/25][23/79] Loss_D: 0.2696 Loss_G: 5.6428 D(x): 0.9073 D(G(z)): 0.1454 / 0.0049\n",
      "[0/25][24/79] Loss_D: 0.3861 Loss_G: 5.6991 D(x): 0.8570 D(G(z)): 0.1728 / 0.0048\n",
      "[0/25][25/79] Loss_D: 0.3842 Loss_G: 6.1475 D(x): 0.8830 D(G(z)): 0.2006 / 0.0032\n",
      "[0/25][26/79] Loss_D: 0.2552 Loss_G: 6.2606 D(x): 0.9175 D(G(z)): 0.1472 / 0.0024\n",
      "[0/25][27/79] Loss_D: 0.3407 Loss_G: 6.0734 D(x): 0.8554 D(G(z)): 0.1436 / 0.0030\n",
      "[0/25][28/79] Loss_D: 0.4398 Loss_G: 6.8084 D(x): 0.8454 D(G(z)): 0.2083 / 0.0015\n",
      "[0/25][29/79] Loss_D: 0.2565 Loss_G: 6.4897 D(x): 0.8693 D(G(z)): 0.0954 / 0.0019\n",
      "[0/25][30/79] Loss_D: 0.2723 Loss_G: 6.3849 D(x): 0.8848 D(G(z)): 0.1255 / 0.0022\n",
      "[0/25][31/79] Loss_D: 0.2258 Loss_G: 6.9311 D(x): 0.9312 D(G(z)): 0.1312 / 0.0013\n",
      "[0/25][32/79] Loss_D: 0.2330 Loss_G: 6.2867 D(x): 0.8719 D(G(z)): 0.0769 / 0.0024\n",
      "[0/25][33/79] Loss_D: 0.2957 Loss_G: 6.6494 D(x): 0.8871 D(G(z)): 0.1355 / 0.0016\n",
      "[0/25][34/79] Loss_D: 0.2141 Loss_G: 6.8386 D(x): 0.9103 D(G(z)): 0.1024 / 0.0014\n",
      "[0/25][35/79] Loss_D: 0.2324 Loss_G: 6.8635 D(x): 0.9044 D(G(z)): 0.1082 / 0.0013\n",
      "[0/25][36/79] Loss_D: 0.1561 Loss_G: 7.1223 D(x): 0.9503 D(G(z)): 0.0948 / 0.0011\n",
      "[0/25][37/79] Loss_D: 0.1684 Loss_G: 6.9202 D(x): 0.9468 D(G(z)): 0.0758 / 0.0012\n",
      "[0/25][38/79] Loss_D: 0.2233 Loss_G: 7.8956 D(x): 0.9365 D(G(z)): 0.1368 / 0.0004\n",
      "[0/25][39/79] Loss_D: 0.1203 Loss_G: 7.0574 D(x): 0.9247 D(G(z)): 0.0384 / 0.0011\n",
      "[0/25][40/79] Loss_D: 0.1300 Loss_G: 6.4959 D(x): 0.9455 D(G(z)): 0.0681 / 0.0019\n",
      "[0/25][41/79] Loss_D: 0.1644 Loss_G: 7.0448 D(x): 0.9373 D(G(z)): 0.0912 / 0.0011\n",
      "[0/25][42/79] Loss_D: 0.1237 Loss_G: 6.7687 D(x): 0.9343 D(G(z)): 0.0495 / 0.0014\n",
      "[0/25][43/79] Loss_D: 0.2574 Loss_G: 6.3187 D(x): 0.8651 D(G(z)): 0.0765 / 0.0021\n",
      "[0/25][44/79] Loss_D: 0.2025 Loss_G: 8.7269 D(x): 0.9682 D(G(z)): 0.1518 / 0.0002\n",
      "[0/25][45/79] Loss_D: 0.0592 Loss_G: 8.2418 D(x): 0.9516 D(G(z)): 0.0082 / 0.0004\n",
      "[0/25][46/79] Loss_D: 0.0888 Loss_G: 5.9073 D(x): 0.9386 D(G(z)): 0.0217 / 0.0033\n",
      "[0/25][47/79] Loss_D: 0.3601 Loss_G: 9.9781 D(x): 0.9547 D(G(z)): 0.2572 / 0.0001\n",
      "[0/25][48/79] Loss_D: 0.0895 Loss_G: 9.9389 D(x): 0.9256 D(G(z)): 0.0027 / 0.0001\n",
      "[0/25][49/79] Loss_D: 0.0831 Loss_G: 7.3284 D(x): 0.9287 D(G(z)): 0.0039 / 0.0009\n",
      "[0/25][50/79] Loss_D: 0.1139 Loss_G: 6.1397 D(x): 0.9700 D(G(z)): 0.0772 / 0.0028\n",
      "[0/25][51/79] Loss_D: 0.3305 Loss_G: 10.8808 D(x): 0.9751 D(G(z)): 0.2514 / 0.0000\n",
      "[0/25][52/79] Loss_D: 0.0497 Loss_G: 11.3121 D(x): 0.9541 D(G(z)): 0.0011 / 0.0000\n",
      "[0/25][53/79] Loss_D: 0.0543 Loss_G: 9.2565 D(x): 0.9504 D(G(z)): 0.0007 / 0.0001\n",
      "[0/25][54/79] Loss_D: 0.0580 Loss_G: 5.6698 D(x): 0.9570 D(G(z)): 0.0126 / 0.0041\n",
      "[0/25][55/79] Loss_D: 0.3744 Loss_G: 11.1587 D(x): 0.9805 D(G(z)): 0.2896 / 0.0000\n",
      "[0/25][56/79] Loss_D: 0.0892 Loss_G: 11.7250 D(x): 0.9255 D(G(z)): 0.0007 / 0.0000\n",
      "[0/25][57/79] Loss_D: 0.0606 Loss_G: 10.0394 D(x): 0.9449 D(G(z)): 0.0003 / 0.0001\n",
      "[0/25][58/79] Loss_D: 0.0658 Loss_G: 6.7589 D(x): 0.9439 D(G(z)): 0.0030 / 0.0014\n",
      "[0/25][59/79] Loss_D: 0.1397 Loss_G: 6.6876 D(x): 0.9683 D(G(z)): 0.0947 / 0.0014\n",
      "[0/25][60/79] Loss_D: 0.1230 Loss_G: 7.9972 D(x): 0.9628 D(G(z)): 0.0783 / 0.0004\n",
      "[0/25][61/79] Loss_D: 0.0553 Loss_G: 7.3890 D(x): 0.9646 D(G(z)): 0.0179 / 0.0007\n",
      "[0/25][62/79] Loss_D: 0.0541 Loss_G: 6.6490 D(x): 0.9848 D(G(z)): 0.0377 / 0.0015\n",
      "[0/25][63/79] Loss_D: 0.1260 Loss_G: 8.7847 D(x): 0.9847 D(G(z)): 0.1023 / 0.0002\n",
      "[0/25][64/79] Loss_D: 0.0487 Loss_G: 8.0833 D(x): 0.9657 D(G(z)): 0.0090 / 0.0004\n",
      "[0/25][65/79] Loss_D: 0.0593 Loss_G: 6.4773 D(x): 0.9641 D(G(z)): 0.0202 / 0.0018\n",
      "[0/25][66/79] Loss_D: 0.1955 Loss_G: 9.8370 D(x): 0.9574 D(G(z)): 0.1332 / 0.0001\n",
      "[0/25][67/79] Loss_D: 0.0522 Loss_G: 9.5096 D(x): 0.9543 D(G(z)): 0.0032 / 0.0001\n",
      "[0/25][68/79] Loss_D: 0.0346 Loss_G: 7.3705 D(x): 0.9713 D(G(z)): 0.0049 / 0.0008\n",
      "[0/25][69/79] Loss_D: 0.0860 Loss_G: 7.8665 D(x): 0.9892 D(G(z)): 0.0712 / 0.0005\n",
      "[0/25][70/79] Loss_D: 0.0776 Loss_G: 7.8234 D(x): 0.9621 D(G(z)): 0.0328 / 0.0005\n",
      "[0/25][71/79] Loss_D: 0.0643 Loss_G: 7.6360 D(x): 0.9741 D(G(z)): 0.0362 / 0.0006\n",
      "[0/25][72/79] Loss_D: 0.1018 Loss_G: 8.0566 D(x): 0.9592 D(G(z)): 0.0517 / 0.0004\n",
      "[0/25][73/79] Loss_D: 0.0637 Loss_G: 8.0506 D(x): 0.9771 D(G(z)): 0.0384 / 0.0004\n",
      "[0/25][74/79] Loss_D: 0.0612 Loss_G: 7.7605 D(x): 0.9743 D(G(z)): 0.0335 / 0.0005\n",
      "[0/25][75/79] Loss_D: 0.0610 Loss_G: 7.4961 D(x): 0.9768 D(G(z)): 0.0347 / 0.0007\n",
      "[0/25][76/79] Loss_D: 0.1142 Loss_G: 7.9756 D(x): 0.9478 D(G(z)): 0.0548 / 0.0004\n",
      "[0/25][77/79] Loss_D: 0.0739 Loss_G: 7.5983 D(x): 0.9640 D(G(z)): 0.0339 / 0.0006\n",
      "[0/25][78/79] Loss_D: 0.1270 Loss_G: 7.2042 D(x): 0.9163 D(G(z)): 0.0350 / 0.0009\n",
      "[1/25][0/79] Loss_D: 0.0731 Loss_G: 7.5909 D(x): 0.9755 D(G(z)): 0.0459 / 0.0006\n",
      "[1/25][1/79] Loss_D: 0.0491 Loss_G: 7.9029 D(x): 0.9921 D(G(z)): 0.0400 / 0.0005\n",
      "[1/25][2/79] Loss_D: 0.0673 Loss_G: 7.0789 D(x): 0.9595 D(G(z)): 0.0214 / 0.0010\n",
      "[1/25][3/79] Loss_D: 0.0833 Loss_G: 7.8144 D(x): 0.9758 D(G(z)): 0.0554 / 0.0005\n",
      "[1/25][4/79] Loss_D: 0.0365 Loss_G: 7.5082 D(x): 0.9843 D(G(z)): 0.0196 / 0.0006\n",
      "[1/25][5/79] Loss_D: 0.0730 Loss_G: 6.9309 D(x): 0.9640 D(G(z)): 0.0280 / 0.0011\n",
      "[1/25][6/79] Loss_D: 0.0831 Loss_G: 8.4882 D(x): 0.9781 D(G(z)): 0.0580 / 0.0002\n",
      "[1/25][7/79] Loss_D: 0.0330 Loss_G: 8.0164 D(x): 0.9797 D(G(z)): 0.0098 / 0.0004\n",
      "[1/25][8/79] Loss_D: 0.0365 Loss_G: 6.8767 D(x): 0.9824 D(G(z)): 0.0167 / 0.0012\n",
      "[1/25][9/79] Loss_D: 0.0735 Loss_G: 8.0464 D(x): 0.9794 D(G(z)): 0.0506 / 0.0004\n",
      "[1/25][10/79] Loss_D: 0.0501 Loss_G: 7.6616 D(x): 0.9667 D(G(z)): 0.0135 / 0.0005\n",
      "[1/25][11/79] Loss_D: 0.0433 Loss_G: 7.1245 D(x): 0.9797 D(G(z)): 0.0215 / 0.0009\n",
      "[1/25][12/79] Loss_D: 0.0590 Loss_G: 8.2014 D(x): 0.9829 D(G(z)): 0.0399 / 0.0003\n",
      "[1/25][13/79] Loss_D: 0.0386 Loss_G: 7.6088 D(x): 0.9736 D(G(z)): 0.0094 / 0.0006\n",
      "[1/25][14/79] Loss_D: 0.0259 Loss_G: 6.9264 D(x): 0.9895 D(G(z)): 0.0151 / 0.0011\n",
      "[1/25][15/79] Loss_D: 0.0494 Loss_G: 7.4742 D(x): 0.9821 D(G(z)): 0.0302 / 0.0006\n",
      "[1/25][16/79] Loss_D: 0.0289 Loss_G: 7.3753 D(x): 0.9847 D(G(z)): 0.0127 / 0.0007\n",
      "[1/25][17/79] Loss_D: 0.0228 Loss_G: 7.2089 D(x): 0.9958 D(G(z)): 0.0184 / 0.0008\n",
      "[1/25][18/79] Loss_D: 0.0556 Loss_G: 6.9943 D(x): 0.9674 D(G(z)): 0.0204 / 0.0010\n",
      "[1/25][19/79] Loss_D: 0.0356 Loss_G: 7.5017 D(x): 0.9911 D(G(z)): 0.0260 / 0.0006\n",
      "[1/25][20/79] Loss_D: 0.0321 Loss_G: 7.3565 D(x): 0.9853 D(G(z)): 0.0165 / 0.0007\n",
      "[1/25][21/79] Loss_D: 0.0284 Loss_G: 7.0768 D(x): 0.9898 D(G(z)): 0.0178 / 0.0009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][22/79] Loss_D: 0.0475 Loss_G: 6.9686 D(x): 0.9769 D(G(z)): 0.0218 / 0.0010\n",
      "[1/25][23/79] Loss_D: 0.0379 Loss_G: 7.3382 D(x): 0.9861 D(G(z)): 0.0234 / 0.0007\n",
      "[1/25][24/79] Loss_D: 0.0272 Loss_G: 7.2811 D(x): 0.9877 D(G(z)): 0.0145 / 0.0007\n",
      "[1/25][25/79] Loss_D: 0.0360 Loss_G: 7.1494 D(x): 0.9833 D(G(z)): 0.0188 / 0.0008\n",
      "[1/25][26/79] Loss_D: 0.0357 Loss_G: 7.6308 D(x): 0.9892 D(G(z)): 0.0243 / 0.0005\n",
      "[1/25][27/79] Loss_D: 0.0289 Loss_G: 7.6458 D(x): 0.9886 D(G(z)): 0.0172 / 0.0005\n",
      "[1/25][28/79] Loss_D: 0.0334 Loss_G: 7.5509 D(x): 0.9862 D(G(z)): 0.0192 / 0.0006\n",
      "[1/25][29/79] Loss_D: 0.0435 Loss_G: 8.1426 D(x): 0.9856 D(G(z)): 0.0283 / 0.0003\n",
      "[1/25][30/79] Loss_D: 0.0637 Loss_G: 7.5298 D(x): 0.9562 D(G(z)): 0.0143 / 0.0006\n",
      "[1/25][31/79] Loss_D: 0.0410 Loss_G: 8.0805 D(x): 0.9881 D(G(z)): 0.0283 / 0.0004\n",
      "[1/25][32/79] Loss_D: 0.0239 Loss_G: 7.8601 D(x): 0.9932 D(G(z)): 0.0168 / 0.0004\n",
      "[1/25][33/79] Loss_D: 0.0275 Loss_G: 7.3644 D(x): 0.9878 D(G(z)): 0.0148 / 0.0007\n",
      "[1/25][34/79] Loss_D: 0.0363 Loss_G: 7.3693 D(x): 0.9858 D(G(z)): 0.0213 / 0.0007\n",
      "[1/25][35/79] Loss_D: 0.0346 Loss_G: 7.4474 D(x): 0.9854 D(G(z)): 0.0192 / 0.0007\n",
      "[1/25][36/79] Loss_D: 0.0309 Loss_G: 7.6191 D(x): 0.9916 D(G(z)): 0.0221 / 0.0006\n",
      "[1/25][37/79] Loss_D: 0.0272 Loss_G: 7.6312 D(x): 0.9917 D(G(z)): 0.0185 / 0.0006\n",
      "[1/25][38/79] Loss_D: 0.0295 Loss_G: 7.1049 D(x): 0.9837 D(G(z)): 0.0126 / 0.0009\n",
      "[1/25][39/79] Loss_D: 0.0358 Loss_G: 7.0005 D(x): 0.9851 D(G(z)): 0.0199 / 0.0010\n",
      "[1/25][40/79] Loss_D: 0.0380 Loss_G: 7.3425 D(x): 0.9855 D(G(z)): 0.0227 / 0.0007\n",
      "[1/25][41/79] Loss_D: 0.0298 Loss_G: 7.1948 D(x): 0.9866 D(G(z)): 0.0160 / 0.0009\n",
      "[1/25][42/79] Loss_D: 0.0363 Loss_G: 6.8423 D(x): 0.9818 D(G(z)): 0.0154 / 0.0012\n",
      "[1/25][43/79] Loss_D: 0.0406 Loss_G: 7.6618 D(x): 0.9919 D(G(z)): 0.0316 / 0.0005\n",
      "[1/25][44/79] Loss_D: 0.0389 Loss_G: 7.2556 D(x): 0.9758 D(G(z)): 0.0130 / 0.0008\n",
      "[1/25][45/79] Loss_D: 0.0314 Loss_G: 6.8546 D(x): 0.9853 D(G(z)): 0.0158 / 0.0012\n",
      "[1/25][46/79] Loss_D: 0.0428 Loss_G: 7.1037 D(x): 0.9825 D(G(z)): 0.0240 / 0.0009\n",
      "[1/25][47/79] Loss_D: 0.0358 Loss_G: 7.2490 D(x): 0.9853 D(G(z)): 0.0204 / 0.0008\n",
      "[1/25][48/79] Loss_D: 0.0180 Loss_G: 7.1724 D(x): 0.9907 D(G(z)): 0.0085 / 0.0008\n",
      "[1/25][49/79] Loss_D: 0.0463 Loss_G: 6.5432 D(x): 0.9725 D(G(z)): 0.0168 / 0.0016\n",
      "[1/25][50/79] Loss_D: 0.0629 Loss_G: 9.1810 D(x): 0.9873 D(G(z)): 0.0485 / 0.0001\n",
      "[1/25][51/79] Loss_D: 0.0174 Loss_G: 9.1881 D(x): 0.9851 D(G(z)): 0.0018 / 0.0001\n",
      "[1/25][52/79] Loss_D: 0.0185 Loss_G: 7.5135 D(x): 0.9851 D(G(z)): 0.0024 / 0.0007\n",
      "[1/25][53/79] Loss_D: 0.0353 Loss_G: 5.9951 D(x): 0.9790 D(G(z)): 0.0130 / 0.0031\n",
      "[1/25][54/79] Loss_D: 0.0955 Loss_G: 9.0506 D(x): 0.9716 D(G(z)): 0.0606 / 0.0001\n",
      "[1/25][55/79] Loss_D: 0.0445 Loss_G: 8.4623 D(x): 0.9617 D(G(z)): 0.0019 / 0.0003\n",
      "[1/25][56/79] Loss_D: 0.0148 Loss_G: 6.9475 D(x): 0.9888 D(G(z)): 0.0033 / 0.0012\n",
      "[1/25][57/79] Loss_D: 0.0354 Loss_G: 6.3384 D(x): 0.9816 D(G(z)): 0.0161 / 0.0024\n",
      "[1/25][58/79] Loss_D: 0.0534 Loss_G: 9.1072 D(x): 0.9957 D(G(z)): 0.0473 / 0.0002\n",
      "[1/25][59/79] Loss_D: 0.0427 Loss_G: 7.7082 D(x): 0.9652 D(G(z)): 0.0057 / 0.0008\n",
      "[1/25][60/79] Loss_D: 0.0537 Loss_G: 6.1177 D(x): 0.9571 D(G(z)): 0.0075 / 0.0032\n",
      "[1/25][61/79] Loss_D: 0.0666 Loss_G: 9.5199 D(x): 0.9973 D(G(z)): 0.0609 / 0.0001\n",
      "[1/25][62/79] Loss_D: 0.0389 Loss_G: 8.3510 D(x): 0.9658 D(G(z)): 0.0022 / 0.0003\n",
      "[1/25][63/79] Loss_D: 0.0109 Loss_G: 6.8102 D(x): 0.9949 D(G(z)): 0.0058 / 0.0017\n",
      "[1/25][64/79] Loss_D: 0.0903 Loss_G: 8.9753 D(x): 0.9824 D(G(z)): 0.0675 / 0.0002\n",
      "[1/25][65/79] Loss_D: 0.0389 Loss_G: 8.2876 D(x): 0.9659 D(G(z)): 0.0022 / 0.0004\n",
      "[1/25][66/79] Loss_D: 0.0569 Loss_G: 5.0387 D(x): 0.9547 D(G(z)): 0.0081 / 0.0091\n",
      "[1/25][67/79] Loss_D: 0.1740 Loss_G: 12.5476 D(x): 0.9886 D(G(z)): 0.1463 / 0.0000\n",
      "[1/25][68/79] Loss_D: 0.6886 Loss_G: 6.2965 D(x): 0.6326 D(G(z)): 0.0000 / 0.0135\n",
      "[1/25][69/79] Loss_D: 1.8994 Loss_G: 2.8809 D(x): 0.3858 D(G(z)): 0.1365 / 0.2492\n",
      "[1/25][70/79] Loss_D: 1.6312 Loss_G: 12.5705 D(x): 0.9944 D(G(z)): 0.4878 / 0.0002\n",
      "[1/25][71/79] Loss_D: 0.8562 Loss_G: 11.2032 D(x): 0.6634 D(G(z)): 0.0010 / 0.0010\n",
      "[1/25][72/79] Loss_D: 0.3445 Loss_G: 10.5508 D(x): 0.8446 D(G(z)): 0.0050 / 0.0031\n",
      "[1/25][73/79] Loss_D: 0.1766 Loss_G: 8.5065 D(x): 0.9215 D(G(z)): 0.0087 / 0.0052\n",
      "[1/25][74/79] Loss_D: 0.0377 Loss_G: 7.2840 D(x): 0.9882 D(G(z)): 0.0231 / 0.0069\n",
      "[1/25][75/79] Loss_D: 0.0677 Loss_G: 5.8335 D(x): 0.9966 D(G(z)): 0.0593 / 0.0047\n",
      "[1/25][76/79] Loss_D: 0.0775 Loss_G: 5.6092 D(x): 0.9912 D(G(z)): 0.0648 / 0.0047\n",
      "[1/25][77/79] Loss_D: 0.1375 Loss_G: 6.5176 D(x): 0.9786 D(G(z)): 0.1039 / 0.0018\n",
      "[1/25][78/79] Loss_D: 0.0520 Loss_G: 6.6776 D(x): 0.9774 D(G(z)): 0.0277 / 0.0022\n",
      "[2/25][0/79] Loss_D: 0.0893 Loss_G: 5.5878 D(x): 0.9451 D(G(z)): 0.0251 / 0.0056\n",
      "[2/25][1/79] Loss_D: 0.1406 Loss_G: 6.4086 D(x): 0.9568 D(G(z)): 0.0854 / 0.0025\n",
      "[2/25][2/79] Loss_D: 0.1308 Loss_G: 6.0090 D(x): 0.9255 D(G(z)): 0.0413 / 0.0036\n",
      "[2/25][3/79] Loss_D: 0.0870 Loss_G: 6.0141 D(x): 0.9604 D(G(z)): 0.0410 / 0.0029\n",
      "[2/25][4/79] Loss_D: 0.0855 Loss_G: 6.5912 D(x): 0.9705 D(G(z)): 0.0478 / 0.0018\n",
      "[2/25][5/79] Loss_D: 0.0847 Loss_G: 6.2513 D(x): 0.9512 D(G(z)): 0.0293 / 0.0031\n",
      "[2/25][6/79] Loss_D: 0.0990 Loss_G: 6.1411 D(x): 0.9566 D(G(z)): 0.0469 / 0.0031\n",
      "[2/25][7/79] Loss_D: 0.0948 Loss_G: 6.9335 D(x): 0.9655 D(G(z)): 0.0524 / 0.0015\n",
      "[2/25][8/79] Loss_D: 0.1312 Loss_G: 6.5702 D(x): 0.9421 D(G(z)): 0.0486 / 0.0022\n",
      "[2/25][9/79] Loss_D: 0.1045 Loss_G: 6.6750 D(x): 0.9582 D(G(z)): 0.0519 / 0.0018\n",
      "[2/25][10/79] Loss_D: 0.0945 Loss_G: 6.8832 D(x): 0.9655 D(G(z)): 0.0550 / 0.0013\n",
      "[2/25][11/79] Loss_D: 0.0907 Loss_G: 6.2378 D(x): 0.9479 D(G(z)): 0.0313 / 0.0031\n",
      "[2/25][12/79] Loss_D: 0.1194 Loss_G: 6.9413 D(x): 0.9667 D(G(z)): 0.0761 / 0.0011\n",
      "[2/25][13/79] Loss_D: 0.1849 Loss_G: 5.0377 D(x): 0.8763 D(G(z)): 0.0147 / 0.0074\n",
      "[2/25][14/79] Loss_D: 0.1816 Loss_G: 8.8543 D(x): 0.9821 D(G(z)): 0.1477 / 0.0002\n",
      "[2/25][15/79] Loss_D: 0.0683 Loss_G: 8.9047 D(x): 0.9414 D(G(z)): 0.0014 / 0.0002\n",
      "[2/25][16/79] Loss_D: 0.1415 Loss_G: 6.1479 D(x): 0.8872 D(G(z)): 0.0016 / 0.0025\n",
      "[2/25][17/79] Loss_D: 0.0329 Loss_G: 4.2831 D(x): 0.9943 D(G(z)): 0.0266 / 0.0153\n",
      "[2/25][18/79] Loss_D: 0.1764 Loss_G: 8.3636 D(x): 0.9953 D(G(z)): 0.1562 / 0.0003\n",
      "[2/25][19/79] Loss_D: 0.0325 Loss_G: 9.1412 D(x): 0.9730 D(G(z)): 0.0017 / 0.0002\n",
      "[2/25][20/79] Loss_D: 0.0593 Loss_G: 7.9131 D(x): 0.9498 D(G(z)): 0.0013 / 0.0007\n",
      "[2/25][21/79] Loss_D: 0.0501 Loss_G: 6.1454 D(x): 0.9569 D(G(z)): 0.0030 / 0.0037\n",
      "[2/25][22/79] Loss_D: 0.0378 Loss_G: 4.8434 D(x): 0.9886 D(G(z)): 0.0252 / 0.0131\n",
      "[2/25][23/79] Loss_D: 0.0880 Loss_G: 5.6882 D(x): 0.9919 D(G(z)): 0.0741 / 0.0051\n",
      "[2/25][24/79] Loss_D: 0.0506 Loss_G: 5.9361 D(x): 0.9776 D(G(z)): 0.0262 / 0.0036\n",
      "[2/25][25/79] Loss_D: 0.0701 Loss_G: 5.3566 D(x): 0.9562 D(G(z)): 0.0205 / 0.0066\n",
      "[2/25][26/79] Loss_D: 0.0630 Loss_G: 5.2375 D(x): 0.9818 D(G(z)): 0.0426 / 0.0067\n",
      "[2/25][27/79] Loss_D: 0.0651 Loss_G: 5.5710 D(x): 0.9815 D(G(z)): 0.0441 / 0.0045\n",
      "[2/25][28/79] Loss_D: 0.1084 Loss_G: 5.1191 D(x): 0.9378 D(G(z)): 0.0323 / 0.0079\n",
      "[2/25][29/79] Loss_D: 0.0703 Loss_G: 5.6376 D(x): 0.9827 D(G(z)): 0.0504 / 0.0041\n",
      "[2/25][30/79] Loss_D: 0.0472 Loss_G: 5.8701 D(x): 0.9828 D(G(z)): 0.0288 / 0.0034\n",
      "[2/25][31/79] Loss_D: 0.0817 Loss_G: 5.4939 D(x): 0.9579 D(G(z)): 0.0356 / 0.0048\n",
      "[2/25][32/79] Loss_D: 0.0781 Loss_G: 5.7867 D(x): 0.9730 D(G(z)): 0.0482 / 0.0035\n",
      "[2/25][33/79] Loss_D: 0.0515 Loss_G: 5.9583 D(x): 0.9861 D(G(z)): 0.0363 / 0.0029\n",
      "[2/25][34/79] Loss_D: 0.1007 Loss_G: 5.8639 D(x): 0.9555 D(G(z)): 0.0512 / 0.0035\n",
      "[2/25][35/79] Loss_D: 0.1390 Loss_G: 5.9930 D(x): 0.9368 D(G(z)): 0.0612 / 0.0030\n",
      "[2/25][36/79] Loss_D: 0.0753 Loss_G: 6.6835 D(x): 0.9758 D(G(z)): 0.0477 / 0.0016\n",
      "[2/25][37/79] Loss_D: 0.0384 Loss_G: 6.6457 D(x): 0.9831 D(G(z)): 0.0206 / 0.0017\n",
      "[2/25][38/79] Loss_D: 0.0905 Loss_G: 5.5792 D(x): 0.9473 D(G(z)): 0.0322 / 0.0047\n",
      "[2/25][39/79] Loss_D: 0.0965 Loss_G: 8.6260 D(x): 0.9867 D(G(z)): 0.0774 / 0.0003\n",
      "[2/25][40/79] Loss_D: 0.1098 Loss_G: 6.3850 D(x): 0.9128 D(G(z)): 0.0025 / 0.0023\n",
      "[2/25][41/79] Loss_D: 0.0725 Loss_G: 5.0943 D(x): 0.9694 D(G(z)): 0.0388 / 0.0076\n",
      "[2/25][42/79] Loss_D: 0.2077 Loss_G: 12.3876 D(x): 0.9849 D(G(z)): 0.1673 / 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][43/79] Loss_D: 0.4486 Loss_G: 7.6073 D(x): 0.7436 D(G(z)): 0.0000 / 0.0237\n",
      "[2/25][44/79] Loss_D: 0.3371 Loss_G: 8.2839 D(x): 0.9912 D(G(z)): 0.1201 / 0.0023\n",
      "[2/25][45/79] Loss_D: 0.0570 Loss_G: 8.8893 D(x): 0.9961 D(G(z)): 0.0490 / 0.0016\n",
      "[2/25][46/79] Loss_D: 0.1783 Loss_G: 6.8300 D(x): 0.9098 D(G(z)): 0.0164 / 0.0034\n",
      "[2/25][47/79] Loss_D: 0.0913 Loss_G: 6.7255 D(x): 0.9831 D(G(z)): 0.0640 / 0.0019\n",
      "[2/25][48/79] Loss_D: 0.0838 Loss_G: 7.3244 D(x): 0.9757 D(G(z)): 0.0555 / 0.0010\n",
      "[2/25][49/79] Loss_D: 0.0708 Loss_G: 6.3750 D(x): 0.9622 D(G(z)): 0.0259 / 0.0023\n",
      "[2/25][50/79] Loss_D: 0.1089 Loss_G: 6.9889 D(x): 0.9713 D(G(z)): 0.0676 / 0.0022\n",
      "[2/25][51/79] Loss_D: 0.1443 Loss_G: 4.5774 D(x): 0.9119 D(G(z)): 0.0169 / 0.0224\n",
      "[2/25][52/79] Loss_D: 0.2407 Loss_G: 10.5181 D(x): 0.9893 D(G(z)): 0.1952 / 0.0001\n",
      "[2/25][53/79] Loss_D: 0.3330 Loss_G: 8.6090 D(x): 0.8083 D(G(z)): 0.0005 / 0.0004\n",
      "[2/25][54/79] Loss_D: 0.0248 Loss_G: 6.3659 D(x): 0.9795 D(G(z)): 0.0023 / 0.0031\n",
      "[2/25][55/79] Loss_D: 0.0351 Loss_G: 5.0564 D(x): 0.9948 D(G(z)): 0.0286 / 0.0125\n",
      "[2/25][56/79] Loss_D: 0.2444 Loss_G: 10.6991 D(x): 0.9979 D(G(z)): 0.1948 / 0.0001\n",
      "[2/25][57/79] Loss_D: 0.1883 Loss_G: 8.9816 D(x): 0.8480 D(G(z)): 0.0005 / 0.0002\n",
      "[2/25][58/79] Loss_D: 0.0670 Loss_G: 5.6565 D(x): 0.9418 D(G(z)): 0.0022 / 0.0056\n",
      "[2/25][59/79] Loss_D: 0.1126 Loss_G: 6.9011 D(x): 0.9923 D(G(z)): 0.0887 / 0.0021\n",
      "[2/25][60/79] Loss_D: 0.0404 Loss_G: 7.1483 D(x): 0.9918 D(G(z)): 0.0309 / 0.0023\n",
      "[2/25][61/79] Loss_D: 0.0876 Loss_G: 5.5839 D(x): 0.9434 D(G(z)): 0.0239 / 0.0066\n",
      "[2/25][62/79] Loss_D: 0.2211 Loss_G: 10.0870 D(x): 0.9621 D(G(z)): 0.1546 / 0.0001\n",
      "[2/25][63/79] Loss_D: 0.3135 Loss_G: 4.7868 D(x): 0.7719 D(G(z)): 0.0006 / 0.0168\n",
      "[2/25][64/79] Loss_D: 0.2000 Loss_G: 8.9267 D(x): 0.9978 D(G(z)): 0.1526 / 0.0006\n",
      "[2/25][65/79] Loss_D: 0.4539 Loss_G: 1.5547 D(x): 0.7242 D(G(z)): 0.0090 / 0.2791\n",
      "[2/25][66/79] Loss_D: 1.7045 Loss_G: 17.1419 D(x): 0.9960 D(G(z)): 0.7300 / 0.0000\n",
      "[2/25][67/79] Loss_D: 6.6305 Loss_G: 11.6537 D(x): 0.0344 D(G(z)): 0.0000 / 0.0000\n",
      "[2/25][68/79] Loss_D: 1.1034 Loss_G: 7.1596 D(x): 0.5462 D(G(z)): 0.0001 / 0.0021\n",
      "[2/25][69/79] Loss_D: 0.0523 Loss_G: 3.9915 D(x): 0.9649 D(G(z)): 0.0083 / 0.0618\n",
      "[2/25][70/79] Loss_D: 0.4480 Loss_G: 4.4246 D(x): 0.9925 D(G(z)): 0.3020 / 0.0275\n",
      "[2/25][71/79] Loss_D: 0.1903 Loss_G: 5.2806 D(x): 0.9793 D(G(z)): 0.1404 / 0.0080\n",
      "[2/25][72/79] Loss_D: 0.1064 Loss_G: 5.2450 D(x): 0.9422 D(G(z)): 0.0398 / 0.0087\n",
      "[2/25][73/79] Loss_D: 0.1786 Loss_G: 4.1404 D(x): 0.8955 D(G(z)): 0.0485 / 0.0234\n",
      "[2/25][74/79] Loss_D: 0.1962 Loss_G: 4.2950 D(x): 0.9375 D(G(z)): 0.1150 / 0.0175\n",
      "[2/25][75/79] Loss_D: 0.1632 Loss_G: 4.2512 D(x): 0.9261 D(G(z)): 0.0720 / 0.0161\n",
      "[2/25][76/79] Loss_D: 0.1598 Loss_G: 4.3608 D(x): 0.9362 D(G(z)): 0.0836 / 0.0145\n",
      "[2/25][77/79] Loss_D: 0.1389 Loss_G: 4.2585 D(x): 0.9283 D(G(z)): 0.0565 / 0.0171\n",
      "[2/25][78/79] Loss_D: 0.1997 Loss_G: 5.8254 D(x): 0.9798 D(G(z)): 0.1583 / 0.0042\n",
      "[3/25][0/79] Loss_D: 0.1698 Loss_G: 5.0070 D(x): 0.8709 D(G(z)): 0.0134 / 0.0095\n",
      "[3/25][1/79] Loss_D: 0.1510 Loss_G: 4.1040 D(x): 0.9382 D(G(z)): 0.0773 / 0.0212\n",
      "[3/25][2/79] Loss_D: 0.2360 Loss_G: 6.7668 D(x): 0.9744 D(G(z)): 0.1809 / 0.0016\n",
      "[3/25][3/79] Loss_D: 0.3695 Loss_G: 4.1684 D(x): 0.7586 D(G(z)): 0.0093 / 0.0412\n",
      "[3/25][4/79] Loss_D: 0.2552 Loss_G: 5.3068 D(x): 0.9549 D(G(z)): 0.1712 / 0.0083\n",
      "[3/25][5/79] Loss_D: 0.0875 Loss_G: 5.8108 D(x): 0.9721 D(G(z)): 0.0544 / 0.0055\n",
      "[3/25][6/79] Loss_D: 0.1533 Loss_G: 4.7999 D(x): 0.9027 D(G(z)): 0.0357 / 0.0109\n",
      "[3/25][7/79] Loss_D: 0.0734 Loss_G: 4.8423 D(x): 0.9766 D(G(z)): 0.0471 / 0.0120\n",
      "[3/25][8/79] Loss_D: 0.0990 Loss_G: 5.6574 D(x): 0.9820 D(G(z)): 0.0754 / 0.0049\n",
      "[3/25][9/79] Loss_D: 0.0864 Loss_G: 5.3933 D(x): 0.9510 D(G(z)): 0.0306 / 0.0062\n",
      "[3/25][10/79] Loss_D: 0.1482 Loss_G: 4.3430 D(x): 0.9172 D(G(z)): 0.0420 / 0.0183\n",
      "[3/25][11/79] Loss_D: 0.1272 Loss_G: 5.1602 D(x): 0.9637 D(G(z)): 0.0811 / 0.0076\n",
      "[3/25][12/79] Loss_D: 0.1469 Loss_G: 5.5419 D(x): 0.9428 D(G(z)): 0.0775 / 0.0056\n",
      "[3/25][13/79] Loss_D: 0.1560 Loss_G: 4.7271 D(x): 0.9154 D(G(z)): 0.0503 / 0.0125\n",
      "[3/25][14/79] Loss_D: 0.0866 Loss_G: 4.9646 D(x): 0.9577 D(G(z)): 0.0403 / 0.0095\n",
      "[3/25][15/79] Loss_D: 0.1787 Loss_G: 5.8299 D(x): 0.9495 D(G(z)): 0.1019 / 0.0038\n",
      "[3/25][16/79] Loss_D: 0.1656 Loss_G: 4.7240 D(x): 0.9069 D(G(z)): 0.0338 / 0.0118\n",
      "[3/25][17/79] Loss_D: 0.2578 Loss_G: 5.8853 D(x): 0.9121 D(G(z)): 0.1408 / 0.0047\n",
      "[3/25][18/79] Loss_D: 0.1287 Loss_G: 5.5854 D(x): 0.9390 D(G(z)): 0.0560 / 0.0045\n",
      "[3/25][19/79] Loss_D: 0.1548 Loss_G: 5.2037 D(x): 0.9362 D(G(z)): 0.0660 / 0.0067\n",
      "[3/25][20/79] Loss_D: 0.2452 Loss_G: 6.5779 D(x): 0.9329 D(G(z)): 0.1488 / 0.0028\n",
      "[3/25][21/79] Loss_D: 0.1976 Loss_G: 5.2872 D(x): 0.8899 D(G(z)): 0.0544 / 0.0061\n",
      "[3/25][22/79] Loss_D: 0.4121 Loss_G: 7.9609 D(x): 0.9093 D(G(z)): 0.2385 / 0.0009\n",
      "[3/25][23/79] Loss_D: 0.7098 Loss_G: 3.3243 D(x): 0.6616 D(G(z)): 0.0318 / 0.1343\n",
      "[3/25][24/79] Loss_D: 1.8536 Loss_G: 11.0609 D(x): 0.9716 D(G(z)): 0.6906 / 0.0000\n",
      "[3/25][25/79] Loss_D: 2.2962 Loss_G: 6.8763 D(x): 0.1602 D(G(z)): 0.0001 / 0.0193\n",
      "[3/25][26/79] Loss_D: 0.0789 Loss_G: 5.0817 D(x): 0.9896 D(G(z)): 0.0495 / 0.0315\n",
      "[3/25][27/79] Loss_D: 0.2889 Loss_G: 6.2961 D(x): 0.9955 D(G(z)): 0.1712 / 0.0042\n",
      "[3/25][28/79] Loss_D: 0.0717 Loss_G: 5.7426 D(x): 0.9669 D(G(z)): 0.0344 / 0.0091\n",
      "[3/25][29/79] Loss_D: 0.0953 Loss_G: 5.2066 D(x): 0.9609 D(G(z)): 0.0494 / 0.0125\n",
      "[3/25][30/79] Loss_D: 0.2042 Loss_G: 4.4786 D(x): 0.9243 D(G(z)): 0.0980 / 0.0176\n",
      "[3/25][31/79] Loss_D: 0.2242 Loss_G: 5.6563 D(x): 0.9604 D(G(z)): 0.1559 / 0.0060\n",
      "[3/25][32/79] Loss_D: 0.3418 Loss_G: 3.2921 D(x): 0.8115 D(G(z)): 0.0747 / 0.0517\n",
      "[3/25][33/79] Loss_D: 0.7512 Loss_G: 9.8703 D(x): 0.9864 D(G(z)): 0.4815 / 0.0002\n",
      "[3/25][34/79] Loss_D: 2.1043 Loss_G: 5.8370 D(x): 0.2734 D(G(z)): 0.0008 / 0.0070\n",
      "[3/25][35/79] Loss_D: 0.1134 Loss_G: 3.0728 D(x): 0.9769 D(G(z)): 0.0792 / 0.1002\n",
      "[3/25][36/79] Loss_D: 0.5994 Loss_G: 5.7282 D(x): 0.9934 D(G(z)): 0.3658 / 0.0051\n",
      "[3/25][37/79] Loss_D: 0.1739 Loss_G: 5.3516 D(x): 0.8904 D(G(z)): 0.0408 / 0.0076\n",
      "[3/25][38/79] Loss_D: 0.2397 Loss_G: 3.9507 D(x): 0.8473 D(G(z)): 0.0473 / 0.0352\n",
      "[3/25][39/79] Loss_D: 0.1534 Loss_G: 4.0689 D(x): 0.9714 D(G(z)): 0.1093 / 0.0254\n",
      "[3/25][40/79] Loss_D: 0.2894 Loss_G: 4.6567 D(x): 0.9184 D(G(z)): 0.1723 / 0.0130\n",
      "[3/25][41/79] Loss_D: 0.1110 Loss_G: 5.1127 D(x): 0.9738 D(G(z)): 0.0778 / 0.0089\n",
      "[3/25][42/79] Loss_D: 0.1218 Loss_G: 4.6226 D(x): 0.9214 D(G(z)): 0.0357 / 0.0142\n",
      "[3/25][43/79] Loss_D: 0.1688 Loss_G: 4.0136 D(x): 0.9317 D(G(z)): 0.0865 / 0.0240\n",
      "[3/25][44/79] Loss_D: 0.2593 Loss_G: 5.9305 D(x): 0.9494 D(G(z)): 0.1758 / 0.0041\n",
      "[3/25][45/79] Loss_D: 0.3312 Loss_G: 3.7041 D(x): 0.7709 D(G(z)): 0.0254 / 0.0328\n",
      "[3/25][46/79] Loss_D: 0.2281 Loss_G: 5.9315 D(x): 0.9788 D(G(z)): 0.1786 / 0.0033\n",
      "[3/25][47/79] Loss_D: 0.0650 Loss_G: 6.1461 D(x): 0.9550 D(G(z)): 0.0170 / 0.0027\n",
      "[3/25][48/79] Loss_D: 0.0838 Loss_G: 4.8513 D(x): 0.9476 D(G(z)): 0.0267 / 0.0103\n",
      "[3/25][49/79] Loss_D: 0.1479 Loss_G: 5.2958 D(x): 0.9601 D(G(z)): 0.0940 / 0.0075\n",
      "[3/25][50/79] Loss_D: 0.0807 Loss_G: 5.2721 D(x): 0.9618 D(G(z)): 0.0380 / 0.0069\n",
      "[3/25][51/79] Loss_D: 0.3181 Loss_G: 3.0254 D(x): 0.8250 D(G(z)): 0.0632 / 0.0587\n",
      "[3/25][52/79] Loss_D: 0.5195 Loss_G: 10.7742 D(x): 0.9940 D(G(z)): 0.3783 / 0.0000\n",
      "[3/25][53/79] Loss_D: 1.3306 Loss_G: 7.4625 D(x): 0.3818 D(G(z)): 0.0002 / 0.0013\n",
      "[3/25][54/79] Loss_D: 0.0382 Loss_G: 3.7207 D(x): 0.9786 D(G(z)): 0.0135 / 0.0476\n",
      "[3/25][55/79] Loss_D: 0.8733 Loss_G: 9.7483 D(x): 0.9963 D(G(z)): 0.4780 / 0.0002\n",
      "[3/25][56/79] Loss_D: 0.2714 Loss_G: 8.9650 D(x): 0.8070 D(G(z)): 0.0018 / 0.0003\n",
      "[3/25][57/79] Loss_D: 0.1589 Loss_G: 6.2904 D(x): 0.8999 D(G(z)): 0.0042 / 0.0041\n",
      "[3/25][58/79] Loss_D: 0.0708 Loss_G: 4.7351 D(x): 0.9856 D(G(z)): 0.0508 / 0.0176\n",
      "[3/25][59/79] Loss_D: 0.1930 Loss_G: 5.9758 D(x): 0.9912 D(G(z)): 0.1546 / 0.0042\n",
      "[3/25][60/79] Loss_D: 0.1147 Loss_G: 6.1462 D(x): 0.9562 D(G(z)): 0.0605 / 0.0035\n",
      "[3/25][61/79] Loss_D: 0.1244 Loss_G: 5.5247 D(x): 0.9471 D(G(z)): 0.0602 / 0.0061\n",
      "[3/25][62/79] Loss_D: 0.2612 Loss_G: 3.4320 D(x): 0.8420 D(G(z)): 0.0508 / 0.0430\n",
      "[3/25][63/79] Loss_D: 0.5089 Loss_G: 9.5095 D(x): 0.9853 D(G(z)): 0.3516 / 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][64/79] Loss_D: 0.5240 Loss_G: 7.9938 D(x): 0.6559 D(G(z)): 0.0006 / 0.0005\n",
      "[3/25][65/79] Loss_D: 0.0708 Loss_G: 4.7982 D(x): 0.9554 D(G(z)): 0.0080 / 0.0143\n",
      "[3/25][66/79] Loss_D: 0.5322 Loss_G: 10.4484 D(x): 0.9965 D(G(z)): 0.3601 / 0.0001\n",
      "[3/25][67/79] Loss_D: 0.2728 Loss_G: 9.4410 D(x): 0.8064 D(G(z)): 0.0005 / 0.0004\n",
      "[3/25][68/79] Loss_D: 0.1248 Loss_G: 7.1658 D(x): 0.8950 D(G(z)): 0.0016 / 0.0029\n",
      "[3/25][69/79] Loss_D: 0.0411 Loss_G: 4.9659 D(x): 0.9800 D(G(z)): 0.0196 / 0.0151\n",
      "[3/25][70/79] Loss_D: 0.2134 Loss_G: 6.4000 D(x): 0.9695 D(G(z)): 0.1454 / 0.0026\n",
      "[3/25][71/79] Loss_D: 0.1189 Loss_G: 5.5947 D(x): 0.9104 D(G(z)): 0.0166 / 0.0069\n",
      "[3/25][72/79] Loss_D: 0.0926 Loss_G: 4.9202 D(x): 0.9575 D(G(z)): 0.0443 / 0.0149\n",
      "[3/25][73/79] Loss_D: 0.1122 Loss_G: 5.3887 D(x): 0.9805 D(G(z)): 0.0801 / 0.0068\n",
      "[3/25][74/79] Loss_D: 0.0705 Loss_G: 5.4628 D(x): 0.9786 D(G(z)): 0.0464 / 0.0061\n",
      "[3/25][75/79] Loss_D: 0.0905 Loss_G: 4.9287 D(x): 0.9519 D(G(z)): 0.0349 / 0.0096\n",
      "[3/25][76/79] Loss_D: 0.1030 Loss_G: 4.9174 D(x): 0.9626 D(G(z)): 0.0595 / 0.0101\n",
      "[3/25][77/79] Loss_D: 0.0792 Loss_G: 4.9692 D(x): 0.9672 D(G(z)): 0.0420 / 0.0088\n",
      "[3/25][78/79] Loss_D: 0.1302 Loss_G: 4.7816 D(x): 0.9288 D(G(z)): 0.0485 / 0.0104\n",
      "[4/25][0/79] Loss_D: 0.1169 Loss_G: 5.3117 D(x): 0.9705 D(G(z)): 0.0796 / 0.0069\n",
      "[4/25][1/79] Loss_D: 0.0850 Loss_G: 5.3635 D(x): 0.9658 D(G(z)): 0.0467 / 0.0061\n",
      "[4/25][2/79] Loss_D: 0.1061 Loss_G: 5.0401 D(x): 0.9481 D(G(z)): 0.0470 / 0.0089\n",
      "[4/25][3/79] Loss_D: 0.1107 Loss_G: 5.0040 D(x): 0.9504 D(G(z)): 0.0544 / 0.0096\n",
      "[4/25][4/79] Loss_D: 0.2140 Loss_G: 6.0185 D(x): 0.9265 D(G(z)): 0.1174 / 0.0034\n",
      "[4/25][5/79] Loss_D: 0.0890 Loss_G: 6.1896 D(x): 0.9689 D(G(z)): 0.0473 / 0.0029\n",
      "[4/25][6/79] Loss_D: 0.0975 Loss_G: 5.5795 D(x): 0.9461 D(G(z)): 0.0354 / 0.0054\n",
      "[4/25][7/79] Loss_D: 0.1488 Loss_G: 5.6831 D(x): 0.9385 D(G(z)): 0.0722 / 0.0049\n",
      "[4/25][8/79] Loss_D: 0.1044 Loss_G: 6.8543 D(x): 0.9761 D(G(z)): 0.0741 / 0.0015\n",
      "[4/25][9/79] Loss_D: 0.0803 Loss_G: 6.1045 D(x): 0.9495 D(G(z)): 0.0262 / 0.0034\n",
      "[4/25][10/79] Loss_D: 0.0915 Loss_G: 6.1513 D(x): 0.9714 D(G(z)): 0.0578 / 0.0029\n",
      "[4/25][11/79] Loss_D: 0.0396 Loss_G: 6.2602 D(x): 0.9877 D(G(z)): 0.0261 / 0.0029\n",
      "[4/25][12/79] Loss_D: 0.1617 Loss_G: 5.9403 D(x): 0.9308 D(G(z)): 0.0644 / 0.0034\n",
      "[4/25][13/79] Loss_D: 0.0958 Loss_G: 7.4263 D(x): 0.9805 D(G(z)): 0.0702 / 0.0009\n",
      "[4/25][14/79] Loss_D: 0.0555 Loss_G: 6.6915 D(x): 0.9590 D(G(z)): 0.0123 / 0.0018\n",
      "[4/25][15/79] Loss_D: 0.0793 Loss_G: 6.1590 D(x): 0.9739 D(G(z)): 0.0496 / 0.0028\n",
      "[4/25][16/79] Loss_D: 0.1179 Loss_G: 6.7762 D(x): 0.9554 D(G(z)): 0.0643 / 0.0015\n",
      "[4/25][17/79] Loss_D: 0.0894 Loss_G: 6.0424 D(x): 0.9457 D(G(z)): 0.0283 / 0.0031\n",
      "[4/25][18/79] Loss_D: 0.0886 Loss_G: 6.6216 D(x): 0.9779 D(G(z)): 0.0619 / 0.0017\n",
      "[4/25][19/79] Loss_D: 0.0806 Loss_G: 6.3144 D(x): 0.9617 D(G(z)): 0.0361 / 0.0022\n",
      "[4/25][20/79] Loss_D: 0.0891 Loss_G: 5.8006 D(x): 0.9524 D(G(z)): 0.0324 / 0.0040\n",
      "[4/25][21/79] Loss_D: 0.0828 Loss_G: 7.1423 D(x): 0.9965 D(G(z)): 0.0745 / 0.0010\n",
      "[4/25][22/79] Loss_D: 0.0882 Loss_G: 6.1820 D(x): 0.9378 D(G(z)): 0.0202 / 0.0027\n",
      "[4/25][23/79] Loss_D: 0.0524 Loss_G: 6.2735 D(x): 0.9937 D(G(z)): 0.0446 / 0.0024\n",
      "[4/25][24/79] Loss_D: 0.0844 Loss_G: 6.5858 D(x): 0.9667 D(G(z)): 0.0473 / 0.0016\n",
      "[4/25][25/79] Loss_D: 0.0482 Loss_G: 6.4448 D(x): 0.9796 D(G(z)): 0.0266 / 0.0018\n",
      "[4/25][26/79] Loss_D: 0.1385 Loss_G: 5.3864 D(x): 0.9155 D(G(z)): 0.0377 / 0.0053\n",
      "[4/25][27/79] Loss_D: 0.1572 Loss_G: 9.7939 D(x): 0.9866 D(G(z)): 0.1305 / 0.0001\n",
      "[4/25][28/79] Loss_D: 0.0928 Loss_G: 9.6204 D(x): 0.9201 D(G(z)): 0.0008 / 0.0001\n",
      "[4/25][29/79] Loss_D: 0.0557 Loss_G: 7.5750 D(x): 0.9504 D(G(z)): 0.0010 / 0.0006\n",
      "[4/25][30/79] Loss_D: 0.0330 Loss_G: 5.0143 D(x): 0.9813 D(G(z)): 0.0136 / 0.0082\n",
      "[4/25][31/79] Loss_D: 0.3015 Loss_G: 12.2723 D(x): 0.9906 D(G(z)): 0.2355 / 0.0000\n",
      "[4/25][32/79] Loss_D: 0.6819 Loss_G: 8.1220 D(x): 0.5773 D(G(z)): 0.0001 / 0.0018\n",
      "[4/25][33/79] Loss_D: 0.0313 Loss_G: 5.0313 D(x): 0.9923 D(G(z)): 0.0225 / 0.0188\n",
      "[4/25][34/79] Loss_D: 0.4688 Loss_G: 15.4515 D(x): 0.9783 D(G(z)): 0.2908 / 0.0000\n",
      "[4/25][35/79] Loss_D: 1.4429 Loss_G: 10.0082 D(x): 0.4466 D(G(z)): 0.0000 / 0.0001\n",
      "[4/25][36/79] Loss_D: 0.0016 Loss_G: 7.5327 D(x): 0.9993 D(G(z)): 0.0009 / 0.0008\n",
      "[4/25][37/79] Loss_D: 0.0232 Loss_G: 5.2288 D(x): 0.9954 D(G(z)): 0.0182 / 0.0081\n",
      "[4/25][38/79] Loss_D: 0.0543 Loss_G: 5.2242 D(x): 0.9888 D(G(z)): 0.0414 / 0.0073\n",
      "[4/25][39/79] Loss_D: 0.2219 Loss_G: 8.8295 D(x): 0.9731 D(G(z)): 0.1678 / 0.0002\n",
      "[4/25][40/79] Loss_D: 0.9448 Loss_G: 0.8855 D(x): 0.4951 D(G(z)): 0.0020 / 0.4662\n",
      "[4/25][41/79] Loss_D: 2.9815 Loss_G: 17.5081 D(x): 0.9999 D(G(z)): 0.9260 / 0.0000\n",
      "[4/25][42/79] Loss_D: 3.0468 Loss_G: 15.2160 D(x): 0.2052 D(G(z)): 0.0000 / 0.0000\n",
      "[4/25][43/79] Loss_D: 0.3774 Loss_G: 10.4899 D(x): 0.7891 D(G(z)): 0.0000 / 0.0004\n",
      "[4/25][44/79] Loss_D: 0.0675 Loss_G: 5.8100 D(x): 0.9676 D(G(z)): 0.0192 / 0.0234\n",
      "[4/25][45/79] Loss_D: 1.3990 Loss_G: 14.4766 D(x): 0.9947 D(G(z)): 0.5781 / 0.0000\n",
      "[4/25][46/79] Loss_D: 0.6892 Loss_G: 12.5992 D(x): 0.6479 D(G(z)): 0.0008 / 0.0002\n",
      "[4/25][47/79] Loss_D: 0.3425 Loss_G: 9.4081 D(x): 0.8117 D(G(z)): 0.0010 / 0.0006\n",
      "[4/25][48/79] Loss_D: 0.0527 Loss_G: 5.4665 D(x): 0.9678 D(G(z)): 0.0152 / 0.0137\n",
      "[4/25][49/79] Loss_D: 0.4964 Loss_G: 6.6815 D(x): 0.9722 D(G(z)): 0.2652 / 0.0044\n",
      "[4/25][50/79] Loss_D: 0.1209 Loss_G: 7.3013 D(x): 0.9872 D(G(z)): 0.0877 / 0.0023\n",
      "[4/25][51/79] Loss_D: 0.0923 Loss_G: 6.2301 D(x): 0.9509 D(G(z)): 0.0323 / 0.0035\n",
      "[4/25][52/79] Loss_D: 0.1279 Loss_G: 5.9597 D(x): 0.9743 D(G(z)): 0.0894 / 0.0044\n",
      "[4/25][53/79] Loss_D: 0.1553 Loss_G: 6.1916 D(x): 0.9574 D(G(z)): 0.0917 / 0.0060\n",
      "[4/25][54/79] Loss_D: 0.1869 Loss_G: 6.0253 D(x): 0.9206 D(G(z)): 0.0830 / 0.0055\n",
      "[4/25][55/79] Loss_D: 0.1383 Loss_G: 6.5683 D(x): 0.9684 D(G(z)): 0.0931 / 0.0031\n",
      "[4/25][56/79] Loss_D: 0.1680 Loss_G: 5.5400 D(x): 0.8938 D(G(z)): 0.0353 / 0.0049\n",
      "[4/25][57/79] Loss_D: 0.1576 Loss_G: 6.0505 D(x): 0.9459 D(G(z)): 0.0902 / 0.0031\n",
      "[4/25][58/79] Loss_D: 0.1014 Loss_G: 6.7963 D(x): 0.9688 D(G(z)): 0.0621 / 0.0023\n",
      "[4/25][59/79] Loss_D: 0.0917 Loss_G: 5.8035 D(x): 0.9339 D(G(z)): 0.0167 / 0.0042\n",
      "[4/25][60/79] Loss_D: 0.0648 Loss_G: 5.1102 D(x): 0.9756 D(G(z)): 0.0383 / 0.0074\n",
      "[4/25][61/79] Loss_D: 0.1408 Loss_G: 7.3114 D(x): 0.9900 D(G(z)): 0.1162 / 0.0014\n",
      "[4/25][62/79] Loss_D: 0.0834 Loss_G: 6.9324 D(x): 0.9326 D(G(z)): 0.0100 / 0.0019\n",
      "[4/25][63/79] Loss_D: 0.0722 Loss_G: 5.6986 D(x): 0.9459 D(G(z)): 0.0142 / 0.0062\n",
      "[4/25][64/79] Loss_D: 0.1322 Loss_G: 4.4509 D(x): 0.9196 D(G(z)): 0.0374 / 0.0147\n",
      "[4/25][65/79] Loss_D: 0.2223 Loss_G: 8.0726 D(x): 0.9766 D(G(z)): 0.1646 / 0.0007\n",
      "[4/25][66/79] Loss_D: 0.0820 Loss_G: 8.1817 D(x): 0.9290 D(G(z)): 0.0041 / 0.0006\n",
      "[4/25][67/79] Loss_D: 0.1064 Loss_G: 6.8575 D(x): 0.9155 D(G(z)): 0.0025 / 0.0016\n",
      "[4/25][68/79] Loss_D: 0.0342 Loss_G: 5.2809 D(x): 0.9798 D(G(z)): 0.0130 / 0.0078\n",
      "[4/25][69/79] Loss_D: 0.0720 Loss_G: 5.5906 D(x): 0.9888 D(G(z)): 0.0574 / 0.0058\n",
      "[4/25][70/79] Loss_D: 0.0665 Loss_G: 6.3821 D(x): 0.9861 D(G(z)): 0.0500 / 0.0025\n",
      "[4/25][71/79] Loss_D: 0.0496 Loss_G: 6.3166 D(x): 0.9751 D(G(z)): 0.0229 / 0.0028\n",
      "[4/25][72/79] Loss_D: 0.0651 Loss_G: 6.0962 D(x): 0.9750 D(G(z)): 0.0380 / 0.0029\n",
      "[4/25][73/79] Loss_D: 0.1036 Loss_G: 7.8834 D(x): 0.9813 D(G(z)): 0.0782 / 0.0006\n",
      "[4/25][74/79] Loss_D: 0.0795 Loss_G: 7.0885 D(x): 0.9388 D(G(z)): 0.0113 / 0.0013\n",
      "[4/25][75/79] Loss_D: 0.2125 Loss_G: 4.8240 D(x): 0.8913 D(G(z)): 0.0250 / 0.0112\n",
      "[4/25][76/79] Loss_D: 0.3333 Loss_G: 12.5485 D(x): 0.9830 D(G(z)): 0.2539 / 0.0000\n",
      "[4/25][77/79] Loss_D: 0.1836 Loss_G: 13.4250 D(x): 0.8660 D(G(z)): 0.0001 / 0.0000\n",
      "[4/25][78/79] Loss_D: 0.0121 Loss_G: 12.7205 D(x): 0.9881 D(G(z)): 0.0000 / 0.0000\n",
      "[5/25][0/79] Loss_D: 0.0679 Loss_G: 10.8335 D(x): 0.9427 D(G(z)): 0.0000 / 0.0000\n",
      "[5/25][1/79] Loss_D: 0.0466 Loss_G: 7.9151 D(x): 0.9684 D(G(z)): 0.0005 / 0.0005\n",
      "[5/25][2/79] Loss_D: 0.0351 Loss_G: 4.8789 D(x): 0.9833 D(G(z)): 0.0173 / 0.0119\n",
      "[5/25][3/79] Loss_D: 0.3117 Loss_G: 8.8398 D(x): 0.9780 D(G(z)): 0.2275 / 0.0002\n",
      "[5/25][4/79] Loss_D: 0.0740 Loss_G: 9.1809 D(x): 0.9408 D(G(z)): 0.0029 / 0.0002\n",
      "[5/25][5/79] Loss_D: 0.0396 Loss_G: 8.4077 D(x): 0.9649 D(G(z)): 0.0017 / 0.0006\n",
      "[5/25][6/79] Loss_D: 0.0368 Loss_G: 6.4898 D(x): 0.9725 D(G(z)): 0.0080 / 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][7/79] Loss_D: 0.0773 Loss_G: 5.4928 D(x): 0.9749 D(G(z)): 0.0462 / 0.0096\n",
      "[5/25][8/79] Loss_D: 0.1426 Loss_G: 6.5631 D(x): 0.9912 D(G(z)): 0.1104 / 0.0025\n",
      "[5/25][9/79] Loss_D: 0.1234 Loss_G: 6.0977 D(x): 0.9302 D(G(z)): 0.0345 / 0.0032\n",
      "[5/25][10/79] Loss_D: 0.1574 Loss_G: 4.9227 D(x): 0.9146 D(G(z)): 0.0523 / 0.0101\n",
      "[5/25][11/79] Loss_D: 0.2174 Loss_G: 6.7809 D(x): 0.9541 D(G(z)): 0.1436 / 0.0015\n",
      "[5/25][12/79] Loss_D: 0.2436 Loss_G: 5.0605 D(x): 0.8450 D(G(z)): 0.0291 / 0.0083\n",
      "[5/25][13/79] Loss_D: 0.2290 Loss_G: 7.2415 D(x): 0.9706 D(G(z)): 0.1680 / 0.0010\n",
      "[5/25][14/79] Loss_D: 0.1420 Loss_G: 6.0334 D(x): 0.8947 D(G(z)): 0.0210 / 0.0032\n",
      "[5/25][15/79] Loss_D: 0.0541 Loss_G: 5.2302 D(x): 0.9724 D(G(z)): 0.0251 / 0.0070\n",
      "[5/25][16/79] Loss_D: 0.2043 Loss_G: 5.2072 D(x): 0.9238 D(G(z)): 0.1076 / 0.0072\n",
      "[5/25][17/79] Loss_D: 0.2255 Loss_G: 6.1948 D(x): 0.9146 D(G(z)): 0.1164 / 0.0030\n",
      "[5/25][18/79] Loss_D: 0.1345 Loss_G: 5.3824 D(x): 0.9086 D(G(z)): 0.0288 / 0.0072\n",
      "[5/25][19/79] Loss_D: 0.1765 Loss_G: 6.4821 D(x): 0.9623 D(G(z)): 0.1115 / 0.0024\n",
      "[5/25][20/79] Loss_D: 0.2667 Loss_G: 3.8175 D(x): 0.8281 D(G(z)): 0.0246 / 0.0300\n",
      "[5/25][21/79] Loss_D: 0.5397 Loss_G: 11.0715 D(x): 0.9641 D(G(z)): 0.3446 / 0.0000\n",
      "[5/25][22/79] Loss_D: 1.6390 Loss_G: 3.4585 D(x): 0.3370 D(G(z)): 0.0002 / 0.0594\n",
      "[5/25][23/79] Loss_D: 0.6283 Loss_G: 8.1527 D(x): 0.9842 D(G(z)): 0.4180 / 0.0005\n",
      "[5/25][24/79] Loss_D: 0.1828 Loss_G: 8.1310 D(x): 0.8633 D(G(z)): 0.0079 / 0.0008\n",
      "[5/25][25/79] Loss_D: 0.1208 Loss_G: 6.8685 D(x): 0.9042 D(G(z)): 0.0037 / 0.0025\n",
      "[5/25][26/79] Loss_D: 0.0346 Loss_G: 5.4057 D(x): 0.9888 D(G(z)): 0.0221 / 0.0106\n",
      "[5/25][27/79] Loss_D: 0.0601 Loss_G: 5.2847 D(x): 0.9958 D(G(z)): 0.0526 / 0.0100\n",
      "[5/25][28/79] Loss_D: 0.1021 Loss_G: 5.2532 D(x): 0.9586 D(G(z)): 0.0500 / 0.0101\n",
      "[5/25][29/79] Loss_D: 0.1009 Loss_G: 5.9875 D(x): 0.9829 D(G(z)): 0.0755 / 0.0049\n",
      "[5/25][30/79] Loss_D: 0.0679 Loss_G: 5.8837 D(x): 0.9622 D(G(z)): 0.0256 / 0.0055\n",
      "[5/25][31/79] Loss_D: 0.0837 Loss_G: 4.9570 D(x): 0.9426 D(G(z)): 0.0215 / 0.0104\n",
      "[5/25][32/79] Loss_D: 0.0628 Loss_G: 5.1065 D(x): 0.9803 D(G(z)): 0.0408 / 0.0094\n",
      "[5/25][33/79] Loss_D: 0.0608 Loss_G: 5.4027 D(x): 0.9736 D(G(z)): 0.0322 / 0.0073\n",
      "[5/25][34/79] Loss_D: 0.1082 Loss_G: 4.5662 D(x): 0.9319 D(G(z)): 0.0306 / 0.0151\n",
      "[5/25][35/79] Loss_D: 0.1056 Loss_G: 5.7853 D(x): 0.9705 D(G(z)): 0.0676 / 0.0051\n",
      "[5/25][36/79] Loss_D: 0.0787 Loss_G: 5.2079 D(x): 0.9467 D(G(z)): 0.0191 / 0.0076\n",
      "[5/25][37/79] Loss_D: 0.1005 Loss_G: 4.7583 D(x): 0.9449 D(G(z)): 0.0394 / 0.0113\n",
      "[5/25][38/79] Loss_D: 0.0945 Loss_G: 5.2422 D(x): 0.9581 D(G(z)): 0.0401 / 0.0072\n",
      "[5/25][39/79] Loss_D: 0.0909 Loss_G: 5.8496 D(x): 0.9614 D(G(z)): 0.0469 / 0.0042\n",
      "[5/25][40/79] Loss_D: 0.0699 Loss_G: 5.5782 D(x): 0.9629 D(G(z)): 0.0298 / 0.0049\n",
      "[5/25][41/79] Loss_D: 0.0888 Loss_G: 4.8039 D(x): 0.9455 D(G(z)): 0.0270 / 0.0109\n",
      "[5/25][42/79] Loss_D: 0.1788 Loss_G: 9.0906 D(x): 0.9554 D(G(z)): 0.1214 / 0.0002\n",
      "[5/25][43/79] Loss_D: 0.3398 Loss_G: 2.5714 D(x): 0.7553 D(G(z)): 0.0011 / 0.1139\n",
      "[5/25][44/79] Loss_D: 0.9356 Loss_G: 14.7749 D(x): 0.9969 D(G(z)): 0.5321 / 0.0000\n",
      "[5/25][45/79] Loss_D: 4.2260 Loss_G: 11.0070 D(x): 0.1170 D(G(z)): 0.0000 / 0.0001\n",
      "[5/25][46/79] Loss_D: 0.1160 Loss_G: 8.5012 D(x): 0.9061 D(G(z)): 0.0004 / 0.0012\n",
      "[5/25][47/79] Loss_D: 0.2359 Loss_G: 5.1472 D(x): 0.9197 D(G(z)): 0.0118 / 0.0251\n",
      "[5/25][48/79] Loss_D: 0.2438 Loss_G: 6.9755 D(x): 0.9976 D(G(z)): 0.1521 / 0.0019\n",
      "[5/25][49/79] Loss_D: 0.0447 Loss_G: 7.4027 D(x): 0.9836 D(G(z)): 0.0252 / 0.0015\n",
      "[5/25][50/79] Loss_D: 0.0379 Loss_G: 6.6155 D(x): 0.9737 D(G(z)): 0.0070 / 0.0024\n",
      "[5/25][51/79] Loss_D: 0.0652 Loss_G: 5.0377 D(x): 0.9627 D(G(z)): 0.0222 / 0.0118\n",
      "[5/25][52/79] Loss_D: 0.1480 Loss_G: 5.0079 D(x): 0.9550 D(G(z)): 0.0881 / 0.0098\n",
      "[5/25][53/79] Loss_D: 0.2169 Loss_G: 4.6131 D(x): 0.9005 D(G(z)): 0.0561 / 0.0147\n",
      "[5/25][54/79] Loss_D: 0.1418 Loss_G: 5.1435 D(x): 0.9554 D(G(z)): 0.0830 / 0.0084\n",
      "[5/25][55/79] Loss_D: 0.1790 Loss_G: 5.2701 D(x): 0.9362 D(G(z)): 0.0785 / 0.0073\n",
      "[5/25][56/79] Loss_D: 0.1477 Loss_G: 5.3509 D(x): 0.9454 D(G(z)): 0.0680 / 0.0065\n",
      "[5/25][57/79] Loss_D: 0.2295 Loss_G: 4.3784 D(x): 0.8862 D(G(z)): 0.0491 / 0.0182\n",
      "[5/25][58/79] Loss_D: 0.2283 Loss_G: 6.2242 D(x): 0.9647 D(G(z)): 0.1598 / 0.0026\n",
      "[5/25][59/79] Loss_D: 0.1603 Loss_G: 5.4567 D(x): 0.8908 D(G(z)): 0.0121 / 0.0057\n",
      "[5/25][60/79] Loss_D: 0.1538 Loss_G: 4.0456 D(x): 0.9274 D(G(z)): 0.0620 / 0.0232\n",
      "[5/25][61/79] Loss_D: 0.1887 Loss_G: 5.6583 D(x): 0.9624 D(G(z)): 0.1250 / 0.0051\n",
      "[5/25][62/79] Loss_D: 0.1068 Loss_G: 5.2793 D(x): 0.9293 D(G(z)): 0.0235 / 0.0064\n",
      "[5/25][63/79] Loss_D: 0.0665 Loss_G: 4.7430 D(x): 0.9574 D(G(z)): 0.0206 / 0.0112\n",
      "[5/25][64/79] Loss_D: 0.0991 Loss_G: 5.0497 D(x): 0.9800 D(G(z)): 0.0730 / 0.0079\n",
      "[5/25][65/79] Loss_D: 0.1550 Loss_G: 4.8046 D(x): 0.9213 D(G(z)): 0.0550 / 0.0110\n",
      "[5/25][66/79] Loss_D: 0.2248 Loss_G: 3.3190 D(x): 0.8742 D(G(z)): 0.0389 / 0.0440\n",
      "[5/25][67/79] Loss_D: 0.4184 Loss_G: 8.9353 D(x): 0.9383 D(G(z)): 0.2527 / 0.0009\n",
      "[5/25][68/79] Loss_D: 0.5038 Loss_G: 4.4265 D(x): 0.6959 D(G(z)): 0.0018 / 0.0169\n",
      "[5/25][69/79] Loss_D: 0.3465 Loss_G: 7.6769 D(x): 0.9689 D(G(z)): 0.2414 / 0.0008\n",
      "[5/25][70/79] Loss_D: 0.1222 Loss_G: 7.6869 D(x): 0.9319 D(G(z)): 0.0061 / 0.0010\n",
      "[5/25][71/79] Loss_D: 0.2616 Loss_G: 3.6706 D(x): 0.8578 D(G(z)): 0.0179 / 0.0444\n",
      "[5/25][72/79] Loss_D: 0.6960 Loss_G: 11.2486 D(x): 0.9609 D(G(z)): 0.3778 / 0.0000\n",
      "[5/25][73/79] Loss_D: 1.0347 Loss_G: 6.1710 D(x): 0.5724 D(G(z)): 0.0007 / 0.0053\n",
      "[5/25][74/79] Loss_D: 0.4778 Loss_G: 3.0805 D(x): 0.9061 D(G(z)): 0.0683 / 0.0871\n",
      "[5/25][75/79] Loss_D: 0.8002 Loss_G: 9.6807 D(x): 0.9823 D(G(z)): 0.4423 / 0.0003\n",
      "[5/25][76/79] Loss_D: 0.9191 Loss_G: 7.1043 D(x): 0.6325 D(G(z)): 0.0019 / 0.0025\n",
      "[5/25][77/79] Loss_D: 0.1130 Loss_G: 4.9184 D(x): 0.9268 D(G(z)): 0.0113 / 0.0179\n",
      "[5/25][78/79] Loss_D: 0.1483 Loss_G: 5.1623 D(x): 0.9920 D(G(z)): 0.1238 / 0.0105\n",
      "[6/25][0/79] Loss_D: 0.2259 Loss_G: 5.9605 D(x): 0.9674 D(G(z)): 0.1555 / 0.0053\n",
      "[6/25][1/79] Loss_D: 0.1504 Loss_G: 5.4561 D(x): 0.9257 D(G(z)): 0.0394 / 0.0064\n",
      "[6/25][2/79] Loss_D: 0.1398 Loss_G: 4.5149 D(x): 0.9114 D(G(z)): 0.0339 / 0.0164\n",
      "[6/25][3/79] Loss_D: 0.1787 Loss_G: 3.8618 D(x): 0.9207 D(G(z)): 0.0784 / 0.0261\n",
      "[6/25][4/79] Loss_D: 0.1972 Loss_G: 3.9679 D(x): 0.9112 D(G(z)): 0.0838 / 0.0246\n",
      "[6/25][5/79] Loss_D: 0.3758 Loss_G: 3.9072 D(x): 0.8280 D(G(z)): 0.1397 / 0.0282\n",
      "[6/25][6/79] Loss_D: 0.3504 Loss_G: 5.6142 D(x): 0.8925 D(G(z)): 0.1899 / 0.0060\n",
      "[6/25][7/79] Loss_D: 0.2438 Loss_G: 4.2279 D(x): 0.8343 D(G(z)): 0.0274 / 0.0271\n",
      "[6/25][8/79] Loss_D: 0.1892 Loss_G: 4.5578 D(x): 0.9585 D(G(z)): 0.1282 / 0.0164\n",
      "[6/25][9/79] Loss_D: 0.2191 Loss_G: 5.8708 D(x): 0.9462 D(G(z)): 0.1429 / 0.0039\n",
      "[6/25][10/79] Loss_D: 0.7552 Loss_G: 0.8757 D(x): 0.6030 D(G(z)): 0.0805 / 0.4478\n",
      "[6/25][11/79] Loss_D: 1.9684 Loss_G: 11.3608 D(x): 0.9814 D(G(z)): 0.8198 / 0.0000\n",
      "[6/25][12/79] Loss_D: 3.7500 Loss_G: 5.7632 D(x): 0.0659 D(G(z)): 0.0001 / 0.0074\n",
      "[6/25][13/79] Loss_D: 0.3831 Loss_G: 2.1003 D(x): 0.7556 D(G(z)): 0.0267 / 0.2150\n",
      "[6/25][14/79] Loss_D: 0.5704 Loss_G: 4.4395 D(x): 0.9821 D(G(z)): 0.3720 / 0.0207\n",
      "[6/25][15/79] Loss_D: 0.3911 Loss_G: 3.6968 D(x): 0.7980 D(G(z)): 0.1183 / 0.0370\n",
      "[6/25][16/79] Loss_D: 0.3823 Loss_G: 2.7212 D(x): 0.8048 D(G(z)): 0.1227 / 0.0941\n",
      "[6/25][17/79] Loss_D: 0.5080 Loss_G: 4.3666 D(x): 0.9294 D(G(z)): 0.3224 / 0.0182\n",
      "[6/25][18/79] Loss_D: 0.4613 Loss_G: 3.0116 D(x): 0.7132 D(G(z)): 0.0492 / 0.0740\n",
      "[6/25][19/79] Loss_D: 0.4581 Loss_G: 3.0038 D(x): 0.8867 D(G(z)): 0.2513 / 0.0688\n",
      "[6/25][20/79] Loss_D: 0.5081 Loss_G: 3.7729 D(x): 0.8228 D(G(z)): 0.2207 / 0.0401\n",
      "[6/25][21/79] Loss_D: 0.5281 Loss_G: 2.8793 D(x): 0.7412 D(G(z)): 0.1519 / 0.0886\n",
      "[6/25][22/79] Loss_D: 0.4705 Loss_G: 3.3380 D(x): 0.8453 D(G(z)): 0.2174 / 0.0560\n",
      "[6/25][23/79] Loss_D: 0.2876 Loss_G: 3.6356 D(x): 0.8729 D(G(z)): 0.1249 / 0.0386\n",
      "[6/25][24/79] Loss_D: 0.3780 Loss_G: 2.7049 D(x): 0.7786 D(G(z)): 0.0805 / 0.1113\n",
      "[6/25][25/79] Loss_D: 0.4185 Loss_G: 5.2224 D(x): 0.9605 D(G(z)): 0.2896 / 0.0088\n",
      "[6/25][26/79] Loss_D: 0.4199 Loss_G: 3.5358 D(x): 0.7125 D(G(z)): 0.0203 / 0.0505\n",
      "[6/25][27/79] Loss_D: 0.3587 Loss_G: 3.7066 D(x): 0.8971 D(G(z)): 0.1943 / 0.0424\n",
      "[6/25][28/79] Loss_D: 0.2079 Loss_G: 4.6231 D(x): 0.9259 D(G(z)): 0.1028 / 0.0285\n",
      "[6/25][29/79] Loss_D: 0.3162 Loss_G: 3.1903 D(x): 0.8246 D(G(z)): 0.0781 / 0.0592\n",
      "[6/25][30/79] Loss_D: 0.2874 Loss_G: 3.9129 D(x): 0.9086 D(G(z)): 0.1484 / 0.0316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][31/79] Loss_D: 0.2941 Loss_G: 3.5248 D(x): 0.8603 D(G(z)): 0.1102 / 0.0424\n",
      "[6/25][32/79] Loss_D: 0.2271 Loss_G: 4.0328 D(x): 0.9053 D(G(z)): 0.1059 / 0.0248\n",
      "[6/25][33/79] Loss_D: 0.4623 Loss_G: 1.4804 D(x): 0.7359 D(G(z)): 0.0880 / 0.2570\n",
      "[6/25][34/79] Loss_D: 0.7785 Loss_G: 8.8075 D(x): 0.9848 D(G(z)): 0.5065 / 0.0002\n",
      "[6/25][35/79] Loss_D: 2.0565 Loss_G: 2.9057 D(x): 0.2185 D(G(z)): 0.0006 / 0.1017\n",
      "[6/25][36/79] Loss_D: 0.4241 Loss_G: 3.4069 D(x): 0.9485 D(G(z)): 0.2687 / 0.0447\n",
      "[6/25][37/79] Loss_D: 0.3989 Loss_G: 3.9669 D(x): 0.8499 D(G(z)): 0.1670 / 0.0305\n",
      "[6/25][38/79] Loss_D: 0.7521 Loss_G: 2.4161 D(x): 0.7117 D(G(z)): 0.1797 / 0.1783\n",
      "[6/25][39/79] Loss_D: 0.6466 Loss_G: 4.3492 D(x): 0.8568 D(G(z)): 0.3208 / 0.0200\n",
      "[6/25][40/79] Loss_D: 0.3819 Loss_G: 3.3312 D(x): 0.7894 D(G(z)): 0.0962 / 0.0601\n",
      "[6/25][41/79] Loss_D: 0.4897 Loss_G: 3.4457 D(x): 0.8281 D(G(z)): 0.2096 / 0.0521\n",
      "[6/25][42/79] Loss_D: 0.4272 Loss_G: 3.7931 D(x): 0.8493 D(G(z)): 0.1767 / 0.0486\n",
      "[6/25][43/79] Loss_D: 0.2731 Loss_G: 3.6492 D(x): 0.8752 D(G(z)): 0.1042 / 0.0434\n",
      "[6/25][44/79] Loss_D: 0.2373 Loss_G: 4.0292 D(x): 0.9147 D(G(z)): 0.1163 / 0.0285\n",
      "[6/25][45/79] Loss_D: 0.3523 Loss_G: 3.8582 D(x): 0.8606 D(G(z)): 0.1266 / 0.0359\n",
      "[6/25][46/79] Loss_D: 0.3000 Loss_G: 3.4278 D(x): 0.8644 D(G(z)): 0.1093 / 0.0464\n",
      "[6/25][47/79] Loss_D: 0.3816 Loss_G: 5.2862 D(x): 0.9210 D(G(z)): 0.2210 / 0.0082\n",
      "[6/25][48/79] Loss_D: 0.4939 Loss_G: 2.0845 D(x): 0.6973 D(G(z)): 0.0257 / 0.1758\n",
      "[6/25][49/79] Loss_D: 0.6688 Loss_G: 6.8233 D(x): 0.9530 D(G(z)): 0.3956 / 0.0035\n",
      "[6/25][50/79] Loss_D: 1.3413 Loss_G: 1.0904 D(x): 0.4487 D(G(z)): 0.0150 / 0.4016\n",
      "[6/25][51/79] Loss_D: 1.2936 Loss_G: 7.1452 D(x): 0.9716 D(G(z)): 0.6256 / 0.0016\n",
      "[6/25][52/79] Loss_D: 0.8538 Loss_G: 3.9005 D(x): 0.5584 D(G(z)): 0.0126 / 0.0437\n",
      "[6/25][53/79] Loss_D: 0.5502 Loss_G: 1.8588 D(x): 0.7673 D(G(z)): 0.1345 / 0.2287\n",
      "[6/25][54/79] Loss_D: 1.3625 Loss_G: 8.5401 D(x): 0.9634 D(G(z)): 0.6145 / 0.0005\n",
      "[6/25][55/79] Loss_D: 2.6307 Loss_G: 2.7927 D(x): 0.2013 D(G(z)): 0.0023 / 0.1159\n",
      "[6/25][56/79] Loss_D: 0.4415 Loss_G: 2.9690 D(x): 0.9030 D(G(z)): 0.2305 / 0.1142\n",
      "[6/25][57/79] Loss_D: 0.6545 Loss_G: 5.4385 D(x): 0.9362 D(G(z)): 0.3329 / 0.0091\n",
      "[6/25][58/79] Loss_D: 0.8193 Loss_G: 1.8929 D(x): 0.5775 D(G(z)): 0.0468 / 0.2626\n",
      "[6/25][59/79] Loss_D: 1.0387 Loss_G: 5.5998 D(x): 0.9610 D(G(z)): 0.5484 / 0.0061\n",
      "[6/25][60/79] Loss_D: 1.6963 Loss_G: 0.8016 D(x): 0.3543 D(G(z)): 0.0524 / 0.5188\n",
      "[6/25][61/79] Loss_D: 1.4998 Loss_G: 4.7517 D(x): 0.9502 D(G(z)): 0.6642 / 0.0167\n",
      "[6/25][62/79] Loss_D: 0.6737 Loss_G: 3.7537 D(x): 0.6213 D(G(z)): 0.0423 / 0.0458\n",
      "[6/25][63/79] Loss_D: 0.3646 Loss_G: 2.4822 D(x): 0.8167 D(G(z)): 0.1144 / 0.1075\n",
      "[6/25][64/79] Loss_D: 0.5151 Loss_G: 3.8259 D(x): 0.9378 D(G(z)): 0.3298 / 0.0307\n",
      "[6/25][65/79] Loss_D: 0.4596 Loss_G: 3.2004 D(x): 0.7577 D(G(z)): 0.0876 / 0.0557\n",
      "[6/25][66/79] Loss_D: 0.3669 Loss_G: 2.9498 D(x): 0.8744 D(G(z)): 0.1756 / 0.0685\n",
      "[6/25][67/79] Loss_D: 0.4081 Loss_G: 3.2111 D(x): 0.8458 D(G(z)): 0.1730 / 0.0580\n",
      "[6/25][68/79] Loss_D: 0.5846 Loss_G: 2.3321 D(x): 0.7290 D(G(z)): 0.1726 / 0.1233\n",
      "[6/25][69/79] Loss_D: 0.5439 Loss_G: 3.9043 D(x): 0.8717 D(G(z)): 0.3090 / 0.0280\n",
      "[6/25][70/79] Loss_D: 0.4711 Loss_G: 2.8847 D(x): 0.7136 D(G(z)): 0.0713 / 0.0928\n",
      "[6/25][71/79] Loss_D: 0.5144 Loss_G: 3.9733 D(x): 0.9076 D(G(z)): 0.2879 / 0.0308\n",
      "[6/25][72/79] Loss_D: 0.4698 Loss_G: 2.6844 D(x): 0.7151 D(G(z)): 0.0584 / 0.0867\n",
      "[6/25][73/79] Loss_D: 0.3991 Loss_G: 3.2417 D(x): 0.8957 D(G(z)): 0.2279 / 0.0529\n",
      "[6/25][74/79] Loss_D: 0.3271 Loss_G: 3.8717 D(x): 0.9017 D(G(z)): 0.1725 / 0.0364\n",
      "[6/25][75/79] Loss_D: 0.4395 Loss_G: 2.3645 D(x): 0.7523 D(G(z)): 0.0981 / 0.1262\n",
      "[6/25][76/79] Loss_D: 0.4448 Loss_G: 4.0549 D(x): 0.9327 D(G(z)): 0.2847 / 0.0271\n",
      "[6/25][77/79] Loss_D: 0.4682 Loss_G: 2.9735 D(x): 0.7534 D(G(z)): 0.1033 / 0.0725\n",
      "[6/25][78/79] Loss_D: 0.4143 Loss_G: 3.7238 D(x): 0.8572 D(G(z)): 0.1776 / 0.0806\n",
      "[7/25][0/79] Loss_D: 0.7689 Loss_G: 4.3742 D(x): 0.8117 D(G(z)): 0.3326 / 0.0179\n",
      "[7/25][1/79] Loss_D: 0.5572 Loss_G: 2.2985 D(x): 0.6816 D(G(z)): 0.0547 / 0.1348\n",
      "[7/25][2/79] Loss_D: 0.5540 Loss_G: 4.1219 D(x): 0.9135 D(G(z)): 0.3312 / 0.0320\n",
      "[7/25][3/79] Loss_D: 0.5170 Loss_G: 3.3721 D(x): 0.7745 D(G(z)): 0.1790 / 0.0576\n",
      "[7/25][4/79] Loss_D: 0.7631 Loss_G: 2.3056 D(x): 0.6914 D(G(z)): 0.2294 / 0.1436\n",
      "[7/25][5/79] Loss_D: 0.7969 Loss_G: 6.0527 D(x): 0.8641 D(G(z)): 0.4139 / 0.0054\n",
      "[7/25][6/79] Loss_D: 1.1698 Loss_G: 1.0086 D(x): 0.4086 D(G(z)): 0.0138 / 0.4334\n",
      "[7/25][7/79] Loss_D: 1.2783 Loss_G: 7.2931 D(x): 0.9769 D(G(z)): 0.6632 / 0.0011\n",
      "[7/25][8/79] Loss_D: 1.2344 Loss_G: 3.9257 D(x): 0.3747 D(G(z)): 0.0089 / 0.0423\n",
      "[7/25][9/79] Loss_D: 0.2245 Loss_G: 2.9813 D(x): 0.9232 D(G(z)): 0.1174 / 0.0860\n",
      "[7/25][10/79] Loss_D: 0.4400 Loss_G: 5.2494 D(x): 0.9611 D(G(z)): 0.3087 / 0.0083\n",
      "[7/25][11/79] Loss_D: 0.5629 Loss_G: 2.3791 D(x): 0.6516 D(G(z)): 0.0375 / 0.1324\n",
      "[7/25][12/79] Loss_D: 0.8867 Loss_G: 5.1943 D(x): 0.9136 D(G(z)): 0.4963 / 0.0094\n",
      "[7/25][13/79] Loss_D: 0.9735 Loss_G: 2.0327 D(x): 0.4775 D(G(z)): 0.0368 / 0.1679\n",
      "[7/25][14/79] Loss_D: 0.9669 Loss_G: 5.3392 D(x): 0.9409 D(G(z)): 0.5233 / 0.0093\n",
      "[7/25][15/79] Loss_D: 1.2103 Loss_G: 0.8678 D(x): 0.3850 D(G(z)): 0.0390 / 0.4710\n",
      "[7/25][16/79] Loss_D: 1.9930 Loss_G: 5.7969 D(x): 0.9607 D(G(z)): 0.7820 / 0.0076\n",
      "[7/25][17/79] Loss_D: 1.5037 Loss_G: 2.1804 D(x): 0.3151 D(G(z)): 0.0272 / 0.1616\n",
      "[7/25][18/79] Loss_D: 0.5224 Loss_G: 2.5099 D(x): 0.8662 D(G(z)): 0.2848 / 0.1025\n",
      "[7/25][19/79] Loss_D: 0.5199 Loss_G: 4.0641 D(x): 0.8654 D(G(z)): 0.2799 / 0.0242\n",
      "[7/25][20/79] Loss_D: 0.4611 Loss_G: 2.8426 D(x): 0.7155 D(G(z)): 0.0731 / 0.0775\n",
      "[7/25][21/79] Loss_D: 0.3573 Loss_G: 2.8468 D(x): 0.8701 D(G(z)): 0.1817 / 0.0746\n",
      "[7/25][22/79] Loss_D: 0.3550 Loss_G: 3.5731 D(x): 0.8974 D(G(z)): 0.2008 / 0.0397\n",
      "[7/25][23/79] Loss_D: 0.3839 Loss_G: 3.1852 D(x): 0.8108 D(G(z)): 0.1334 / 0.0550\n",
      "[7/25][24/79] Loss_D: 0.3187 Loss_G: 3.6531 D(x): 0.8803 D(G(z)): 0.1576 / 0.0341\n",
      "[7/25][25/79] Loss_D: 0.2108 Loss_G: 3.5342 D(x): 0.8811 D(G(z)): 0.0711 / 0.0359\n",
      "[7/25][26/79] Loss_D: 0.2339 Loss_G: 4.1121 D(x): 0.9332 D(G(z)): 0.1413 / 0.0220\n",
      "[7/25][27/79] Loss_D: 0.2643 Loss_G: 3.2516 D(x): 0.8313 D(G(z)): 0.0507 / 0.0498\n",
      "[7/25][28/79] Loss_D: 0.3179 Loss_G: 4.4394 D(x): 0.9246 D(G(z)): 0.1926 / 0.0168\n",
      "[7/25][29/79] Loss_D: 0.2761 Loss_G: 3.7190 D(x): 0.8384 D(G(z)): 0.0813 / 0.0360\n",
      "[7/25][30/79] Loss_D: 0.2787 Loss_G: 3.7370 D(x): 0.8869 D(G(z)): 0.1303 / 0.0318\n",
      "[7/25][31/79] Loss_D: 0.3921 Loss_G: 3.3258 D(x): 0.8040 D(G(z)): 0.1346 / 0.0479\n",
      "[7/25][32/79] Loss_D: 0.4700 Loss_G: 5.4928 D(x): 0.8966 D(G(z)): 0.2813 / 0.0056\n",
      "[7/25][33/79] Loss_D: 0.5957 Loss_G: 1.9832 D(x): 0.6413 D(G(z)): 0.0442 / 0.1790\n",
      "[7/25][34/79] Loss_D: 0.8938 Loss_G: 6.6029 D(x): 0.9345 D(G(z)): 0.5197 / 0.0023\n",
      "[7/25][35/79] Loss_D: 1.1010 Loss_G: 2.7253 D(x): 0.4065 D(G(z)): 0.0168 / 0.0969\n",
      "[7/25][36/79] Loss_D: 0.6555 Loss_G: 5.9909 D(x): 0.9605 D(G(z)): 0.4211 / 0.0034\n",
      "[7/25][37/79] Loss_D: 0.6616 Loss_G: 2.7137 D(x): 0.6183 D(G(z)): 0.0327 / 0.0970\n",
      "[7/25][38/79] Loss_D: 0.6266 Loss_G: 5.0346 D(x): 0.9068 D(G(z)): 0.3628 / 0.0122\n",
      "[7/25][39/79] Loss_D: 0.4183 Loss_G: 3.0224 D(x): 0.7585 D(G(z)): 0.0864 / 0.0694\n",
      "[7/25][40/79] Loss_D: 0.5153 Loss_G: 5.8008 D(x): 0.8887 D(G(z)): 0.2849 / 0.0053\n",
      "[7/25][41/79] Loss_D: 0.6780 Loss_G: 2.5018 D(x): 0.5926 D(G(z)): 0.0350 / 0.1177\n",
      "[7/25][42/79] Loss_D: 0.7112 Loss_G: 5.1266 D(x): 0.9294 D(G(z)): 0.4131 / 0.0102\n",
      "[7/25][43/79] Loss_D: 0.3731 Loss_G: 3.9302 D(x): 0.7617 D(G(z)): 0.0624 / 0.0314\n",
      "[7/25][44/79] Loss_D: 0.2616 Loss_G: 3.5995 D(x): 0.8960 D(G(z)): 0.1277 / 0.0364\n",
      "[7/25][45/79] Loss_D: 0.4445 Loss_G: 3.4502 D(x): 0.7959 D(G(z)): 0.1593 / 0.0466\n",
      "[7/25][46/79] Loss_D: 0.3239 Loss_G: 4.0651 D(x): 0.8857 D(G(z)): 0.1694 / 0.0266\n",
      "[7/25][47/79] Loss_D: 0.2968 Loss_G: 3.6702 D(x): 0.8457 D(G(z)): 0.0980 / 0.0354\n",
      "[7/25][48/79] Loss_D: 0.1706 Loss_G: 4.2062 D(x): 0.9481 D(G(z)): 0.1037 / 0.0200\n",
      "[7/25][49/79] Loss_D: 0.1072 Loss_G: 4.4226 D(x): 0.9539 D(G(z)): 0.0568 / 0.0161\n",
      "[7/25][50/79] Loss_D: 0.3145 Loss_G: 2.7460 D(x): 0.7889 D(G(z)): 0.0474 / 0.0834\n",
      "[7/25][51/79] Loss_D: 0.3579 Loss_G: 5.0293 D(x): 0.9844 D(G(z)): 0.2768 / 0.0084\n",
      "[7/25][52/79] Loss_D: 0.3196 Loss_G: 3.2242 D(x): 0.7851 D(G(z)): 0.0374 / 0.0530\n",
      "[7/25][53/79] Loss_D: 0.3042 Loss_G: 6.2367 D(x): 0.9395 D(G(z)): 0.2015 / 0.0034\n",
      "[7/25][54/79] Loss_D: 0.1383 Loss_G: 3.8969 D(x): 0.9056 D(G(z)): 0.0339 / 0.0427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][55/79] Loss_D: 0.4945 Loss_G: 5.8245 D(x): 0.8376 D(G(z)): 0.2302 / 0.0045\n",
      "[7/25][56/79] Loss_D: 0.3647 Loss_G: 3.2015 D(x): 0.7487 D(G(z)): 0.0349 / 0.0610\n",
      "[7/25][57/79] Loss_D: 0.3922 Loss_G: 4.8100 D(x): 0.9138 D(G(z)): 0.2387 / 0.0122\n",
      "[7/25][58/79] Loss_D: 0.2850 Loss_G: 3.5013 D(x): 0.8133 D(G(z)): 0.0472 / 0.0505\n",
      "[7/25][59/79] Loss_D: 0.5818 Loss_G: 4.5922 D(x): 0.8599 D(G(z)): 0.3117 / 0.0123\n",
      "[7/25][60/79] Loss_D: 0.5409 Loss_G: 1.1242 D(x): 0.6723 D(G(z)): 0.0471 / 0.3855\n",
      "[7/25][61/79] Loss_D: 1.1824 Loss_G: 10.8721 D(x): 0.9584 D(G(z)): 0.6198 / 0.0000\n",
      "[7/25][62/79] Loss_D: 3.5619 Loss_G: 2.4306 D(x): 0.0567 D(G(z)): 0.0001 / 0.1380\n",
      "[7/25][63/79] Loss_D: 0.6513 Loss_G: 6.3440 D(x): 0.9168 D(G(z)): 0.3781 / 0.0032\n",
      "[7/25][64/79] Loss_D: 0.3962 Loss_G: 3.5504 D(x): 0.7157 D(G(z)): 0.0167 / 0.0592\n",
      "[7/25][65/79] Loss_D: 0.4000 Loss_G: 2.6188 D(x): 0.8527 D(G(z)): 0.1784 / 0.0920\n",
      "[7/25][66/79] Loss_D: 0.4797 Loss_G: 5.8071 D(x): 0.9605 D(G(z)): 0.3165 / 0.0057\n",
      "[7/25][67/79] Loss_D: 0.5227 Loss_G: 3.1956 D(x): 0.6513 D(G(z)): 0.0203 / 0.0748\n",
      "[7/25][68/79] Loss_D: 0.3155 Loss_G: 3.7178 D(x): 0.9391 D(G(z)): 0.2009 / 0.0329\n",
      "[7/25][69/79] Loss_D: 0.2229 Loss_G: 3.9114 D(x): 0.9042 D(G(z)): 0.1065 / 0.0291\n",
      "[7/25][70/79] Loss_D: 0.2250 Loss_G: 3.2959 D(x): 0.8790 D(G(z)): 0.0796 / 0.0484\n",
      "[7/25][71/79] Loss_D: 0.2590 Loss_G: 3.6872 D(x): 0.9066 D(G(z)): 0.1395 / 0.0314\n",
      "[7/25][72/79] Loss_D: 0.2156 Loss_G: 4.4053 D(x): 0.9370 D(G(z)): 0.1305 / 0.0199\n",
      "[7/25][73/79] Loss_D: 0.3305 Loss_G: 2.9705 D(x): 0.7803 D(G(z)): 0.0522 / 0.0655\n",
      "[7/25][74/79] Loss_D: 0.1895 Loss_G: 3.4310 D(x): 0.9517 D(G(z)): 0.1243 / 0.0418\n",
      "[7/25][75/79] Loss_D: 0.1681 Loss_G: 4.6922 D(x): 0.9828 D(G(z)): 0.1348 / 0.0121\n",
      "[7/25][76/79] Loss_D: 0.3442 Loss_G: 2.9228 D(x): 0.7478 D(G(z)): 0.0263 / 0.0678\n",
      "[7/25][77/79] Loss_D: 0.4144 Loss_G: 2.3197 D(x): 0.7948 D(G(z)): 0.1465 / 0.1182\n",
      "[7/25][78/79] Loss_D: 0.1589 Loss_G: 4.5171 D(x): 0.9853 D(G(z)): 0.1323 / 0.0119\n",
      "[8/25][0/79] Loss_D: 0.4594 Loss_G: 5.2112 D(x): 0.9949 D(G(z)): 0.3344 / 0.0112\n",
      "[8/25][1/79] Loss_D: 0.2147 Loss_G: 2.8488 D(x): 0.8395 D(G(z)): 0.0201 / 0.0950\n",
      "[8/25][2/79] Loss_D: 0.6928 Loss_G: 5.6660 D(x): 0.8284 D(G(z)): 0.3400 / 0.0046\n",
      "[8/25][3/79] Loss_D: 1.2938 Loss_G: 0.1425 D(x): 0.3663 D(G(z)): 0.0292 / 0.8771\n",
      "[8/25][4/79] Loss_D: 3.0962 Loss_G: 6.6189 D(x): 0.9820 D(G(z)): 0.9125 / 0.0026\n",
      "[8/25][5/79] Loss_D: 1.8267 Loss_G: 3.4730 D(x): 0.2461 D(G(z)): 0.0123 / 0.0551\n",
      "[8/25][6/79] Loss_D: 0.5165 Loss_G: 1.6142 D(x): 0.6890 D(G(z)): 0.0822 / 0.2837\n",
      "[8/25][7/79] Loss_D: 1.2214 Loss_G: 5.1736 D(x): 0.9219 D(G(z)): 0.5906 / 0.0121\n",
      "[8/25][8/79] Loss_D: 0.5902 Loss_G: 4.1107 D(x): 0.6376 D(G(z)): 0.0335 / 0.0254\n",
      "[8/25][9/79] Loss_D: 0.2333 Loss_G: 3.3362 D(x): 0.8846 D(G(z)): 0.0921 / 0.0516\n",
      "[8/25][10/79] Loss_D: 0.3026 Loss_G: 3.2827 D(x): 0.8551 D(G(z)): 0.1215 / 0.0526\n",
      "[8/25][11/79] Loss_D: 0.3026 Loss_G: 4.6460 D(x): 0.9477 D(G(z)): 0.1860 / 0.0150\n",
      "[8/25][12/79] Loss_D: 0.2107 Loss_G: 4.2227 D(x): 0.8568 D(G(z)): 0.0378 / 0.0235\n",
      "[8/25][13/79] Loss_D: 0.1936 Loss_G: 3.5085 D(x): 0.9050 D(G(z)): 0.0792 / 0.0432\n",
      "[8/25][14/79] Loss_D: 0.2392 Loss_G: 4.1792 D(x): 0.9201 D(G(z)): 0.1360 / 0.0205\n",
      "[8/25][15/79] Loss_D: 0.2543 Loss_G: 3.6190 D(x): 0.8723 D(G(z)): 0.0965 / 0.0379\n",
      "[8/25][16/79] Loss_D: 0.1096 Loss_G: 4.2610 D(x): 0.9792 D(G(z)): 0.0820 / 0.0211\n",
      "[8/25][17/79] Loss_D: 0.3934 Loss_G: 2.0442 D(x): 0.7313 D(G(z)): 0.0493 / 0.1469\n",
      "[8/25][18/79] Loss_D: 0.3907 Loss_G: 3.3831 D(x): 0.8754 D(G(z)): 0.2130 / 0.0418\n",
      "[8/25][19/79] Loss_D: 0.1658 Loss_G: 4.1723 D(x): 0.9563 D(G(z)): 0.1092 / 0.0197\n",
      "[8/25][20/79] Loss_D: 0.1153 Loss_G: 4.5341 D(x): 0.9326 D(G(z)): 0.0419 / 0.0145\n",
      "[8/25][21/79] Loss_D: 0.1494 Loss_G: 3.6255 D(x): 0.9006 D(G(z)): 0.0395 / 0.0341\n",
      "[8/25][22/79] Loss_D: 0.1080 Loss_G: 3.6249 D(x): 0.9776 D(G(z)): 0.0798 / 0.0343\n",
      "[8/25][23/79] Loss_D: 0.1985 Loss_G: 3.8230 D(x): 0.9169 D(G(z)): 0.0986 / 0.0295\n",
      "[8/25][24/79] Loss_D: 0.2500 Loss_G: 3.3517 D(x): 0.8696 D(G(z)): 0.0971 / 0.0431\n",
      "[8/25][25/79] Loss_D: 0.1687 Loss_G: 3.9594 D(x): 0.9744 D(G(z)): 0.1281 / 0.0268\n",
      "[8/25][26/79] Loss_D: 0.2332 Loss_G: 3.5384 D(x): 0.8752 D(G(z)): 0.0874 / 0.0390\n",
      "[8/25][27/79] Loss_D: 0.2103 Loss_G: 3.5898 D(x): 0.9447 D(G(z)): 0.1362 / 0.0348\n",
      "[8/25][28/79] Loss_D: 0.3999 Loss_G: 2.0419 D(x): 0.7378 D(G(z)): 0.0546 / 0.1554\n",
      "[8/25][29/79] Loss_D: 0.8932 Loss_G: 3.6448 D(x): 0.7731 D(G(z)): 0.4247 / 0.0358\n",
      "[8/25][30/79] Loss_D: 0.3388 Loss_G: 3.1743 D(x): 0.8068 D(G(z)): 0.0957 / 0.0562\n",
      "[8/25][31/79] Loss_D: 0.2860 Loss_G: 2.7343 D(x): 0.8640 D(G(z)): 0.1216 / 0.0787\n",
      "[8/25][32/79] Loss_D: 0.3734 Loss_G: 4.0317 D(x): 0.9162 D(G(z)): 0.2375 / 0.0230\n",
      "[8/25][33/79] Loss_D: 0.2255 Loss_G: 3.7624 D(x): 0.9016 D(G(z)): 0.1067 / 0.0287\n",
      "[8/25][34/79] Loss_D: 0.3554 Loss_G: 2.7137 D(x): 0.8164 D(G(z)): 0.1239 / 0.0835\n",
      "[8/25][35/79] Loss_D: 0.2182 Loss_G: 3.5608 D(x): 0.9494 D(G(z)): 0.1482 / 0.0392\n",
      "[8/25][36/79] Loss_D: 0.4972 Loss_G: 1.5345 D(x): 0.7254 D(G(z)): 0.1219 / 0.2443\n",
      "[8/25][37/79] Loss_D: 0.8690 Loss_G: 4.4864 D(x): 0.8338 D(G(z)): 0.4710 / 0.0146\n",
      "[8/25][38/79] Loss_D: 1.0587 Loss_G: 0.3109 D(x): 0.4092 D(G(z)): 0.0362 / 0.7523\n",
      "[8/25][39/79] Loss_D: 2.1311 Loss_G: 5.6363 D(x): 0.9928 D(G(z)): 0.8335 / 0.0053\n",
      "[8/25][40/79] Loss_D: 0.8175 Loss_G: 4.6871 D(x): 0.5137 D(G(z)): 0.0072 / 0.0153\n",
      "[8/25][41/79] Loss_D: 0.1655 Loss_G: 2.9524 D(x): 0.8759 D(G(z)): 0.0260 / 0.0796\n",
      "[8/25][42/79] Loss_D: 0.1404 Loss_G: 2.9180 D(x): 0.9833 D(G(z)): 0.1117 / 0.0779\n",
      "[8/25][43/79] Loss_D: 0.3376 Loss_G: 3.8992 D(x): 0.9843 D(G(z)): 0.2584 / 0.0271\n",
      "[8/25][44/79] Loss_D: 0.2084 Loss_G: 3.8615 D(x): 0.8725 D(G(z)): 0.0566 / 0.0283\n",
      "[8/25][45/79] Loss_D: 0.2129 Loss_G: 3.1879 D(x): 0.8706 D(G(z)): 0.0597 / 0.0566\n",
      "[8/25][46/79] Loss_D: 0.3688 Loss_G: 4.1377 D(x): 0.9463 D(G(z)): 0.2575 / 0.0210\n",
      "[8/25][47/79] Loss_D: 0.4259 Loss_G: 2.4481 D(x): 0.7388 D(G(z)): 0.0753 / 0.1097\n",
      "[8/25][48/79] Loss_D: 0.8123 Loss_G: 7.8335 D(x): 0.9156 D(G(z)): 0.4704 / 0.0008\n",
      "[8/25][49/79] Loss_D: 2.9148 Loss_G: 1.0904 D(x): 0.0892 D(G(z)): 0.0018 / 0.4152\n",
      "[8/25][50/79] Loss_D: 1.3178 Loss_G: 7.9406 D(x): 0.9764 D(G(z)): 0.6479 / 0.0005\n",
      "[8/25][51/79] Loss_D: 3.0291 Loss_G: 2.4599 D(x): 0.0875 D(G(z)): 0.0016 / 0.1168\n",
      "[8/25][52/79] Loss_D: 0.3575 Loss_G: 2.4794 D(x): 0.9758 D(G(z)): 0.2541 / 0.1153\n",
      "[8/25][53/79] Loss_D: 0.3532 Loss_G: 4.0438 D(x): 0.9748 D(G(z)): 0.2461 / 0.0212\n",
      "[8/25][54/79] Loss_D: 0.2211 Loss_G: 3.8712 D(x): 0.8732 D(G(z)): 0.0712 / 0.0278\n",
      "[8/25][55/79] Loss_D: 0.1780 Loss_G: 3.3227 D(x): 0.8929 D(G(z)): 0.0532 / 0.0436\n",
      "[8/25][56/79] Loss_D: 0.4416 Loss_G: 2.0776 D(x): 0.7945 D(G(z)): 0.1690 / 0.1500\n",
      "[8/25][57/79] Loss_D: 0.4347 Loss_G: 3.7269 D(x): 0.9738 D(G(z)): 0.3229 / 0.0300\n",
      "[8/25][58/79] Loss_D: 0.4181 Loss_G: 3.0320 D(x): 0.7653 D(G(z)): 0.1193 / 0.0638\n",
      "[8/25][59/79] Loss_D: 0.6415 Loss_G: 1.5556 D(x): 0.6631 D(G(z)): 0.1431 / 0.2344\n",
      "[8/25][60/79] Loss_D: 0.7069 Loss_G: 3.8648 D(x): 0.8891 D(G(z)): 0.4261 / 0.0269\n",
      "[8/25][61/79] Loss_D: 0.4727 Loss_G: 2.6278 D(x): 0.7176 D(G(z)): 0.1001 / 0.0875\n",
      "[8/25][62/79] Loss_D: 0.4502 Loss_G: 3.8084 D(x): 0.9015 D(G(z)): 0.2668 / 0.0313\n",
      "[8/25][63/79] Loss_D: 0.2442 Loss_G: 3.8286 D(x): 0.8683 D(G(z)): 0.0859 / 0.0274\n",
      "[8/25][64/79] Loss_D: 0.2777 Loss_G: 2.7987 D(x): 0.8039 D(G(z)): 0.0468 / 0.0742\n",
      "[8/25][65/79] Loss_D: 0.3076 Loss_G: 3.4056 D(x): 0.9248 D(G(z)): 0.1947 / 0.0415\n",
      "[8/25][66/79] Loss_D: 0.2709 Loss_G: 4.1119 D(x): 0.9140 D(G(z)): 0.1565 / 0.0194\n",
      "[8/25][67/79] Loss_D: 0.1902 Loss_G: 3.9882 D(x): 0.9018 D(G(z)): 0.0763 / 0.0235\n",
      "[8/25][68/79] Loss_D: 0.2771 Loss_G: 2.9367 D(x): 0.8192 D(G(z)): 0.0507 / 0.0676\n",
      "[8/25][69/79] Loss_D: 0.4825 Loss_G: 4.9746 D(x): 0.9570 D(G(z)): 0.3373 / 0.0087\n",
      "[8/25][70/79] Loss_D: 0.4158 Loss_G: 3.2394 D(x): 0.7305 D(G(z)): 0.0476 / 0.0472\n",
      "[8/25][71/79] Loss_D: 0.2766 Loss_G: 4.4990 D(x): 0.9170 D(G(z)): 0.1641 / 0.0141\n",
      "[8/25][72/79] Loss_D: 0.4375 Loss_G: 3.3171 D(x): 0.7662 D(G(z)): 0.1306 / 0.0443\n",
      "[8/25][73/79] Loss_D: 0.3581 Loss_G: 4.3553 D(x): 0.8734 D(G(z)): 0.1753 / 0.0178\n",
      "[8/25][74/79] Loss_D: 0.1797 Loss_G: 4.9711 D(x): 0.9481 D(G(z)): 0.1146 / 0.0087\n",
      "[8/25][75/79] Loss_D: 0.2728 Loss_G: 4.4800 D(x): 0.8741 D(G(z)): 0.0994 / 0.0144\n",
      "[8/25][76/79] Loss_D: 0.5128 Loss_G: 2.5640 D(x): 0.7357 D(G(z)): 0.1091 / 0.0943\n",
      "[8/25][77/79] Loss_D: 0.8576 Loss_G: 8.1981 D(x): 0.8657 D(G(z)): 0.4688 / 0.0005\n",
      "[8/25][78/79] Loss_D: 0.9219 Loss_G: 5.0356 D(x): 0.4944 D(G(z)): 0.0020 / 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][0/79] Loss_D: 0.6764 Loss_G: 6.5261 D(x): 0.9622 D(G(z)): 0.3475 / 0.0023\n",
      "[9/25][1/79] Loss_D: 0.3625 Loss_G: 4.9770 D(x): 0.7960 D(G(z)): 0.0696 / 0.0124\n",
      "[9/25][2/79] Loss_D: 0.3637 Loss_G: 5.0330 D(x): 0.9001 D(G(z)): 0.1871 / 0.0113\n",
      "[9/25][3/79] Loss_D: 0.5413 Loss_G: 5.3824 D(x): 0.8136 D(G(z)): 0.2380 / 0.0076\n",
      "[9/25][4/79] Loss_D: 0.6131 Loss_G: 4.0993 D(x): 0.7225 D(G(z)): 0.1809 / 0.0284\n",
      "[9/25][5/79] Loss_D: 0.5963 Loss_G: 6.1138 D(x): 0.8416 D(G(z)): 0.3003 / 0.0040\n",
      "[9/25][6/79] Loss_D: 0.9606 Loss_G: 1.6708 D(x): 0.4764 D(G(z)): 0.0514 / 0.3043\n",
      "[9/25][7/79] Loss_D: 1.5036 Loss_G: 8.7618 D(x): 0.9497 D(G(z)): 0.6689 / 0.0007\n",
      "[9/25][8/79] Loss_D: 1.5181 Loss_G: 3.4036 D(x): 0.3461 D(G(z)): 0.0066 / 0.0881\n",
      "[9/25][9/79] Loss_D: 0.4443 Loss_G: 2.9445 D(x): 0.9233 D(G(z)): 0.2157 / 0.1005\n",
      "[9/25][10/79] Loss_D: 0.7176 Loss_G: 6.0112 D(x): 0.9769 D(G(z)): 0.4147 / 0.0051\n",
      "[9/25][11/79] Loss_D: 0.8652 Loss_G: 3.1045 D(x): 0.5418 D(G(z)): 0.0243 / 0.0611\n",
      "[9/25][12/79] Loss_D: 0.3214 Loss_G: 3.3045 D(x): 0.9675 D(G(z)): 0.2292 / 0.0533\n",
      "[9/25][13/79] Loss_D: 0.3599 Loss_G: 4.3745 D(x): 0.9097 D(G(z)): 0.2169 / 0.0177\n",
      "[9/25][14/79] Loss_D: 0.3521 Loss_G: 4.3180 D(x): 0.8613 D(G(z)): 0.1569 / 0.0203\n",
      "[9/25][15/79] Loss_D: 0.3709 Loss_G: 3.6125 D(x): 0.7443 D(G(z)): 0.0306 / 0.0459\n",
      "[9/25][16/79] Loss_D: 0.4437 Loss_G: 3.3088 D(x): 0.8751 D(G(z)): 0.2338 / 0.0495\n",
      "[9/25][17/79] Loss_D: 0.3701 Loss_G: 4.0384 D(x): 0.8930 D(G(z)): 0.1978 / 0.0261\n",
      "[9/25][18/79] Loss_D: 0.2070 Loss_G: 3.9851 D(x): 0.8715 D(G(z)): 0.0588 / 0.0278\n",
      "[9/25][19/79] Loss_D: 0.1147 Loss_G: 3.9460 D(x): 0.9508 D(G(z)): 0.0604 / 0.0289\n",
      "[9/25][20/79] Loss_D: 0.2717 Loss_G: 3.1712 D(x): 0.8732 D(G(z)): 0.1163 / 0.0570\n",
      "[9/25][21/79] Loss_D: 0.2086 Loss_G: 4.1920 D(x): 0.9622 D(G(z)): 0.1485 / 0.0207\n",
      "[9/25][22/79] Loss_D: 0.3329 Loss_G: 3.2440 D(x): 0.7939 D(G(z)): 0.0730 / 0.0535\n",
      "[9/25][23/79] Loss_D: 0.2646 Loss_G: 4.1617 D(x): 0.9449 D(G(z)): 0.1719 / 0.0213\n",
      "[9/25][24/79] Loss_D: 0.1884 Loss_G: 3.9745 D(x): 0.9004 D(G(z)): 0.0746 / 0.0249\n",
      "[9/25][25/79] Loss_D: 0.1131 Loss_G: 4.1014 D(x): 0.9442 D(G(z)): 0.0510 / 0.0233\n",
      "[9/25][26/79] Loss_D: 0.2350 Loss_G: 3.8644 D(x): 0.9399 D(G(z)): 0.1485 / 0.0257\n",
      "[9/25][27/79] Loss_D: 0.9466 Loss_G: 0.6656 D(x): 0.4568 D(G(z)): 0.0528 / 0.5390\n",
      "[9/25][28/79] Loss_D: 1.4972 Loss_G: 5.4737 D(x): 0.9904 D(G(z)): 0.7372 / 0.0067\n",
      "[9/25][29/79] Loss_D: 0.2934 Loss_G: 3.3460 D(x): 0.7979 D(G(z)): 0.0371 / 0.0561\n",
      "[9/25][30/79] Loss_D: 0.6189 Loss_G: 3.5320 D(x): 0.7767 D(G(z)): 0.2680 / 0.0405\n",
      "[9/25][31/79] Loss_D: 0.5309 Loss_G: 2.9768 D(x): 0.7430 D(G(z)): 0.1673 / 0.0694\n",
      "[9/25][32/79] Loss_D: 0.6961 Loss_G: 4.9073 D(x): 0.7931 D(G(z)): 0.3318 / 0.0104\n",
      "[9/25][33/79] Loss_D: 1.0437 Loss_G: 0.5846 D(x): 0.4294 D(G(z)): 0.0359 / 0.5851\n",
      "[9/25][34/79] Loss_D: 1.8071 Loss_G: 8.4490 D(x): 0.9581 D(G(z)): 0.7978 / 0.0003\n",
      "[9/25][35/79] Loss_D: 2.4678 Loss_G: 3.7046 D(x): 0.1637 D(G(z)): 0.0016 / 0.0406\n",
      "[9/25][36/79] Loss_D: 0.2711 Loss_G: 1.7704 D(x): 0.8734 D(G(z)): 0.1050 / 0.2237\n",
      "[9/25][37/79] Loss_D: 0.9481 Loss_G: 4.6108 D(x): 0.9230 D(G(z)): 0.5270 / 0.0113\n",
      "[9/25][38/79] Loss_D: 0.6126 Loss_G: 2.9555 D(x): 0.6091 D(G(z)): 0.0328 / 0.0679\n",
      "[9/25][39/79] Loss_D: 0.3074 Loss_G: 2.1225 D(x): 0.8480 D(G(z)): 0.1114 / 0.1350\n",
      "[9/25][40/79] Loss_D: 0.4831 Loss_G: 3.9557 D(x): 0.9311 D(G(z)): 0.3206 / 0.0224\n",
      "[9/25][41/79] Loss_D: 0.4260 Loss_G: 2.8149 D(x): 0.7385 D(G(z)): 0.0833 / 0.0669\n",
      "[9/25][42/79] Loss_D: 0.2731 Loss_G: 3.6038 D(x): 0.9288 D(G(z)): 0.1746 / 0.0314\n",
      "[9/25][43/79] Loss_D: 0.3217 Loss_G: 3.0954 D(x): 0.8023 D(G(z)): 0.0654 / 0.0594\n",
      "[9/25][44/79] Loss_D: 0.3704 Loss_G: 3.8097 D(x): 0.8968 D(G(z)): 0.2145 / 0.0275\n",
      "[9/25][45/79] Loss_D: 0.3720 Loss_G: 2.7915 D(x): 0.7690 D(G(z)): 0.0779 / 0.0737\n",
      "[9/25][46/79] Loss_D: 0.3380 Loss_G: 4.4337 D(x): 0.9513 D(G(z)): 0.2344 / 0.0153\n",
      "[9/25][47/79] Loss_D: 0.3899 Loss_G: 3.5498 D(x): 0.7669 D(G(z)): 0.0477 / 0.0384\n",
      "[9/25][48/79] Loss_D: 0.2083 Loss_G: 3.0142 D(x): 0.8851 D(G(z)): 0.0754 / 0.0617\n",
      "[9/25][49/79] Loss_D: 0.3374 Loss_G: 4.3651 D(x): 0.9210 D(G(z)): 0.2103 / 0.0159\n",
      "[9/25][50/79] Loss_D: 0.3756 Loss_G: 3.4283 D(x): 0.7815 D(G(z)): 0.0967 / 0.0404\n",
      "[9/25][51/79] Loss_D: 0.4402 Loss_G: 4.1728 D(x): 0.8386 D(G(z)): 0.2149 / 0.0190\n",
      "[9/25][52/79] Loss_D: 0.2456 Loss_G: 5.0758 D(x): 0.9156 D(G(z)): 0.1389 / 0.0084\n",
      "[9/25][53/79] Loss_D: 0.3822 Loss_G: 3.2351 D(x): 0.7491 D(G(z)): 0.0603 / 0.0434\n",
      "[9/25][54/79] Loss_D: 0.2664 Loss_G: 3.5838 D(x): 0.8973 D(G(z)): 0.1374 / 0.0351\n",
      "[9/25][55/79] Loss_D: 0.2741 Loss_G: 6.0462 D(x): 0.9607 D(G(z)): 0.2000 / 0.0031\n",
      "[9/25][56/79] Loss_D: 1.1614 Loss_G: 1.6781 D(x): 0.3964 D(G(z)): 0.0164 / 0.2559\n",
      "[9/25][57/79] Loss_D: 0.6847 Loss_G: 5.9866 D(x): 0.9926 D(G(z)): 0.4229 / 0.0060\n",
      "[9/25][58/79] Loss_D: 0.1987 Loss_G: 6.4533 D(x): 0.8721 D(G(z)): 0.0177 / 0.0031\n",
      "[9/25][59/79] Loss_D: 0.1942 Loss_G: 4.8942 D(x): 0.8566 D(G(z)): 0.0134 / 0.0160\n",
      "[9/25][60/79] Loss_D: 0.1316 Loss_G: 3.9846 D(x): 0.9546 D(G(z)): 0.0645 / 0.0388\n",
      "[9/25][61/79] Loss_D: 0.2672 Loss_G: 4.7233 D(x): 0.9612 D(G(z)): 0.1758 / 0.0170\n",
      "[9/25][62/79] Loss_D: 0.4645 Loss_G: 3.7007 D(x): 0.7716 D(G(z)): 0.0809 / 0.0405\n",
      "[9/25][63/79] Loss_D: 0.2867 Loss_G: 4.5028 D(x): 0.9452 D(G(z)): 0.1885 / 0.0188\n",
      "[9/25][64/79] Loss_D: 0.1381 Loss_G: 4.7894 D(x): 0.9306 D(G(z)): 0.0586 / 0.0152\n",
      "[9/25][65/79] Loss_D: 0.1840 Loss_G: 4.2064 D(x): 0.9149 D(G(z)): 0.0774 / 0.0208\n",
      "[9/25][66/79] Loss_D: 0.3452 Loss_G: 3.8441 D(x): 0.8650 D(G(z)): 0.1203 / 0.0294\n",
      "[9/25][67/79] Loss_D: 0.5087 Loss_G: 4.1461 D(x): 0.8299 D(G(z)): 0.2041 / 0.0267\n",
      "[9/25][68/79] Loss_D: 0.5198 Loss_G: 3.9393 D(x): 0.7775 D(G(z)): 0.1657 / 0.0336\n",
      "[9/25][69/79] Loss_D: 0.6193 Loss_G: 3.8177 D(x): 0.7482 D(G(z)): 0.1948 / 0.0307\n",
      "[9/25][70/79] Loss_D: 0.2758 Loss_G: 4.5894 D(x): 0.9055 D(G(z)): 0.1361 / 0.0145\n",
      "[9/25][71/79] Loss_D: 0.2043 Loss_G: 4.3850 D(x): 0.9120 D(G(z)): 0.0883 / 0.0165\n",
      "[9/25][72/79] Loss_D: 0.3258 Loss_G: 3.9012 D(x): 0.8619 D(G(z)): 0.0956 / 0.0320\n",
      "[9/25][73/79] Loss_D: 0.3823 Loss_G: 2.8207 D(x): 0.7980 D(G(z)): 0.0992 / 0.0847\n",
      "[9/25][74/79] Loss_D: 0.5480 Loss_G: 6.2605 D(x): 0.9421 D(G(z)): 0.3463 / 0.0029\n",
      "[9/25][75/79] Loss_D: 0.3599 Loss_G: 4.7881 D(x): 0.7419 D(G(z)): 0.0184 / 0.0160\n",
      "[9/25][76/79] Loss_D: 0.2806 Loss_G: 3.4073 D(x): 0.8687 D(G(z)): 0.0730 / 0.0607\n",
      "[9/25][77/79] Loss_D: 0.5317 Loss_G: 6.0713 D(x): 0.9426 D(G(z)): 0.3245 / 0.0039\n",
      "[9/25][78/79] Loss_D: 0.9165 Loss_G: 2.0800 D(x): 0.5019 D(G(z)): 0.0145 / 0.2245\n",
      "[10/25][0/79] Loss_D: 1.0179 Loss_G: 5.9758 D(x): 0.9180 D(G(z)): 0.4545 / 0.0077\n",
      "[10/25][1/79] Loss_D: 0.2907 Loss_G: 5.4748 D(x): 0.8310 D(G(z)): 0.0592 / 0.0096\n",
      "[10/25][2/79] Loss_D: 0.2805 Loss_G: 3.8963 D(x): 0.8206 D(G(z)): 0.0368 / 0.0408\n",
      "[10/25][3/79] Loss_D: 0.3028 Loss_G: 4.0188 D(x): 0.9310 D(G(z)): 0.1775 / 0.0288\n",
      "[10/25][4/79] Loss_D: 0.3668 Loss_G: 5.2905 D(x): 0.9148 D(G(z)): 0.1943 / 0.0100\n",
      "[10/25][5/79] Loss_D: 0.2408 Loss_G: 4.6087 D(x): 0.8492 D(G(z)): 0.0601 / 0.0154\n",
      "[10/25][6/79] Loss_D: 0.2652 Loss_G: 4.1808 D(x): 0.8929 D(G(z)): 0.1243 / 0.0228\n",
      "[10/25][7/79] Loss_D: 0.4195 Loss_G: 3.8826 D(x): 0.8174 D(G(z)): 0.1513 / 0.0285\n",
      "[10/25][8/79] Loss_D: 0.4900 Loss_G: 4.1466 D(x): 0.8109 D(G(z)): 0.1733 / 0.0219\n",
      "[10/25][9/79] Loss_D: 0.2377 Loss_G: 4.4876 D(x): 0.8910 D(G(z)): 0.1039 / 0.0156\n",
      "[10/25][10/79] Loss_D: 0.2826 Loss_G: 3.6193 D(x): 0.8461 D(G(z)): 0.0676 / 0.0364\n",
      "[10/25][11/79] Loss_D: 0.4464 Loss_G: 5.2358 D(x): 0.8763 D(G(z)): 0.2327 / 0.0083\n",
      "[10/25][12/79] Loss_D: 0.2735 Loss_G: 4.5124 D(x): 0.8355 D(G(z)): 0.0560 / 0.0215\n",
      "[10/25][13/79] Loss_D: 0.2159 Loss_G: 4.8176 D(x): 0.9474 D(G(z)): 0.1309 / 0.0123\n",
      "[10/25][14/79] Loss_D: 0.2698 Loss_G: 3.5146 D(x): 0.8288 D(G(z)): 0.0507 / 0.0397\n",
      "[10/25][15/79] Loss_D: 0.3646 Loss_G: 5.5994 D(x): 0.9612 D(G(z)): 0.2537 / 0.0052\n",
      "[10/25][16/79] Loss_D: 1.0404 Loss_G: 1.4692 D(x): 0.4476 D(G(z)): 0.0212 / 0.3204\n",
      "[10/25][17/79] Loss_D: 1.5189 Loss_G: 8.0636 D(x): 0.9846 D(G(z)): 0.7033 / 0.0005\n",
      "[10/25][18/79] Loss_D: 0.6797 Loss_G: 5.9513 D(x): 0.5669 D(G(z)): 0.0022 / 0.0047\n",
      "[10/25][19/79] Loss_D: 0.3167 Loss_G: 2.0818 D(x): 0.7991 D(G(z)): 0.0382 / 0.1832\n",
      "[10/25][20/79] Loss_D: 1.1158 Loss_G: 10.1324 D(x): 0.9765 D(G(z)): 0.5919 / 0.0001\n",
      "[10/25][21/79] Loss_D: 1.4186 Loss_G: 5.5072 D(x): 0.3685 D(G(z)): 0.0005 / 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][22/79] Loss_D: 0.3471 Loss_G: 2.3882 D(x): 0.8555 D(G(z)): 0.0997 / 0.1996\n",
      "[10/25][23/79] Loss_D: 1.5870 Loss_G: 7.6698 D(x): 0.9349 D(G(z)): 0.6791 / 0.0019\n",
      "[10/25][24/79] Loss_D: 1.9416 Loss_G: 2.6903 D(x): 0.2699 D(G(z)): 0.0238 / 0.1454\n",
      "[10/25][25/79] Loss_D: 1.1014 Loss_G: 5.6235 D(x): 0.8664 D(G(z)): 0.4840 / 0.0079\n",
      "[10/25][26/79] Loss_D: 0.3788 Loss_G: 5.3006 D(x): 0.7794 D(G(z)): 0.0655 / 0.0086\n",
      "[10/25][27/79] Loss_D: 0.3773 Loss_G: 3.5759 D(x): 0.7723 D(G(z)): 0.0762 / 0.0448\n",
      "[10/25][28/79] Loss_D: 0.3464 Loss_G: 4.3708 D(x): 0.9457 D(G(z)): 0.2235 / 0.0201\n",
      "[10/25][29/79] Loss_D: 0.8680 Loss_G: 3.3371 D(x): 0.6132 D(G(z)): 0.1947 / 0.0497\n",
      "[10/25][30/79] Loss_D: 0.5462 Loss_G: 5.9691 D(x): 0.9241 D(G(z)): 0.3360 / 0.0034\n",
      "[10/25][31/79] Loss_D: 0.5289 Loss_G: 4.4807 D(x): 0.6394 D(G(z)): 0.0260 / 0.0167\n",
      "[10/25][32/79] Loss_D: 0.1623 Loss_G: 3.7689 D(x): 0.9203 D(G(z)): 0.0653 / 0.0384\n",
      "[10/25][33/79] Loss_D: 0.2461 Loss_G: 3.9644 D(x): 0.9453 D(G(z)): 0.1589 / 0.0256\n",
      "[10/25][34/79] Loss_D: 0.3201 Loss_G: 3.9631 D(x): 0.8555 D(G(z)): 0.1148 / 0.0273\n",
      "[10/25][35/79] Loss_D: 0.2815 Loss_G: 4.2687 D(x): 0.9090 D(G(z)): 0.1568 / 0.0196\n",
      "[10/25][36/79] Loss_D: 0.2243 Loss_G: 4.1082 D(x): 0.8958 D(G(z)): 0.0812 / 0.0220\n",
      "[10/25][37/79] Loss_D: 0.4482 Loss_G: 3.1833 D(x): 0.7898 D(G(z)): 0.1502 / 0.0569\n",
      "[10/25][38/79] Loss_D: 0.3083 Loss_G: 4.2974 D(x): 0.9365 D(G(z)): 0.1834 / 0.0187\n",
      "[10/25][39/79] Loss_D: 0.4086 Loss_G: 3.4344 D(x): 0.7655 D(G(z)): 0.0614 / 0.0494\n",
      "[10/25][40/79] Loss_D: 0.2930 Loss_G: 3.8895 D(x): 0.9293 D(G(z)): 0.1775 / 0.0277\n",
      "[10/25][41/79] Loss_D: 0.3280 Loss_G: 4.3025 D(x): 0.8733 D(G(z)): 0.1583 / 0.0181\n",
      "[10/25][42/79] Loss_D: 0.3477 Loss_G: 3.6309 D(x): 0.8279 D(G(z)): 0.0720 / 0.0367\n",
      "[10/25][43/79] Loss_D: 0.3330 Loss_G: 4.9451 D(x): 0.9740 D(G(z)): 0.2396 / 0.0105\n",
      "[10/25][44/79] Loss_D: 0.4479 Loss_G: 4.0865 D(x): 0.7541 D(G(z)): 0.0855 / 0.0264\n",
      "[10/25][45/79] Loss_D: 0.7852 Loss_G: 4.8972 D(x): 0.7493 D(G(z)): 0.3283 / 0.0121\n",
      "[10/25][46/79] Loss_D: 0.3833 Loss_G: 5.6890 D(x): 0.8625 D(G(z)): 0.1656 / 0.0063\n",
      "[10/25][47/79] Loss_D: 0.7159 Loss_G: 3.3293 D(x): 0.6107 D(G(z)): 0.0510 / 0.0572\n",
      "[10/25][48/79] Loss_D: 0.6115 Loss_G: 4.5587 D(x): 0.8626 D(G(z)): 0.3237 / 0.0158\n",
      "[10/25][49/79] Loss_D: 0.1856 Loss_G: 5.1311 D(x): 0.8970 D(G(z)): 0.0404 / 0.0092\n",
      "[10/25][50/79] Loss_D: 0.1309 Loss_G: 4.3601 D(x): 0.9269 D(G(z)): 0.0431 / 0.0206\n",
      "[10/25][51/79] Loss_D: 0.1712 Loss_G: 3.6769 D(x): 0.9268 D(G(z)): 0.0816 / 0.0321\n",
      "[10/25][52/79] Loss_D: 0.3675 Loss_G: 4.1829 D(x): 0.8881 D(G(z)): 0.1906 / 0.0232\n",
      "[10/25][53/79] Loss_D: 0.3683 Loss_G: 4.0666 D(x): 0.8345 D(G(z)): 0.1455 / 0.0229\n",
      "[10/25][54/79] Loss_D: 0.3021 Loss_G: 3.4574 D(x): 0.8163 D(G(z)): 0.0761 / 0.0476\n",
      "[10/25][55/79] Loss_D: 0.5600 Loss_G: 4.9385 D(x): 0.8688 D(G(z)): 0.3036 / 0.0101\n",
      "[10/25][56/79] Loss_D: 0.4817 Loss_G: 3.5316 D(x): 0.7169 D(G(z)): 0.0986 / 0.0472\n",
      "[10/25][57/79] Loss_D: 0.3948 Loss_G: 3.2875 D(x): 0.8204 D(G(z)): 0.1517 / 0.0588\n",
      "[10/25][58/79] Loss_D: 0.6933 Loss_G: 4.4458 D(x): 0.8260 D(G(z)): 0.3306 / 0.0199\n",
      "[10/25][59/79] Loss_D: 0.3613 Loss_G: 4.5216 D(x): 0.8612 D(G(z)): 0.1247 / 0.0184\n",
      "[10/25][60/79] Loss_D: 0.4950 Loss_G: 2.8423 D(x): 0.6940 D(G(z)): 0.0674 / 0.0792\n",
      "[10/25][61/79] Loss_D: 0.4816 Loss_G: 3.8987 D(x): 0.9242 D(G(z)): 0.2951 / 0.0307\n",
      "[10/25][62/79] Loss_D: 0.7853 Loss_G: 3.8848 D(x): 0.7102 D(G(z)): 0.2667 / 0.0359\n",
      "[10/25][63/79] Loss_D: 0.5442 Loss_G: 3.2413 D(x): 0.7511 D(G(z)): 0.1540 / 0.0531\n",
      "[10/25][64/79] Loss_D: 1.1821 Loss_G: 2.9147 D(x): 0.5963 D(G(z)): 0.3701 / 0.0750\n",
      "[10/25][65/79] Loss_D: 0.9667 Loss_G: 4.3190 D(x): 0.7361 D(G(z)): 0.4040 / 0.0193\n",
      "[10/25][66/79] Loss_D: 0.8358 Loss_G: 1.6405 D(x): 0.5364 D(G(z)): 0.0740 / 0.2838\n",
      "[10/25][67/79] Loss_D: 0.9187 Loss_G: 4.7576 D(x): 0.9271 D(G(z)): 0.4906 / 0.0147\n",
      "[10/25][68/79] Loss_D: 0.3916 Loss_G: 4.1921 D(x): 0.7625 D(G(z)): 0.0516 / 0.0278\n",
      "[10/25][69/79] Loss_D: 0.2563 Loss_G: 3.3514 D(x): 0.8785 D(G(z)): 0.1007 / 0.0567\n",
      "[10/25][70/79] Loss_D: 0.3101 Loss_G: 3.9103 D(x): 0.9168 D(G(z)): 0.1767 / 0.0358\n",
      "[10/25][71/79] Loss_D: 0.2336 Loss_G: 4.2343 D(x): 0.9058 D(G(z)): 0.1094 / 0.0277\n",
      "[10/25][72/79] Loss_D: 0.4236 Loss_G: 3.0834 D(x): 0.7964 D(G(z)): 0.1349 / 0.0747\n",
      "[10/25][73/79] Loss_D: 0.6184 Loss_G: 4.9782 D(x): 0.8486 D(G(z)): 0.3006 / 0.0124\n",
      "[10/25][74/79] Loss_D: 0.3511 Loss_G: 3.7447 D(x): 0.8054 D(G(z)): 0.0871 / 0.0392\n",
      "[10/25][75/79] Loss_D: 0.4498 Loss_G: 3.2991 D(x): 0.8237 D(G(z)): 0.1754 / 0.0521\n",
      "[10/25][76/79] Loss_D: 0.7894 Loss_G: 2.9684 D(x): 0.6951 D(G(z)): 0.2267 / 0.0889\n",
      "[10/25][77/79] Loss_D: 0.6842 Loss_G: 7.4340 D(x): 0.8997 D(G(z)): 0.3653 / 0.0013\n",
      "[10/25][78/79] Loss_D: 1.7467 Loss_G: 0.3565 D(x): 0.2846 D(G(z)): 0.0060 / 0.7373\n",
      "[11/25][0/79] Loss_D: 2.4159 Loss_G: 9.6519 D(x): 0.9058 D(G(z)): 0.7572 / 0.0002\n",
      "[11/25][1/79] Loss_D: 5.2216 Loss_G: 5.5293 D(x): 0.0128 D(G(z)): 0.0003 / 0.0165\n",
      "[11/25][2/79] Loss_D: 0.8296 Loss_G: 0.7966 D(x): 0.5460 D(G(z)): 0.0569 / 0.5304\n",
      "[11/25][3/79] Loss_D: 1.8938 Loss_G: 3.4006 D(x): 0.9287 D(G(z)): 0.7384 / 0.0612\n",
      "[11/25][4/79] Loss_D: 0.4506 Loss_G: 4.4292 D(x): 0.8384 D(G(z)): 0.1999 / 0.0188\n",
      "[11/25][5/79] Loss_D: 0.6512 Loss_G: 3.1201 D(x): 0.6834 D(G(z)): 0.1449 / 0.0727\n",
      "[11/25][6/79] Loss_D: 0.4923 Loss_G: 2.9335 D(x): 0.8323 D(G(z)): 0.2250 / 0.0774\n",
      "[11/25][7/79] Loss_D: 0.6499 Loss_G: 2.7688 D(x): 0.7640 D(G(z)): 0.2501 / 0.0863\n",
      "[11/25][8/79] Loss_D: 0.9198 Loss_G: 3.1314 D(x): 0.6986 D(G(z)): 0.3684 / 0.0547\n",
      "[11/25][9/79] Loss_D: 0.7378 Loss_G: 2.6296 D(x): 0.6477 D(G(z)): 0.2087 / 0.0831\n",
      "[11/25][10/79] Loss_D: 0.7886 Loss_G: 1.8441 D(x): 0.6044 D(G(z)): 0.1819 / 0.1897\n",
      "[11/25][11/79] Loss_D: 0.4511 Loss_G: 3.4665 D(x): 0.9287 D(G(z)): 0.2901 / 0.0400\n",
      "[11/25][12/79] Loss_D: 0.2967 Loss_G: 3.7186 D(x): 0.8921 D(G(z)): 0.1537 / 0.0316\n",
      "[11/25][13/79] Loss_D: 0.2711 Loss_G: 3.7244 D(x): 0.8852 D(G(z)): 0.1264 / 0.0313\n",
      "[11/25][14/79] Loss_D: 1.2080 Loss_G: 5.2213 D(x): 0.8147 D(G(z)): 0.5824 / 0.0084\n",
      "[11/25][15/79] Loss_D: 1.4131 Loss_G: 2.1893 D(x): 0.3640 D(G(z)): 0.0847 / 0.1339\n",
      "[11/25][16/79] Loss_D: 0.9254 Loss_G: 3.7243 D(x): 0.8478 D(G(z)): 0.4849 / 0.0361\n",
      "[11/25][17/79] Loss_D: 0.7511 Loss_G: 3.1416 D(x): 0.6061 D(G(z)): 0.1448 / 0.0604\n",
      "[11/25][18/79] Loss_D: 0.4286 Loss_G: 3.0611 D(x): 0.8058 D(G(z)): 0.1613 / 0.0666\n",
      "[11/25][19/79] Loss_D: 0.3770 Loss_G: 3.6726 D(x): 0.9026 D(G(z)): 0.2185 / 0.0364\n",
      "[11/25][20/79] Loss_D: 0.2105 Loss_G: 3.9212 D(x): 0.9216 D(G(z)): 0.1138 / 0.0283\n",
      "[11/25][21/79] Loss_D: 0.3019 Loss_G: 3.6018 D(x): 0.8955 D(G(z)): 0.1488 / 0.0410\n",
      "[11/25][22/79] Loss_D: 0.3911 Loss_G: 3.0473 D(x): 0.8174 D(G(z)): 0.1419 / 0.0649\n",
      "[11/25][23/79] Loss_D: 0.5616 Loss_G: 2.7174 D(x): 0.7829 D(G(z)): 0.2123 / 0.0959\n",
      "[11/25][24/79] Loss_D: 0.7523 Loss_G: 2.3717 D(x): 0.6962 D(G(z)): 0.2524 / 0.1157\n",
      "[11/25][25/79] Loss_D: 0.4896 Loss_G: 3.8708 D(x): 0.8607 D(G(z)): 0.2655 / 0.0273\n",
      "[11/25][26/79] Loss_D: 0.8036 Loss_G: 1.4901 D(x): 0.5686 D(G(z)): 0.0805 / 0.2751\n",
      "[11/25][27/79] Loss_D: 0.8672 Loss_G: 5.6754 D(x): 0.9817 D(G(z)): 0.5413 / 0.0045\n",
      "[11/25][28/79] Loss_D: 0.7606 Loss_G: 3.5381 D(x): 0.5370 D(G(z)): 0.0200 / 0.0484\n",
      "[11/25][29/79] Loss_D: 0.3646 Loss_G: 2.4061 D(x): 0.8440 D(G(z)): 0.1530 / 0.1159\n",
      "[11/25][30/79] Loss_D: 0.6959 Loss_G: 3.9799 D(x): 0.8305 D(G(z)): 0.3378 / 0.0278\n",
      "[11/25][31/79] Loss_D: 0.3532 Loss_G: 3.2222 D(x): 0.7867 D(G(z)): 0.0753 / 0.0608\n",
      "[11/25][32/79] Loss_D: 0.3310 Loss_G: 3.2026 D(x): 0.8881 D(G(z)): 0.1719 / 0.0552\n",
      "[11/25][33/79] Loss_D: 0.3961 Loss_G: 2.8487 D(x): 0.8212 D(G(z)): 0.1597 / 0.0714\n",
      "[11/25][34/79] Loss_D: 0.5096 Loss_G: 2.9285 D(x): 0.8020 D(G(z)): 0.2131 / 0.0657\n",
      "[11/25][35/79] Loss_D: 0.4802 Loss_G: 3.2412 D(x): 0.8221 D(G(z)): 0.2250 / 0.0517\n",
      "[11/25][36/79] Loss_D: 0.8701 Loss_G: 0.8094 D(x): 0.5349 D(G(z)): 0.1154 / 0.4835\n",
      "[11/25][37/79] Loss_D: 1.3043 Loss_G: 5.6543 D(x): 0.9150 D(G(z)): 0.6474 / 0.0054\n",
      "[11/25][38/79] Loss_D: 0.8076 Loss_G: 4.0924 D(x): 0.5057 D(G(z)): 0.0120 / 0.0270\n",
      "[11/25][39/79] Loss_D: 0.8324 Loss_G: 0.9464 D(x): 0.5402 D(G(z)): 0.0872 / 0.4592\n",
      "[11/25][40/79] Loss_D: 1.4735 Loss_G: 4.2710 D(x): 0.9885 D(G(z)): 0.7061 / 0.0225\n",
      "[11/25][41/79] Loss_D: 0.2890 Loss_G: 4.6226 D(x): 0.8286 D(G(z)): 0.0516 / 0.0154\n",
      "[11/25][42/79] Loss_D: 0.4075 Loss_G: 2.6366 D(x): 0.7376 D(G(z)): 0.0558 / 0.1154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][43/79] Loss_D: 0.2977 Loss_G: 2.8409 D(x): 0.9486 D(G(z)): 0.1920 / 0.0839\n",
      "[11/25][44/79] Loss_D: 0.4054 Loss_G: 3.6213 D(x): 0.8943 D(G(z)): 0.2229 / 0.0415\n",
      "[11/25][45/79] Loss_D: 0.4292 Loss_G: 2.6461 D(x): 0.7565 D(G(z)): 0.0969 / 0.0951\n",
      "[11/25][46/79] Loss_D: 0.5166 Loss_G: 2.7658 D(x): 0.8174 D(G(z)): 0.2210 / 0.0887\n",
      "[11/25][47/79] Loss_D: 0.5495 Loss_G: 3.7212 D(x): 0.8356 D(G(z)): 0.2710 / 0.0367\n",
      "[11/25][48/79] Loss_D: 0.6794 Loss_G: 1.5912 D(x): 0.5942 D(G(z)): 0.0630 / 0.2501\n",
      "[11/25][49/79] Loss_D: 1.0312 Loss_G: 5.0606 D(x): 0.9109 D(G(z)): 0.5570 / 0.0102\n",
      "[11/25][50/79] Loss_D: 1.4639 Loss_G: 1.9650 D(x): 0.3281 D(G(z)): 0.0193 / 0.1996\n",
      "[11/25][51/79] Loss_D: 0.6873 Loss_G: 2.7703 D(x): 0.9015 D(G(z)): 0.3954 / 0.0931\n",
      "[11/25][52/79] Loss_D: 0.3654 Loss_G: 3.6968 D(x): 0.8696 D(G(z)): 0.1795 / 0.0357\n",
      "[11/25][53/79] Loss_D: 0.4547 Loss_G: 2.4243 D(x): 0.7305 D(G(z)): 0.0794 / 0.1180\n",
      "[11/25][54/79] Loss_D: 0.2431 Loss_G: 2.8003 D(x): 0.9276 D(G(z)): 0.1443 / 0.0791\n",
      "[11/25][55/79] Loss_D: 0.3238 Loss_G: 2.9373 D(x): 0.8835 D(G(z)): 0.1687 / 0.0691\n",
      "[11/25][56/79] Loss_D: 0.4491 Loss_G: 3.6255 D(x): 0.8636 D(G(z)): 0.2411 / 0.0352\n",
      "[11/25][57/79] Loss_D: 0.6835 Loss_G: 1.4001 D(x): 0.5898 D(G(z)): 0.0752 / 0.3015\n",
      "[11/25][58/79] Loss_D: 1.1525 Loss_G: 5.3777 D(x): 0.9554 D(G(z)): 0.6219 / 0.0071\n",
      "[11/25][59/79] Loss_D: 0.8264 Loss_G: 3.6712 D(x): 0.5139 D(G(z)): 0.0167 / 0.0461\n",
      "[11/25][60/79] Loss_D: 0.6437 Loss_G: 1.1463 D(x): 0.6617 D(G(z)): 0.1347 / 0.3766\n",
      "[11/25][61/79] Loss_D: 1.0676 Loss_G: 5.1558 D(x): 0.9794 D(G(z)): 0.5875 / 0.0089\n",
      "[11/25][62/79] Loss_D: 0.5179 Loss_G: 4.5811 D(x): 0.6557 D(G(z)): 0.0210 / 0.0153\n",
      "[11/25][63/79] Loss_D: 0.3383 Loss_G: 2.4148 D(x): 0.7764 D(G(z)): 0.0504 / 0.1122\n",
      "[11/25][64/79] Loss_D: 0.2750 Loss_G: 3.0394 D(x): 0.9398 D(G(z)): 0.1801 / 0.0608\n",
      "[11/25][65/79] Loss_D: 0.1993 Loss_G: 3.7832 D(x): 0.9473 D(G(z)): 0.1299 / 0.0310\n",
      "[11/25][66/79] Loss_D: 0.1618 Loss_G: 3.8753 D(x): 0.9290 D(G(z)): 0.0790 / 0.0293\n",
      "[11/25][67/79] Loss_D: 0.3651 Loss_G: 2.3927 D(x): 0.7739 D(G(z)): 0.0791 / 0.1149\n",
      "[11/25][68/79] Loss_D: 0.3876 Loss_G: 3.6275 D(x): 0.9431 D(G(z)): 0.2605 / 0.0373\n",
      "[11/25][69/79] Loss_D: 0.3497 Loss_G: 3.2030 D(x): 0.8058 D(G(z)): 0.0944 / 0.0579\n",
      "[11/25][70/79] Loss_D: 0.2336 Loss_G: 3.3592 D(x): 0.9257 D(G(z)): 0.1343 / 0.0467\n",
      "[11/25][71/79] Loss_D: 0.3340 Loss_G: 2.7988 D(x): 0.8302 D(G(z)): 0.1139 / 0.0791\n",
      "[11/25][72/79] Loss_D: 0.5343 Loss_G: 2.8587 D(x): 0.7718 D(G(z)): 0.1925 / 0.0806\n",
      "[11/25][73/79] Loss_D: 0.7323 Loss_G: 2.7318 D(x): 0.7187 D(G(z)): 0.2839 / 0.0898\n",
      "[11/25][74/79] Loss_D: 0.4587 Loss_G: 3.6348 D(x): 0.8246 D(G(z)): 0.2037 / 0.0335\n",
      "[11/25][75/79] Loss_D: 0.5147 Loss_G: 2.5179 D(x): 0.7281 D(G(z)): 0.1344 / 0.1046\n",
      "[11/25][76/79] Loss_D: 0.4476 Loss_G: 2.9391 D(x): 0.8299 D(G(z)): 0.2057 / 0.0619\n",
      "[11/25][77/79] Loss_D: 0.4826 Loss_G: 4.4118 D(x): 0.8747 D(G(z)): 0.2751 / 0.0158\n",
      "[11/25][78/79] Loss_D: 0.5515 Loss_G: 2.2856 D(x): 0.6395 D(G(z)): 0.0612 / 0.1583\n",
      "[12/25][0/79] Loss_D: 1.2519 Loss_G: 5.8811 D(x): 0.9611 D(G(z)): 0.6338 / 0.0043\n",
      "[12/25][1/79] Loss_D: 0.8297 Loss_G: 1.3086 D(x): 0.5086 D(G(z)): 0.0140 / 0.3523\n",
      "[12/25][2/79] Loss_D: 0.7860 Loss_G: 6.3748 D(x): 0.9222 D(G(z)): 0.4425 / 0.0024\n",
      "[12/25][3/79] Loss_D: 1.0956 Loss_G: 1.6766 D(x): 0.4146 D(G(z)): 0.0259 / 0.2597\n",
      "[12/25][4/79] Loss_D: 1.0441 Loss_G: 5.4544 D(x): 0.9435 D(G(z)): 0.5480 / 0.0078\n",
      "[12/25][5/79] Loss_D: 0.4754 Loss_G: 4.3432 D(x): 0.6848 D(G(z)): 0.0374 / 0.0268\n",
      "[12/25][6/79] Loss_D: 0.3257 Loss_G: 4.0153 D(x): 0.9231 D(G(z)): 0.1955 / 0.0273\n",
      "[12/25][7/79] Loss_D: 0.7061 Loss_G: 2.0340 D(x): 0.6164 D(G(z)): 0.1326 / 0.1561\n",
      "[12/25][8/79] Loss_D: 0.9615 Loss_G: 5.4541 D(x): 0.7970 D(G(z)): 0.4658 / 0.0065\n",
      "[12/25][9/79] Loss_D: 0.8155 Loss_G: 2.8216 D(x): 0.5260 D(G(z)): 0.0383 / 0.0982\n",
      "[12/25][10/79] Loss_D: 0.4654 Loss_G: 2.1348 D(x): 0.7927 D(G(z)): 0.1777 / 0.1451\n",
      "[12/25][11/79] Loss_D: 0.8154 Loss_G: 4.9704 D(x): 0.9336 D(G(z)): 0.4828 / 0.0099\n",
      "[12/25][12/79] Loss_D: 0.6461 Loss_G: 3.1576 D(x): 0.5919 D(G(z)): 0.0216 / 0.0676\n",
      "[12/25][13/79] Loss_D: 0.4527 Loss_G: 3.6920 D(x): 0.9029 D(G(z)): 0.2624 / 0.0350\n",
      "[12/25][14/79] Loss_D: 0.2685 Loss_G: 4.0084 D(x): 0.9267 D(G(z)): 0.1643 / 0.0276\n",
      "[12/25][15/79] Loss_D: 0.5908 Loss_G: 2.6201 D(x): 0.7061 D(G(z)): 0.1678 / 0.1009\n",
      "[12/25][16/79] Loss_D: 0.7137 Loss_G: 3.5976 D(x): 0.8203 D(G(z)): 0.3515 / 0.0409\n",
      "[12/25][17/79] Loss_D: 0.6075 Loss_G: 3.5672 D(x): 0.7598 D(G(z)): 0.2244 / 0.0449\n",
      "[12/25][18/79] Loss_D: 0.6661 Loss_G: 2.3397 D(x): 0.6704 D(G(z)): 0.1612 / 0.1353\n",
      "[12/25][19/79] Loss_D: 0.4152 Loss_G: 3.9526 D(x): 0.9333 D(G(z)): 0.2680 / 0.0268\n",
      "[12/25][20/79] Loss_D: 0.4081 Loss_G: 3.4963 D(x): 0.7504 D(G(z)): 0.0778 / 0.0453\n",
      "[12/25][21/79] Loss_D: 0.7037 Loss_G: 1.8130 D(x): 0.6468 D(G(z)): 0.1737 / 0.2154\n",
      "[12/25][22/79] Loss_D: 1.0037 Loss_G: 5.0267 D(x): 0.8447 D(G(z)): 0.5088 / 0.0093\n",
      "[12/25][23/79] Loss_D: 0.6507 Loss_G: 3.7824 D(x): 0.5889 D(G(z)): 0.0241 / 0.0326\n",
      "[12/25][24/79] Loss_D: 0.1835 Loss_G: 2.8364 D(x): 0.9041 D(G(z)): 0.0722 / 0.0774\n",
      "[12/25][25/79] Loss_D: 0.3900 Loss_G: 3.6996 D(x): 0.9399 D(G(z)): 0.2495 / 0.0338\n",
      "[12/25][26/79] Loss_D: 0.1347 Loss_G: 4.6373 D(x): 0.9848 D(G(z)): 0.1051 / 0.0145\n",
      "[12/25][27/79] Loss_D: 0.2525 Loss_G: 3.6935 D(x): 0.8356 D(G(z)): 0.0502 / 0.0331\n",
      "[12/25][28/79] Loss_D: 0.2491 Loss_G: 2.8384 D(x): 0.8380 D(G(z)): 0.0571 / 0.0811\n",
      "[12/25][29/79] Loss_D: 0.3726 Loss_G: 3.3261 D(x): 0.8791 D(G(z)): 0.1942 / 0.0484\n",
      "[12/25][30/79] Loss_D: 0.5050 Loss_G: 5.0264 D(x): 0.9035 D(G(z)): 0.2860 / 0.0096\n",
      "[12/25][31/79] Loss_D: 0.5310 Loss_G: 3.0668 D(x): 0.6407 D(G(z)): 0.0148 / 0.0716\n",
      "[12/25][32/79] Loss_D: 0.2359 Loss_G: 3.6192 D(x): 0.9717 D(G(z)): 0.1742 / 0.0358\n",
      "[12/25][33/79] Loss_D: 0.2761 Loss_G: 3.8396 D(x): 0.8906 D(G(z)): 0.1344 / 0.0280\n",
      "[12/25][34/79] Loss_D: 0.1154 Loss_G: 4.5516 D(x): 0.9388 D(G(z)): 0.0471 / 0.0167\n",
      "[12/25][35/79] Loss_D: 0.2855 Loss_G: 2.8653 D(x): 0.8102 D(G(z)): 0.0444 / 0.0791\n",
      "[12/25][36/79] Loss_D: 0.2581 Loss_G: 3.4428 D(x): 0.9173 D(G(z)): 0.1473 / 0.0418\n",
      "[12/25][37/79] Loss_D: 0.3309 Loss_G: 4.5501 D(x): 0.9517 D(G(z)): 0.2310 / 0.0138\n",
      "[12/25][38/79] Loss_D: 0.3906 Loss_G: 3.3135 D(x): 0.7368 D(G(z)): 0.0355 / 0.0537\n",
      "[12/25][39/79] Loss_D: 0.4478 Loss_G: 3.2432 D(x): 0.7898 D(G(z)): 0.1419 / 0.0523\n",
      "[12/25][40/79] Loss_D: 0.3254 Loss_G: 3.2529 D(x): 0.8608 D(G(z)): 0.1437 / 0.0513\n",
      "[12/25][41/79] Loss_D: 0.3126 Loss_G: 3.6627 D(x): 0.8799 D(G(z)): 0.1376 / 0.0363\n",
      "[12/25][42/79] Loss_D: 0.1961 Loss_G: 3.9611 D(x): 0.9317 D(G(z)): 0.1051 / 0.0254\n",
      "[12/25][43/79] Loss_D: 0.3166 Loss_G: 3.1427 D(x): 0.8139 D(G(z)): 0.0843 / 0.0550\n",
      "[12/25][44/79] Loss_D: 0.2346 Loss_G: 3.7369 D(x): 0.9484 D(G(z)): 0.1561 / 0.0320\n",
      "[12/25][45/79] Loss_D: 0.3034 Loss_G: 3.2522 D(x): 0.8292 D(G(z)): 0.0969 / 0.0506\n",
      "[12/25][46/79] Loss_D: 0.2677 Loss_G: 3.2821 D(x): 0.8872 D(G(z)): 0.1266 / 0.0502\n",
      "[12/25][47/79] Loss_D: 0.4294 Loss_G: 3.3204 D(x): 0.8204 D(G(z)): 0.1776 / 0.0533\n",
      "[12/25][48/79] Loss_D: 0.4470 Loss_G: 3.1651 D(x): 0.8000 D(G(z)): 0.1629 / 0.0606\n",
      "[12/25][49/79] Loss_D: 0.2892 Loss_G: 3.4287 D(x): 0.8783 D(G(z)): 0.1323 / 0.0442\n",
      "[12/25][50/79] Loss_D: 0.2278 Loss_G: 3.5853 D(x): 0.8950 D(G(z)): 0.1029 / 0.0390\n",
      "[12/25][51/79] Loss_D: 0.5689 Loss_G: 2.3896 D(x): 0.7292 D(G(z)): 0.1725 / 0.1235\n",
      "[12/25][52/79] Loss_D: 0.6856 Loss_G: 4.6744 D(x): 0.9129 D(G(z)): 0.4057 / 0.0166\n",
      "[12/25][53/79] Loss_D: 0.7086 Loss_G: 2.0274 D(x): 0.5737 D(G(z)): 0.0152 / 0.1876\n",
      "[12/25][54/79] Loss_D: 0.5802 Loss_G: 5.1914 D(x): 0.9464 D(G(z)): 0.3671 / 0.0085\n",
      "[12/25][55/79] Loss_D: 0.2606 Loss_G: 4.2912 D(x): 0.8248 D(G(z)): 0.0448 / 0.0212\n",
      "[12/25][56/79] Loss_D: 0.2447 Loss_G: 3.1503 D(x): 0.8135 D(G(z)): 0.0192 / 0.0609\n",
      "[12/25][57/79] Loss_D: 0.3019 Loss_G: 3.0741 D(x): 0.9247 D(G(z)): 0.1845 / 0.0635\n",
      "[12/25][58/79] Loss_D: 0.1847 Loss_G: 4.0001 D(x): 0.9596 D(G(z)): 0.1269 / 0.0246\n",
      "[12/25][59/79] Loss_D: 0.1675 Loss_G: 3.9950 D(x): 0.9086 D(G(z)): 0.0641 / 0.0254\n",
      "[12/25][60/79] Loss_D: 0.2145 Loss_G: 3.2713 D(x): 0.8788 D(G(z)): 0.0734 / 0.0488\n",
      "[12/25][61/79] Loss_D: 0.2766 Loss_G: 4.2326 D(x): 0.9375 D(G(z)): 0.1817 / 0.0201\n",
      "[12/25][62/79] Loss_D: 0.4449 Loss_G: 2.5828 D(x): 0.7108 D(G(z)): 0.0413 / 0.1097\n",
      "[12/25][63/79] Loss_D: 0.2545 Loss_G: 3.4649 D(x): 0.9704 D(G(z)): 0.1894 / 0.0421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][64/79] Loss_D: 0.1478 Loss_G: 5.1018 D(x): 0.9903 D(G(z)): 0.1232 / 0.0092\n",
      "[12/25][65/79] Loss_D: 0.7524 Loss_G: 1.5283 D(x): 0.5535 D(G(z)): 0.0220 / 0.2656\n",
      "[12/25][66/79] Loss_D: 0.5473 Loss_G: 2.9669 D(x): 0.9424 D(G(z)): 0.3521 / 0.0631\n",
      "[12/25][67/79] Loss_D: 0.4906 Loss_G: 7.0561 D(x): 0.9367 D(G(z)): 0.3120 / 0.0013\n",
      "[12/25][68/79] Loss_D: 1.6976 Loss_G: 0.5917 D(x): 0.2560 D(G(z)): 0.0045 / 0.6115\n",
      "[12/25][69/79] Loss_D: 1.3764 Loss_G: 2.2883 D(x): 0.9898 D(G(z)): 0.6664 / 0.1583\n",
      "[12/25][70/79] Loss_D: 0.4951 Loss_G: 2.5916 D(x): 0.8009 D(G(z)): 0.2036 / 0.1054\n",
      "[12/25][71/79] Loss_D: 0.6610 Loss_G: 4.0372 D(x): 0.7876 D(G(z)): 0.2978 / 0.0253\n",
      "[12/25][72/79] Loss_D: 1.4187 Loss_G: 0.1570 D(x): 0.3419 D(G(z)): 0.1070 / 0.8636\n",
      "[12/25][73/79] Loss_D: 2.7054 Loss_G: 7.6174 D(x): 0.9837 D(G(z)): 0.9035 / 0.0011\n",
      "[12/25][74/79] Loss_D: 1.5090 Loss_G: 4.5945 D(x): 0.2968 D(G(z)): 0.0031 / 0.0202\n",
      "[12/25][75/79] Loss_D: 0.8837 Loss_G: 0.6360 D(x): 0.5063 D(G(z)): 0.0728 / 0.5778\n",
      "[12/25][76/79] Loss_D: 2.0003 Loss_G: 3.8630 D(x): 0.9739 D(G(z)): 0.7933 / 0.0413\n",
      "[12/25][77/79] Loss_D: 0.6107 Loss_G: 3.6052 D(x): 0.6797 D(G(z)): 0.1289 / 0.0401\n",
      "[12/25][78/79] Loss_D: 0.9731 Loss_G: 1.6350 D(x): 0.5000 D(G(z)): 0.1111 / 0.2896\n",
      "[13/25][0/79] Loss_D: 1.3688 Loss_G: 2.7475 D(x): 0.8429 D(G(z)): 0.6104 / 0.0849\n",
      "[13/25][1/79] Loss_D: 1.1874 Loss_G: 2.4750 D(x): 0.5385 D(G(z)): 0.3328 / 0.1099\n",
      "[13/25][2/79] Loss_D: 0.7965 Loss_G: 1.7451 D(x): 0.6053 D(G(z)): 0.1746 / 0.2092\n",
      "[13/25][3/79] Loss_D: 0.6082 Loss_G: 2.7894 D(x): 0.8538 D(G(z)): 0.3257 / 0.0825\n",
      "[13/25][4/79] Loss_D: 0.6680 Loss_G: 3.0333 D(x): 0.7439 D(G(z)): 0.2540 / 0.0696\n",
      "[13/25][5/79] Loss_D: 0.5923 Loss_G: 2.6295 D(x): 0.7277 D(G(z)): 0.1983 / 0.1030\n",
      "[13/25][6/79] Loss_D: 0.5391 Loss_G: 3.0877 D(x): 0.8263 D(G(z)): 0.2662 / 0.0647\n",
      "[13/25][7/79] Loss_D: 0.7351 Loss_G: 2.7750 D(x): 0.6972 D(G(z)): 0.2404 / 0.0968\n",
      "[13/25][8/79] Loss_D: 0.5122 Loss_G: 4.0208 D(x): 0.8938 D(G(z)): 0.2999 / 0.0264\n",
      "[13/25][9/79] Loss_D: 0.4633 Loss_G: 3.0731 D(x): 0.7296 D(G(z)): 0.1051 / 0.0565\n",
      "[13/25][10/79] Loss_D: 0.5626 Loss_G: 2.1842 D(x): 0.7201 D(G(z)): 0.1687 / 0.1411\n",
      "[13/25][11/79] Loss_D: 0.6672 Loss_G: 3.7864 D(x): 0.7915 D(G(z)): 0.3153 / 0.0279\n",
      "[13/25][12/79] Loss_D: 0.5943 Loss_G: 2.5602 D(x): 0.6702 D(G(z)): 0.1265 / 0.0988\n",
      "[13/25][13/79] Loss_D: 0.5008 Loss_G: 3.2638 D(x): 0.8488 D(G(z)): 0.2574 / 0.0481\n",
      "[13/25][14/79] Loss_D: 0.3767 Loss_G: 3.5723 D(x): 0.8465 D(G(z)): 0.1680 / 0.0376\n",
      "[13/25][15/79] Loss_D: 0.2453 Loss_G: 3.6819 D(x): 0.8859 D(G(z)): 0.1064 / 0.0321\n",
      "[13/25][16/79] Loss_D: 0.2669 Loss_G: 3.6428 D(x): 0.9053 D(G(z)): 0.1455 / 0.0351\n",
      "[13/25][17/79] Loss_D: 0.4610 Loss_G: 2.4432 D(x): 0.7241 D(G(z)): 0.0848 / 0.1130\n",
      "[13/25][18/79] Loss_D: 0.7481 Loss_G: 4.8344 D(x): 0.9634 D(G(z)): 0.4861 / 0.0128\n",
      "[13/25][19/79] Loss_D: 1.0503 Loss_G: 1.5032 D(x): 0.4136 D(G(z)): 0.0391 / 0.2729\n",
      "[13/25][20/79] Loss_D: 0.8123 Loss_G: 4.4011 D(x): 0.8375 D(G(z)): 0.4095 / 0.0189\n",
      "[13/25][21/79] Loss_D: 0.3707 Loss_G: 2.4099 D(x): 0.7735 D(G(z)): 0.0751 / 0.1171\n",
      "[13/25][22/79] Loss_D: 0.3178 Loss_G: 4.9358 D(x): 0.9719 D(G(z)): 0.2351 / 0.0104\n",
      "[13/25][23/79] Loss_D: 0.3662 Loss_G: 2.7486 D(x): 0.7462 D(G(z)): 0.0409 / 0.0822\n",
      "[13/25][24/79] Loss_D: 0.4373 Loss_G: 3.9267 D(x): 0.9202 D(G(z)): 0.2714 / 0.0242\n",
      "[13/25][25/79] Loss_D: 0.2922 Loss_G: 3.3449 D(x): 0.7902 D(G(z)): 0.0413 / 0.0460\n",
      "[13/25][26/79] Loss_D: 0.2896 Loss_G: 3.1115 D(x): 0.8947 D(G(z)): 0.1510 / 0.0527\n",
      "[13/25][27/79] Loss_D: 0.4456 Loss_G: 3.0508 D(x): 0.7815 D(G(z)): 0.1570 / 0.0621\n",
      "[13/25][28/79] Loss_D: 0.2882 Loss_G: 3.9389 D(x): 0.9281 D(G(z)): 0.1844 / 0.0241\n",
      "[13/25][29/79] Loss_D: 0.4600 Loss_G: 2.4036 D(x): 0.6980 D(G(z)): 0.0514 / 0.1109\n",
      "[13/25][30/79] Loss_D: 0.2968 Loss_G: 3.1523 D(x): 0.9363 D(G(z)): 0.1955 / 0.0502\n",
      "[13/25][31/79] Loss_D: 0.1048 Loss_G: 4.1513 D(x): 0.9580 D(G(z)): 0.0586 / 0.0196\n",
      "[13/25][32/79] Loss_D: 0.2009 Loss_G: 3.5484 D(x): 0.8931 D(G(z)): 0.0726 / 0.0403\n",
      "[13/25][33/79] Loss_D: 0.2460 Loss_G: 3.3370 D(x): 0.9032 D(G(z)): 0.1230 / 0.0441\n",
      "[13/25][34/79] Loss_D: 0.4519 Loss_G: 3.7100 D(x): 0.8212 D(G(z)): 0.2000 / 0.0349\n",
      "[13/25][35/79] Loss_D: 0.4040 Loss_G: 2.3773 D(x): 0.7436 D(G(z)): 0.0792 / 0.1204\n",
      "[13/25][36/79] Loss_D: 0.4849 Loss_G: 3.2366 D(x): 0.8543 D(G(z)): 0.2525 / 0.0528\n",
      "[13/25][37/79] Loss_D: 0.1868 Loss_G: 4.2176 D(x): 0.9297 D(G(z)): 0.1024 / 0.0209\n",
      "[13/25][38/79] Loss_D: 0.5348 Loss_G: 1.7319 D(x): 0.6535 D(G(z)): 0.0496 / 0.2000\n",
      "[13/25][39/79] Loss_D: 0.6309 Loss_G: 4.2906 D(x): 0.9426 D(G(z)): 0.4113 / 0.0176\n",
      "[13/25][40/79] Loss_D: 0.2672 Loss_G: 4.0150 D(x): 0.8176 D(G(z)): 0.0466 / 0.0238\n",
      "[13/25][41/79] Loss_D: 0.3454 Loss_G: 3.7004 D(x): 0.8400 D(G(z)): 0.1415 / 0.0316\n",
      "[13/25][42/79] Loss_D: 0.2345 Loss_G: 3.7336 D(x): 0.8824 D(G(z)): 0.0920 / 0.0333\n",
      "[13/25][43/79] Loss_D: 0.1329 Loss_G: 3.7141 D(x): 0.9494 D(G(z)): 0.0750 / 0.0327\n",
      "[13/25][44/79] Loss_D: 0.3659 Loss_G: 2.0189 D(x): 0.7932 D(G(z)): 0.1089 / 0.1537\n",
      "[13/25][45/79] Loss_D: 0.5506 Loss_G: 3.8684 D(x): 0.9329 D(G(z)): 0.3589 / 0.0321\n",
      "[13/25][46/79] Loss_D: 0.7992 Loss_G: 0.4086 D(x): 0.5356 D(G(z)): 0.0792 / 0.7057\n",
      "[13/25][47/79] Loss_D: 2.2587 Loss_G: 8.4825 D(x): 0.9737 D(G(z)): 0.8538 / 0.0003\n",
      "[13/25][48/79] Loss_D: 1.9532 Loss_G: 5.9502 D(x): 0.2148 D(G(z)): 0.0008 / 0.0040\n",
      "[13/25][49/79] Loss_D: 0.3175 Loss_G: 2.6027 D(x): 0.7623 D(G(z)): 0.0112 / 0.1081\n",
      "[13/25][50/79] Loss_D: 0.2585 Loss_G: 2.7002 D(x): 0.9796 D(G(z)): 0.1973 / 0.0841\n",
      "[13/25][51/79] Loss_D: 0.2789 Loss_G: 4.4538 D(x): 0.9954 D(G(z)): 0.2252 / 0.0165\n",
      "[13/25][52/79] Loss_D: 0.1935 Loss_G: 4.0030 D(x): 0.9022 D(G(z)): 0.0781 / 0.0263\n",
      "[13/25][53/79] Loss_D: 0.1996 Loss_G: 3.3576 D(x): 0.8772 D(G(z)): 0.0558 / 0.0491\n",
      "[13/25][54/79] Loss_D: 0.2302 Loss_G: 3.5294 D(x): 0.9418 D(G(z)): 0.1460 / 0.0421\n",
      "[13/25][55/79] Loss_D: 0.2955 Loss_G: 3.8410 D(x): 0.9384 D(G(z)): 0.1935 / 0.0300\n",
      "[13/25][56/79] Loss_D: 0.4688 Loss_G: 2.8056 D(x): 0.7388 D(G(z)): 0.1204 / 0.0747\n",
      "[13/25][57/79] Loss_D: 0.4283 Loss_G: 3.7814 D(x): 0.8596 D(G(z)): 0.2154 / 0.0310\n",
      "[13/25][58/79] Loss_D: 0.3545 Loss_G: 3.6554 D(x): 0.8147 D(G(z)): 0.1190 / 0.0318\n",
      "[13/25][59/79] Loss_D: 0.4646 Loss_G: 2.4976 D(x): 0.7229 D(G(z)): 0.1052 / 0.0988\n",
      "[13/25][60/79] Loss_D: 0.8801 Loss_G: 5.9122 D(x): 0.8511 D(G(z)): 0.4754 / 0.0037\n",
      "[13/25][61/79] Loss_D: 0.4111 Loss_G: 4.1154 D(x): 0.7109 D(G(z)): 0.0159 / 0.0233\n",
      "[13/25][62/79] Loss_D: 0.3753 Loss_G: 2.1583 D(x): 0.7936 D(G(z)): 0.1120 / 0.1532\n",
      "[13/25][63/79] Loss_D: 0.8442 Loss_G: 7.5939 D(x): 0.9443 D(G(z)): 0.5106 / 0.0009\n",
      "[13/25][64/79] Loss_D: 0.9043 Loss_G: 2.8698 D(x): 0.4756 D(G(z)): 0.0078 / 0.0917\n",
      "[13/25][65/79] Loss_D: 0.6247 Loss_G: 7.1627 D(x): 0.9861 D(G(z)): 0.3975 / 0.0015\n",
      "[13/25][66/79] Loss_D: 0.6964 Loss_G: 4.3079 D(x): 0.5955 D(G(z)): 0.0097 / 0.0205\n",
      "[13/25][67/79] Loss_D: 0.1673 Loss_G: 3.0533 D(x): 0.9410 D(G(z)): 0.0928 / 0.0689\n",
      "[13/25][68/79] Loss_D: 0.4947 Loss_G: 4.3923 D(x): 0.9193 D(G(z)): 0.3030 / 0.0178\n",
      "[13/25][69/79] Loss_D: 0.1717 Loss_G: 4.6497 D(x): 0.9267 D(G(z)): 0.0829 / 0.0151\n",
      "[13/25][70/79] Loss_D: 0.3533 Loss_G: 3.2653 D(x): 0.7772 D(G(z)): 0.0459 / 0.0500\n",
      "[13/25][71/79] Loss_D: 0.3457 Loss_G: 3.8467 D(x): 0.9354 D(G(z)): 0.2273 / 0.0265\n",
      "[13/25][72/79] Loss_D: 0.1771 Loss_G: 4.2248 D(x): 0.9176 D(G(z)): 0.0797 / 0.0199\n",
      "[13/25][73/79] Loss_D: 0.2529 Loss_G: 3.2336 D(x): 0.8375 D(G(z)): 0.0608 / 0.0510\n",
      "[13/25][74/79] Loss_D: 0.3590 Loss_G: 4.3554 D(x): 0.9317 D(G(z)): 0.2330 / 0.0165\n",
      "[13/25][75/79] Loss_D: 0.2433 Loss_G: 3.8371 D(x): 0.8459 D(G(z)): 0.0626 / 0.0296\n",
      "[13/25][76/79] Loss_D: 0.3596 Loss_G: 2.5465 D(x): 0.7472 D(G(z)): 0.0414 / 0.1010\n",
      "[13/25][77/79] Loss_D: 0.3453 Loss_G: 4.4267 D(x): 0.9775 D(G(z)): 0.2596 / 0.0156\n",
      "[13/25][78/79] Loss_D: 0.2455 Loss_G: 4.1720 D(x): 0.8524 D(G(z)): 0.0773 / 0.0175\n",
      "[14/25][0/79] Loss_D: 0.1444 Loss_G: 4.8193 D(x): 0.9703 D(G(z)): 0.1041 / 0.0107\n",
      "[14/25][1/79] Loss_D: 0.5607 Loss_G: 1.8222 D(x): 0.6322 D(G(z)): 0.0281 / 0.2165\n",
      "[14/25][2/79] Loss_D: 0.9374 Loss_G: 5.5719 D(x): 0.9770 D(G(z)): 0.5417 / 0.0064\n",
      "[14/25][3/79] Loss_D: 0.5716 Loss_G: 2.8508 D(x): 0.6277 D(G(z)): 0.0227 / 0.1059\n",
      "[14/25][4/79] Loss_D: 0.5178 Loss_G: 7.1702 D(x): 0.9156 D(G(z)): 0.3143 / 0.0011\n",
      "[14/25][5/79] Loss_D: 0.5161 Loss_G: 1.8390 D(x): 0.6482 D(G(z)): 0.0050 / 0.1989\n",
      "[14/25][6/79] Loss_D: 1.1241 Loss_G: 4.9904 D(x): 0.9624 D(G(z)): 0.6142 / 0.0132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25][7/79] Loss_D: 0.4845 Loss_G: 1.7214 D(x): 0.6948 D(G(z)): 0.0491 / 0.2470\n",
      "[14/25][8/79] Loss_D: 1.1103 Loss_G: 6.8947 D(x): 0.9306 D(G(z)): 0.5782 / 0.0018\n",
      "[14/25][9/79] Loss_D: 1.8164 Loss_G: 1.9181 D(x): 0.2319 D(G(z)): 0.0103 / 0.1979\n",
      "[14/25][10/79] Loss_D: 0.9446 Loss_G: 3.6486 D(x): 0.8498 D(G(z)): 0.4757 / 0.0400\n",
      "[14/25][11/79] Loss_D: 0.5471 Loss_G: 3.9310 D(x): 0.7775 D(G(z)): 0.2117 / 0.0304\n",
      "[14/25][12/79] Loss_D: 1.0657 Loss_G: 0.8412 D(x): 0.4744 D(G(z)): 0.1164 / 0.4696\n",
      "[14/25][13/79] Loss_D: 1.8916 Loss_G: 7.0602 D(x): 0.9674 D(G(z)): 0.8071 / 0.0013\n",
      "[14/25][14/79] Loss_D: 1.6063 Loss_G: 3.3594 D(x): 0.2782 D(G(z)): 0.0063 / 0.0555\n",
      "[14/25][15/79] Loss_D: 0.7406 Loss_G: 1.7817 D(x): 0.7425 D(G(z)): 0.2768 / 0.2310\n",
      "[14/25][16/79] Loss_D: 1.2842 Loss_G: 4.5909 D(x): 0.8395 D(G(z)): 0.6227 / 0.0170\n",
      "[14/25][17/79] Loss_D: 1.3862 Loss_G: 1.9115 D(x): 0.3720 D(G(z)): 0.0976 / 0.1872\n",
      "[14/25][18/79] Loss_D: 1.0914 Loss_G: 3.0393 D(x): 0.8114 D(G(z)): 0.5437 / 0.0654\n",
      "[14/25][19/79] Loss_D: 0.5669 Loss_G: 3.5579 D(x): 0.7231 D(G(z)): 0.1723 / 0.0477\n",
      "[14/25][20/79] Loss_D: 0.5165 Loss_G: 2.5077 D(x): 0.7149 D(G(z)): 0.1197 / 0.1240\n",
      "[14/25][21/79] Loss_D: 0.4769 Loss_G: 3.8573 D(x): 0.9229 D(G(z)): 0.2958 / 0.0317\n",
      "[14/25][22/79] Loss_D: 0.2303 Loss_G: 4.1672 D(x): 0.8719 D(G(z)): 0.0794 / 0.0216\n",
      "[14/25][23/79] Loss_D: 0.5339 Loss_G: 2.4099 D(x): 0.7343 D(G(z)): 0.1475 / 0.1193\n",
      "[14/25][24/79] Loss_D: 0.4432 Loss_G: 2.8909 D(x): 0.8409 D(G(z)): 0.2013 / 0.0706\n",
      "[14/25][25/79] Loss_D: 0.5820 Loss_G: 3.7599 D(x): 0.8352 D(G(z)): 0.2862 / 0.0354\n",
      "[14/25][26/79] Loss_D: 0.7803 Loss_G: 1.8224 D(x): 0.5568 D(G(z)): 0.0513 / 0.1967\n",
      "[14/25][27/79] Loss_D: 0.6097 Loss_G: 4.4232 D(x): 0.9703 D(G(z)): 0.3946 / 0.0197\n",
      "[14/25][28/79] Loss_D: 0.5182 Loss_G: 3.3895 D(x): 0.6801 D(G(z)): 0.0599 / 0.0571\n",
      "[14/25][29/79] Loss_D: 0.2937 Loss_G: 3.6760 D(x): 0.9152 D(G(z)): 0.1703 / 0.0326\n",
      "[14/25][30/79] Loss_D: 0.4803 Loss_G: 2.2477 D(x): 0.7710 D(G(z)): 0.1599 / 0.1240\n",
      "[14/25][31/79] Loss_D: 0.4226 Loss_G: 4.7419 D(x): 0.9078 D(G(z)): 0.2641 / 0.0105\n",
      "[14/25][32/79] Loss_D: 0.3157 Loss_G: 3.5741 D(x): 0.7769 D(G(z)): 0.0322 / 0.0369\n",
      "[14/25][33/79] Loss_D: 0.5063 Loss_G: 2.3622 D(x): 0.7227 D(G(z)): 0.1309 / 0.1143\n",
      "[14/25][34/79] Loss_D: 0.5878 Loss_G: 4.0849 D(x): 0.8744 D(G(z)): 0.3411 / 0.0239\n",
      "[14/25][35/79] Loss_D: 0.2644 Loss_G: 3.3460 D(x): 0.8326 D(G(z)): 0.0624 / 0.0558\n",
      "[14/25][36/79] Loss_D: 0.5413 Loss_G: 4.7141 D(x): 0.8436 D(G(z)): 0.2713 / 0.0143\n",
      "[14/25][37/79] Loss_D: 0.6912 Loss_G: 0.4203 D(x): 0.5844 D(G(z)): 0.0157 / 0.6816\n",
      "[14/25][38/79] Loss_D: 1.8998 Loss_G: 8.2649 D(x): 0.9792 D(G(z)): 0.8123 / 0.0004\n",
      "[14/25][39/79] Loss_D: 1.6634 Loss_G: 0.4309 D(x): 0.2525 D(G(z)): 0.0005 / 0.6772\n",
      "[14/25][40/79] Loss_D: 1.7201 Loss_G: 10.1256 D(x): 0.9898 D(G(z)): 0.7732 / 0.0001\n",
      "[14/25][41/79] Loss_D: 2.6186 Loss_G: 6.0844 D(x): 0.1250 D(G(z)): 0.0001 / 0.0054\n",
      "[14/25][42/79] Loss_D: 0.2551 Loss_G: 2.1965 D(x): 0.8077 D(G(z)): 0.0188 / 0.1704\n",
      "[14/25][43/79] Loss_D: 0.5434 Loss_G: 3.1388 D(x): 0.9554 D(G(z)): 0.3303 / 0.0609\n",
      "[14/25][44/79] Loss_D: 0.3046 Loss_G: 4.3991 D(x): 0.9147 D(G(z)): 0.1681 / 0.0216\n",
      "[14/25][45/79] Loss_D: 0.3524 Loss_G: 3.8919 D(x): 0.8234 D(G(z)): 0.1101 / 0.0349\n",
      "[14/25][46/79] Loss_D: 0.6320 Loss_G: 2.3985 D(x): 0.6633 D(G(z)): 0.1197 / 0.1401\n",
      "[14/25][47/79] Loss_D: 0.4775 Loss_G: 4.2208 D(x): 0.9283 D(G(z)): 0.2930 / 0.0227\n",
      "[14/25][48/79] Loss_D: 0.3053 Loss_G: 4.0296 D(x): 0.8247 D(G(z)): 0.0802 / 0.0263\n",
      "[14/25][49/79] Loss_D: 0.7017 Loss_G: 2.2590 D(x): 0.6621 D(G(z)): 0.1649 / 0.1431\n",
      "[14/25][50/79] Loss_D: 0.7516 Loss_G: 4.4621 D(x): 0.8488 D(G(z)): 0.3953 / 0.0160\n",
      "[14/25][51/79] Loss_D: 0.4923 Loss_G: 4.4720 D(x): 0.8255 D(G(z)): 0.2246 / 0.0138\n",
      "[14/25][52/79] Loss_D: 0.4743 Loss_G: 3.1804 D(x): 0.6981 D(G(z)): 0.0592 / 0.0626\n",
      "[14/25][53/79] Loss_D: 0.2850 Loss_G: 2.9223 D(x): 0.8481 D(G(z)): 0.0870 / 0.0768\n",
      "[14/25][54/79] Loss_D: 0.4779 Loss_G: 3.5192 D(x): 0.9017 D(G(z)): 0.2926 / 0.0369\n",
      "[14/25][55/79] Loss_D: 0.4173 Loss_G: 3.1148 D(x): 0.7853 D(G(z)): 0.1384 / 0.0546\n",
      "[14/25][56/79] Loss_D: 0.2506 Loss_G: 3.3311 D(x): 0.9100 D(G(z)): 0.1306 / 0.0498\n",
      "[14/25][57/79] Loss_D: 0.2043 Loss_G: 3.3739 D(x): 0.8964 D(G(z)): 0.0793 / 0.0410\n",
      "[14/25][58/79] Loss_D: 0.2493 Loss_G: 3.1309 D(x): 0.8955 D(G(z)): 0.1194 / 0.0542\n",
      "[14/25][59/79] Loss_D: 0.2713 Loss_G: 3.6102 D(x): 0.9389 D(G(z)): 0.1796 / 0.0322\n",
      "[14/25][60/79] Loss_D: 0.2123 Loss_G: 4.0378 D(x): 0.9234 D(G(z)): 0.1105 / 0.0249\n",
      "[14/25][61/79] Loss_D: 0.2176 Loss_G: 3.6868 D(x): 0.8612 D(G(z)): 0.0488 / 0.0346\n",
      "[14/25][62/79] Loss_D: 0.2864 Loss_G: 2.8449 D(x): 0.8473 D(G(z)): 0.1004 / 0.0722\n",
      "[14/25][63/79] Loss_D: 0.2679 Loss_G: 3.0210 D(x): 0.8992 D(G(z)): 0.1338 / 0.0660\n",
      "[14/25][64/79] Loss_D: 0.2779 Loss_G: 3.2975 D(x): 0.9182 D(G(z)): 0.1632 / 0.0483\n",
      "[14/25][65/79] Loss_D: 0.1540 Loss_G: 3.7762 D(x): 0.9348 D(G(z)): 0.0748 / 0.0330\n",
      "[14/25][66/79] Loss_D: 0.2092 Loss_G: 3.4096 D(x): 0.8686 D(G(z)): 0.0542 / 0.0441\n",
      "[14/25][67/79] Loss_D: 0.1812 Loss_G: 3.1105 D(x): 0.9328 D(G(z)): 0.1015 / 0.0554\n",
      "[14/25][68/79] Loss_D: 0.2797 Loss_G: 2.9219 D(x): 0.8815 D(G(z)): 0.1299 / 0.0679\n",
      "[14/25][69/79] Loss_D: 0.3664 Loss_G: 3.3528 D(x): 0.9176 D(G(z)): 0.2304 / 0.0437\n",
      "[14/25][70/79] Loss_D: 0.2946 Loss_G: 3.5975 D(x): 0.8926 D(G(z)): 0.1530 / 0.0368\n",
      "[14/25][71/79] Loss_D: 0.5852 Loss_G: 1.7499 D(x): 0.6142 D(G(z)): 0.0541 / 0.2068\n",
      "[14/25][72/79] Loss_D: 0.7742 Loss_G: 3.5191 D(x): 0.9054 D(G(z)): 0.4492 / 0.0378\n",
      "[14/25][73/79] Loss_D: 0.4593 Loss_G: 3.3863 D(x): 0.7621 D(G(z)): 0.1417 / 0.0471\n",
      "[14/25][74/79] Loss_D: 0.2249 Loss_G: 3.4283 D(x): 0.8937 D(G(z)): 0.0982 / 0.0444\n",
      "[14/25][75/79] Loss_D: 0.4605 Loss_G: 3.0006 D(x): 0.8177 D(G(z)): 0.2013 / 0.0678\n",
      "[14/25][76/79] Loss_D: 0.8770 Loss_G: 5.1343 D(x): 0.8774 D(G(z)): 0.4816 / 0.0082\n",
      "[14/25][77/79] Loss_D: 1.1506 Loss_G: 2.7402 D(x): 0.4058 D(G(z)): 0.0209 / 0.0830\n",
      "[14/25][78/79] Loss_D: 0.2811 Loss_G: 2.9392 D(x): 0.8960 D(G(z)): 0.1502 / 0.0652\n",
      "[15/25][0/79] Loss_D: 1.1031 Loss_G: 5.8421 D(x): 0.9721 D(G(z)): 0.6093 / 0.0043\n",
      "[15/25][1/79] Loss_D: 0.5659 Loss_G: 5.6443 D(x): 0.6168 D(G(z)): 0.0118 / 0.0060\n",
      "[15/25][2/79] Loss_D: 0.2552 Loss_G: 3.1890 D(x): 0.8244 D(G(z)): 0.0459 / 0.0610\n",
      "[15/25][3/79] Loss_D: 0.4443 Loss_G: 3.6249 D(x): 0.8907 D(G(z)): 0.2475 / 0.0380\n",
      "[15/25][4/79] Loss_D: 0.6525 Loss_G: 3.6540 D(x): 0.7354 D(G(z)): 0.2257 / 0.0415\n",
      "[15/25][5/79] Loss_D: 0.3222 Loss_G: 3.7051 D(x): 0.8464 D(G(z)): 0.1278 / 0.0346\n",
      "[15/25][6/79] Loss_D: 0.3967 Loss_G: 3.3595 D(x): 0.8096 D(G(z)): 0.1427 / 0.0510\n",
      "[15/25][7/79] Loss_D: 0.4708 Loss_G: 5.3128 D(x): 0.8790 D(G(z)): 0.2707 / 0.0067\n",
      "[15/25][8/79] Loss_D: 0.3790 Loss_G: 3.6321 D(x): 0.7841 D(G(z)): 0.1002 / 0.0380\n",
      "[15/25][9/79] Loss_D: 0.4715 Loss_G: 3.4133 D(x): 0.8107 D(G(z)): 0.2032 / 0.0433\n",
      "[15/25][10/79] Loss_D: 0.5909 Loss_G: 4.6903 D(x): 0.8226 D(G(z)): 0.2970 / 0.0112\n",
      "[15/25][11/79] Loss_D: 0.3356 Loss_G: 4.9271 D(x): 0.8385 D(G(z)): 0.1244 / 0.0108\n",
      "[15/25][12/79] Loss_D: 0.2695 Loss_G: 3.7693 D(x): 0.8246 D(G(z)): 0.0484 / 0.0308\n",
      "[15/25][13/79] Loss_D: 0.4409 Loss_G: 2.8998 D(x): 0.7849 D(G(z)): 0.1482 / 0.0746\n",
      "[15/25][14/79] Loss_D: 0.5425 Loss_G: 7.0267 D(x): 0.9556 D(G(z)): 0.3595 / 0.0013\n",
      "[15/25][15/79] Loss_D: 0.3613 Loss_G: 5.3315 D(x): 0.7417 D(G(z)): 0.0090 / 0.0076\n",
      "[15/25][16/79] Loss_D: 0.1760 Loss_G: 3.1657 D(x): 0.8891 D(G(z)): 0.0444 / 0.0623\n",
      "[15/25][17/79] Loss_D: 0.3463 Loss_G: 3.9885 D(x): 0.9241 D(G(z)): 0.2075 / 0.0258\n",
      "[15/25][18/79] Loss_D: 0.5863 Loss_G: 4.7478 D(x): 0.7848 D(G(z)): 0.2267 / 0.0146\n",
      "[15/25][19/79] Loss_D: 0.6321 Loss_G: 2.9400 D(x): 0.6415 D(G(z)): 0.0920 / 0.0783\n",
      "[15/25][20/79] Loss_D: 0.3093 Loss_G: 5.5417 D(x): 0.9651 D(G(z)): 0.2181 / 0.0053\n",
      "[15/25][21/79] Loss_D: 0.2619 Loss_G: 4.3942 D(x): 0.8140 D(G(z)): 0.0309 / 0.0213\n",
      "[15/25][22/79] Loss_D: 0.1155 Loss_G: 4.3732 D(x): 0.9782 D(G(z)): 0.0822 / 0.0214\n",
      "[15/25][23/79] Loss_D: 0.1863 Loss_G: 3.7401 D(x): 0.8724 D(G(z)): 0.0421 / 0.0324\n",
      "[15/25][24/79] Loss_D: 0.1739 Loss_G: 3.8154 D(x): 0.9341 D(G(z)): 0.0941 / 0.0319\n",
      "[15/25][25/79] Loss_D: 0.1846 Loss_G: 3.6769 D(x): 0.9121 D(G(z)): 0.0795 / 0.0342\n",
      "[15/25][26/79] Loss_D: 0.2403 Loss_G: 4.3336 D(x): 0.9417 D(G(z)): 0.1563 / 0.0179\n",
      "[15/25][27/79] Loss_D: 0.2797 Loss_G: 3.7216 D(x): 0.7912 D(G(z)): 0.0212 / 0.0318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/25][28/79] Loss_D: 0.3637 Loss_G: 3.0359 D(x): 0.8444 D(G(z)): 0.1494 / 0.0657\n",
      "[15/25][29/79] Loss_D: 0.2851 Loss_G: 5.4783 D(x): 0.9653 D(G(z)): 0.2069 / 0.0057\n",
      "[15/25][30/79] Loss_D: 0.2555 Loss_G: 4.9990 D(x): 0.7986 D(G(z)): 0.0115 / 0.0106\n",
      "[15/25][31/79] Loss_D: 0.3565 Loss_G: 2.1808 D(x): 0.7644 D(G(z)): 0.0400 / 0.1491\n",
      "[15/25][32/79] Loss_D: 0.5486 Loss_G: 5.8529 D(x): 0.9554 D(G(z)): 0.3586 / 0.0048\n",
      "[15/25][33/79] Loss_D: 0.0767 Loss_G: 6.4003 D(x): 0.9473 D(G(z)): 0.0190 / 0.0030\n",
      "[15/25][34/79] Loss_D: 0.4407 Loss_G: 3.5583 D(x): 0.6784 D(G(z)): 0.0125 / 0.0416\n",
      "[15/25][35/79] Loss_D: 0.0971 Loss_G: 2.9630 D(x): 0.9634 D(G(z)): 0.0564 / 0.0656\n",
      "[15/25][36/79] Loss_D: 0.3006 Loss_G: 4.7233 D(x): 0.9701 D(G(z)): 0.2198 / 0.0123\n",
      "[15/25][37/79] Loss_D: 0.0997 Loss_G: 5.3592 D(x): 0.9474 D(G(z)): 0.0427 / 0.0071\n",
      "[15/25][38/79] Loss_D: 0.1320 Loss_G: 4.6275 D(x): 0.9044 D(G(z)): 0.0255 / 0.0156\n",
      "[15/25][39/79] Loss_D: 0.1328 Loss_G: 3.9554 D(x): 0.9644 D(G(z)): 0.0873 / 0.0290\n",
      "[15/25][40/79] Loss_D: 0.1242 Loss_G: 4.1088 D(x): 0.9373 D(G(z)): 0.0517 / 0.0235\n",
      "[15/25][41/79] Loss_D: 0.1874 Loss_G: 3.7084 D(x): 0.9161 D(G(z)): 0.0893 / 0.0333\n",
      "[15/25][42/79] Loss_D: 0.3248 Loss_G: 4.0306 D(x): 0.8917 D(G(z)): 0.1743 / 0.0251\n",
      "[15/25][43/79] Loss_D: 0.3906 Loss_G: 4.6768 D(x): 0.9047 D(G(z)): 0.2124 / 0.0157\n",
      "[15/25][44/79] Loss_D: 0.2032 Loss_G: 4.6451 D(x): 0.8569 D(G(z)): 0.0351 / 0.0165\n",
      "[15/25][45/79] Loss_D: 0.4177 Loss_G: 2.5233 D(x): 0.7387 D(G(z)): 0.0516 / 0.1078\n",
      "[15/25][46/79] Loss_D: 0.3587 Loss_G: 4.1415 D(x): 0.9562 D(G(z)): 0.2466 / 0.0228\n",
      "[15/25][47/79] Loss_D: 0.1193 Loss_G: 5.0361 D(x): 0.9642 D(G(z)): 0.0725 / 0.0105\n",
      "[15/25][48/79] Loss_D: 0.2270 Loss_G: 3.6629 D(x): 0.8393 D(G(z)): 0.0372 / 0.0368\n",
      "[15/25][49/79] Loss_D: 0.1969 Loss_G: 4.0301 D(x): 0.9569 D(G(z)): 0.1344 / 0.0246\n",
      "[15/25][50/79] Loss_D: 0.2194 Loss_G: 4.5969 D(x): 0.9386 D(G(z)): 0.1375 / 0.0124\n",
      "[15/25][51/79] Loss_D: 0.1471 Loss_G: 4.6849 D(x): 0.9052 D(G(z)): 0.0369 / 0.0136\n",
      "[15/25][52/79] Loss_D: 0.2332 Loss_G: 3.7566 D(x): 0.8799 D(G(z)): 0.0812 / 0.0317\n",
      "[15/25][53/79] Loss_D: 0.1401 Loss_G: 3.8714 D(x): 0.9247 D(G(z)): 0.0554 / 0.0276\n",
      "[15/25][54/79] Loss_D: 0.2666 Loss_G: 4.8567 D(x): 0.9643 D(G(z)): 0.1935 / 0.0107\n",
      "[15/25][55/79] Loss_D: 0.2148 Loss_G: 4.2952 D(x): 0.8524 D(G(z)): 0.0316 / 0.0179\n",
      "[15/25][56/79] Loss_D: 0.2738 Loss_G: 3.9746 D(x): 0.9056 D(G(z)): 0.1439 / 0.0231\n",
      "[15/25][57/79] Loss_D: 0.4024 Loss_G: 3.9474 D(x): 0.8036 D(G(z)): 0.1402 / 0.0250\n",
      "[15/25][58/79] Loss_D: 0.2495 Loss_G: 5.2708 D(x): 0.9375 D(G(z)): 0.1584 / 0.0065\n",
      "[15/25][59/79] Loss_D: 0.1867 Loss_G: 4.4558 D(x): 0.8778 D(G(z)): 0.0424 / 0.0149\n",
      "[15/25][60/79] Loss_D: 0.2153 Loss_G: 4.8302 D(x): 0.9574 D(G(z)): 0.1517 / 0.0102\n",
      "[15/25][61/79] Loss_D: 0.4672 Loss_G: 2.5949 D(x): 0.6939 D(G(z)): 0.0469 / 0.0906\n",
      "[15/25][62/79] Loss_D: 0.6580 Loss_G: 6.6414 D(x): 0.9374 D(G(z)): 0.4130 / 0.0019\n",
      "[15/25][63/79] Loss_D: 0.5633 Loss_G: 4.0994 D(x): 0.6294 D(G(z)): 0.0164 / 0.0264\n",
      "[15/25][64/79] Loss_D: 0.4433 Loss_G: 3.2311 D(x): 0.8481 D(G(z)): 0.2022 / 0.0637\n",
      "[15/25][65/79] Loss_D: 0.8694 Loss_G: 7.7024 D(x): 0.9487 D(G(z)): 0.4977 / 0.0011\n",
      "[15/25][66/79] Loss_D: 1.8874 Loss_G: 1.8610 D(x): 0.2429 D(G(z)): 0.0313 / 0.2239\n",
      "[15/25][67/79] Loss_D: 2.0724 Loss_G: 6.6702 D(x): 0.8462 D(G(z)): 0.7650 / 0.0026\n",
      "[15/25][68/79] Loss_D: 3.3153 Loss_G: 1.3028 D(x): 0.0941 D(G(z)): 0.0163 / 0.3760\n",
      "[15/25][69/79] Loss_D: 1.4879 Loss_G: 4.5834 D(x): 0.9582 D(G(z)): 0.6046 / 0.0222\n",
      "[15/25][70/79] Loss_D: 0.4209 Loss_G: 4.7987 D(x): 0.8398 D(G(z)): 0.1642 / 0.0205\n",
      "[15/25][71/79] Loss_D: 0.8555 Loss_G: 2.0326 D(x): 0.6227 D(G(z)): 0.1854 / 0.2058\n",
      "[15/25][72/79] Loss_D: 1.3633 Loss_G: 4.8670 D(x): 0.8972 D(G(z)): 0.6253 / 0.0144\n",
      "[15/25][73/79] Loss_D: 1.2122 Loss_G: 2.1648 D(x): 0.4624 D(G(z)): 0.0845 / 0.1729\n",
      "[15/25][74/79] Loss_D: 0.7237 Loss_G: 3.3278 D(x): 0.8820 D(G(z)): 0.4003 / 0.0566\n",
      "[15/25][75/79] Loss_D: 0.4363 Loss_G: 4.8561 D(x): 0.9043 D(G(z)): 0.2523 / 0.0126\n",
      "[15/25][76/79] Loss_D: 0.8323 Loss_G: 2.6292 D(x): 0.6229 D(G(z)): 0.2093 / 0.0900\n",
      "[15/25][77/79] Loss_D: 1.5255 Loss_G: 3.4769 D(x): 0.5348 D(G(z)): 0.4969 / 0.0488\n",
      "[15/25][78/79] Loss_D: 0.4893 Loss_G: 1.9463 D(x): 0.6768 D(G(z)): 0.0591 / 0.1757\n",
      "[16/25][0/79] Loss_D: 2.1269 Loss_G: 6.4708 D(x): 0.9026 D(G(z)): 0.8030 / 0.0043\n",
      "[16/25][1/79] Loss_D: 1.2262 Loss_G: 3.0056 D(x): 0.4293 D(G(z)): 0.0175 / 0.1106\n",
      "[16/25][2/79] Loss_D: 0.8180 Loss_G: 3.6822 D(x): 0.8128 D(G(z)): 0.3445 / 0.0540\n",
      "[16/25][3/79] Loss_D: 0.6807 Loss_G: 2.8773 D(x): 0.6719 D(G(z)): 0.1450 / 0.0949\n",
      "[16/25][4/79] Loss_D: 0.7999 Loss_G: 5.0841 D(x): 0.8486 D(G(z)): 0.4020 / 0.0102\n",
      "[16/25][5/79] Loss_D: 0.5109 Loss_G: 3.3724 D(x): 0.7302 D(G(z)): 0.1277 / 0.0460\n",
      "[16/25][6/79] Loss_D: 0.7733 Loss_G: 1.7423 D(x): 0.6272 D(G(z)): 0.1922 / 0.2137\n",
      "[16/25][7/79] Loss_D: 1.4038 Loss_G: 4.8370 D(x): 0.8981 D(G(z)): 0.6772 / 0.0199\n",
      "[16/25][8/79] Loss_D: 0.8596 Loss_G: 3.5563 D(x): 0.5406 D(G(z)): 0.0457 / 0.0560\n",
      "[16/25][9/79] Loss_D: 0.8257 Loss_G: 1.8146 D(x): 0.6904 D(G(z)): 0.2682 / 0.2348\n",
      "[16/25][10/79] Loss_D: 0.9171 Loss_G: 3.7350 D(x): 0.8597 D(G(z)): 0.4612 / 0.0360\n",
      "[16/25][11/79] Loss_D: 0.6993 Loss_G: 3.3892 D(x): 0.6599 D(G(z)): 0.1140 / 0.0513\n",
      "[16/25][12/79] Loss_D: 0.5967 Loss_G: 2.1699 D(x): 0.7215 D(G(z)): 0.1689 / 0.1505\n",
      "[16/25][13/79] Loss_D: 1.0662 Loss_G: 4.7293 D(x): 0.8964 D(G(z)): 0.5585 / 0.0170\n",
      "[16/25][14/79] Loss_D: 0.7218 Loss_G: 3.5825 D(x): 0.5702 D(G(z)): 0.0489 / 0.0560\n",
      "[16/25][15/79] Loss_D: 0.7559 Loss_G: 2.2830 D(x): 0.7408 D(G(z)): 0.3023 / 0.1408\n",
      "[16/25][16/79] Loss_D: 0.8955 Loss_G: 5.2287 D(x): 0.8732 D(G(z)): 0.4628 / 0.0083\n",
      "[16/25][17/79] Loss_D: 1.3022 Loss_G: 1.8559 D(x): 0.3939 D(G(z)): 0.0772 / 0.2224\n",
      "[16/25][18/79] Loss_D: 0.7982 Loss_G: 3.7548 D(x): 0.8543 D(G(z)): 0.4201 / 0.0364\n",
      "[16/25][19/79] Loss_D: 0.5311 Loss_G: 3.6514 D(x): 0.7679 D(G(z)): 0.1603 / 0.0408\n",
      "[16/25][20/79] Loss_D: 0.2154 Loss_G: 3.9154 D(x): 0.9121 D(G(z)): 0.1051 / 0.0309\n",
      "[16/25][21/79] Loss_D: 0.2809 Loss_G: 3.7575 D(x): 0.8877 D(G(z)): 0.1337 / 0.0362\n",
      "[16/25][22/79] Loss_D: 0.2880 Loss_G: 4.0349 D(x): 0.8941 D(G(z)): 0.1460 / 0.0281\n",
      "[16/25][23/79] Loss_D: 0.2727 Loss_G: 3.9709 D(x): 0.8985 D(G(z)): 0.1272 / 0.0342\n",
      "[16/25][24/79] Loss_D: 0.7589 Loss_G: 1.5838 D(x): 0.5839 D(G(z)): 0.1243 / 0.2576\n",
      "[16/25][25/79] Loss_D: 1.0482 Loss_G: 4.9819 D(x): 0.9300 D(G(z)): 0.5703 / 0.0106\n",
      "[16/25][26/79] Loss_D: 0.8169 Loss_G: 2.3501 D(x): 0.5291 D(G(z)): 0.0451 / 0.1402\n",
      "[16/25][27/79] Loss_D: 0.5364 Loss_G: 4.6329 D(x): 0.8949 D(G(z)): 0.3107 / 0.0153\n",
      "[16/25][28/79] Loss_D: 0.2974 Loss_G: 4.0378 D(x): 0.8275 D(G(z)): 0.0828 / 0.0281\n",
      "[16/25][29/79] Loss_D: 0.6476 Loss_G: 1.8127 D(x): 0.6306 D(G(z)): 0.0735 / 0.2261\n",
      "[16/25][30/79] Loss_D: 1.4457 Loss_G: 4.6350 D(x): 0.9332 D(G(z)): 0.6853 / 0.0183\n",
      "[16/25][31/79] Loss_D: 0.4439 Loss_G: 4.4250 D(x): 0.6957 D(G(z)): 0.0264 / 0.0225\n",
      "[16/25][32/79] Loss_D: 0.5003 Loss_G: 2.1113 D(x): 0.6989 D(G(z)): 0.0864 / 0.1578\n",
      "[16/25][33/79] Loss_D: 0.5768 Loss_G: 3.2116 D(x): 0.9276 D(G(z)): 0.3580 / 0.0645\n",
      "[16/25][34/79] Loss_D: 0.6003 Loss_G: 4.1476 D(x): 0.8107 D(G(z)): 0.2634 / 0.0257\n",
      "[16/25][35/79] Loss_D: 0.6877 Loss_G: 1.9061 D(x): 0.6165 D(G(z)): 0.1259 / 0.1886\n",
      "[16/25][36/79] Loss_D: 0.3565 Loss_G: 3.0789 D(x): 0.9424 D(G(z)): 0.2383 / 0.0618\n",
      "[16/25][37/79] Loss_D: 1.0494 Loss_G: 1.8528 D(x): 0.5892 D(G(z)): 0.3305 / 0.1868\n",
      "[16/25][38/79] Loss_D: 0.6520 Loss_G: 5.0210 D(x): 0.8423 D(G(z)): 0.3576 / 0.0103\n",
      "[16/25][39/79] Loss_D: 0.9214 Loss_G: 1.4346 D(x): 0.4720 D(G(z)): 0.0316 / 0.2858\n",
      "[16/25][40/79] Loss_D: 0.9656 Loss_G: 4.0333 D(x): 0.9720 D(G(z)): 0.5596 / 0.0257\n",
      "[16/25][41/79] Loss_D: 0.7170 Loss_G: 1.3230 D(x): 0.5923 D(G(z)): 0.1082 / 0.3035\n",
      "[16/25][42/79] Loss_D: 0.9175 Loss_G: 4.2986 D(x): 0.8182 D(G(z)): 0.4669 / 0.0187\n",
      "[16/25][43/79] Loss_D: 1.1836 Loss_G: 1.4995 D(x): 0.4079 D(G(z)): 0.0566 / 0.2742\n",
      "[16/25][44/79] Loss_D: 0.9117 Loss_G: 5.2057 D(x): 0.9821 D(G(z)): 0.5548 / 0.0080\n",
      "[16/25][45/79] Loss_D: 1.1108 Loss_G: 0.7082 D(x): 0.3971 D(G(z)): 0.0239 / 0.5378\n",
      "[16/25][46/79] Loss_D: 1.4043 Loss_G: 5.4907 D(x): 0.9746 D(G(z)): 0.6808 / 0.0101\n",
      "[16/25][47/79] Loss_D: 1.5105 Loss_G: 2.3039 D(x): 0.3074 D(G(z)): 0.0381 / 0.1511\n",
      "[16/25][48/79] Loss_D: 0.6117 Loss_G: 2.9344 D(x): 0.8898 D(G(z)): 0.3460 / 0.0776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/25][49/79] Loss_D: 0.3801 Loss_G: 3.8721 D(x): 0.8664 D(G(z)): 0.1905 / 0.0301\n",
      "[16/25][50/79] Loss_D: 0.3655 Loss_G: 3.4258 D(x): 0.8244 D(G(z)): 0.1292 / 0.0488\n",
      "[16/25][51/79] Loss_D: 0.4984 Loss_G: 2.0370 D(x): 0.7363 D(G(z)): 0.1430 / 0.1628\n",
      "[16/25][52/79] Loss_D: 0.6586 Loss_G: 3.1998 D(x): 0.8006 D(G(z)): 0.3144 / 0.0529\n",
      "[16/25][53/79] Loss_D: 0.5819 Loss_G: 2.6516 D(x): 0.7217 D(G(z)): 0.1866 / 0.0964\n",
      "[16/25][54/79] Loss_D: 0.4716 Loss_G: 2.7246 D(x): 0.7887 D(G(z)): 0.1866 / 0.0867\n",
      "[16/25][55/79] Loss_D: 0.4049 Loss_G: 3.8348 D(x): 0.8631 D(G(z)): 0.2120 / 0.0273\n",
      "[16/25][56/79] Loss_D: 0.4462 Loss_G: 2.7421 D(x): 0.7377 D(G(z)): 0.1048 / 0.0764\n",
      "[16/25][57/79] Loss_D: 0.4052 Loss_G: 2.9112 D(x): 0.8244 D(G(z)): 0.1625 / 0.0745\n",
      "[16/25][58/79] Loss_D: 0.5013 Loss_G: 4.8368 D(x): 0.9188 D(G(z)): 0.3110 / 0.0115\n",
      "[16/25][59/79] Loss_D: 1.1225 Loss_G: 1.2470 D(x): 0.4020 D(G(z)): 0.0264 / 0.3348\n",
      "[16/25][60/79] Loss_D: 0.8335 Loss_G: 5.5002 D(x): 0.9684 D(G(z)): 0.4939 / 0.0058\n",
      "[16/25][61/79] Loss_D: 0.4927 Loss_G: 3.4418 D(x): 0.6783 D(G(z)): 0.0373 / 0.0543\n",
      "[16/25][62/79] Loss_D: 0.3299 Loss_G: 3.1299 D(x): 0.8704 D(G(z)): 0.1575 / 0.0615\n",
      "[16/25][63/79] Loss_D: 0.4405 Loss_G: 3.6958 D(x): 0.8520 D(G(z)): 0.2174 / 0.0359\n",
      "[16/25][64/79] Loss_D: 0.4565 Loss_G: 3.9641 D(x): 0.8427 D(G(z)): 0.2232 / 0.0256\n",
      "[16/25][65/79] Loss_D: 1.4669 Loss_G: 0.6946 D(x): 0.3569 D(G(z)): 0.1555 / 0.5470\n",
      "[16/25][66/79] Loss_D: 1.5724 Loss_G: 6.7425 D(x): 0.9781 D(G(z)): 0.7123 / 0.0020\n",
      "[16/25][67/79] Loss_D: 0.8943 Loss_G: 4.6049 D(x): 0.5142 D(G(z)): 0.0099 / 0.0156\n",
      "[16/25][68/79] Loss_D: 0.7365 Loss_G: 1.2252 D(x): 0.6268 D(G(z)): 0.1336 / 0.3443\n",
      "[16/25][69/79] Loss_D: 1.6763 Loss_G: 4.7895 D(x): 0.9050 D(G(z)): 0.7250 / 0.0229\n",
      "[16/25][70/79] Loss_D: 0.6878 Loss_G: 4.6508 D(x): 0.6502 D(G(z)): 0.0885 / 0.0243\n",
      "[16/25][71/79] Loss_D: 1.3806 Loss_G: 1.0452 D(x): 0.3955 D(G(z)): 0.1482 / 0.4233\n",
      "[16/25][72/79] Loss_D: 1.4100 Loss_G: 4.5563 D(x): 0.9456 D(G(z)): 0.6804 / 0.0165\n",
      "[16/25][73/79] Loss_D: 0.1721 Loss_G: 5.4503 D(x): 0.9046 D(G(z)): 0.0613 / 0.0068\n",
      "[16/25][74/79] Loss_D: 0.6876 Loss_G: 2.9599 D(x): 0.5955 D(G(z)): 0.0507 / 0.0824\n",
      "[16/25][75/79] Loss_D: 0.5980 Loss_G: 2.6844 D(x): 0.8672 D(G(z)): 0.3204 / 0.0966\n",
      "[16/25][76/79] Loss_D: 0.3434 Loss_G: 3.9308 D(x): 0.8984 D(G(z)): 0.1860 / 0.0329\n",
      "[16/25][77/79] Loss_D: 0.7213 Loss_G: 2.4672 D(x): 0.6653 D(G(z)): 0.1958 / 0.1220\n",
      "[16/25][78/79] Loss_D: 0.7183 Loss_G: 3.8716 D(x): 0.7090 D(G(z)): 0.2904 / 0.0271\n",
      "[17/25][0/79] Loss_D: 0.6034 Loss_G: 4.2892 D(x): 0.9099 D(G(z)): 0.3602 / 0.0212\n",
      "[17/25][1/79] Loss_D: 0.4823 Loss_G: 3.9880 D(x): 0.7978 D(G(z)): 0.1764 / 0.0271\n",
      "[17/25][2/79] Loss_D: 0.6260 Loss_G: 3.4096 D(x): 0.6883 D(G(z)): 0.1807 / 0.0499\n",
      "[17/25][3/79] Loss_D: 1.0519 Loss_G: 1.7214 D(x): 0.5153 D(G(z)): 0.2106 / 0.2438\n",
      "[17/25][4/79] Loss_D: 1.0510 Loss_G: 5.2155 D(x): 0.9370 D(G(z)): 0.5557 / 0.0113\n",
      "[17/25][5/79] Loss_D: 0.3952 Loss_G: 4.9011 D(x): 0.7489 D(G(z)): 0.0353 / 0.0142\n",
      "[17/25][6/79] Loss_D: 0.5574 Loss_G: 2.2815 D(x): 0.6683 D(G(z)): 0.0758 / 0.1561\n",
      "[17/25][7/79] Loss_D: 0.8203 Loss_G: 4.0211 D(x): 0.9376 D(G(z)): 0.4776 / 0.0266\n",
      "[17/25][8/79] Loss_D: 0.5023 Loss_G: 2.9201 D(x): 0.6873 D(G(z)): 0.0731 / 0.0731\n",
      "[17/25][9/79] Loss_D: 0.3709 Loss_G: 3.4422 D(x): 0.9322 D(G(z)): 0.2284 / 0.0454\n",
      "[17/25][10/79] Loss_D: 0.3239 Loss_G: 3.6553 D(x): 0.8566 D(G(z)): 0.1390 / 0.0397\n",
      "[17/25][11/79] Loss_D: 0.5488 Loss_G: 2.3120 D(x): 0.7067 D(G(z)): 0.1269 / 0.1334\n",
      "[17/25][12/79] Loss_D: 0.5908 Loss_G: 2.7609 D(x): 0.8712 D(G(z)): 0.3110 / 0.0821\n",
      "[17/25][13/79] Loss_D: 0.6643 Loss_G: 2.2354 D(x): 0.7003 D(G(z)): 0.1941 / 0.1291\n",
      "[17/25][14/79] Loss_D: 0.4754 Loss_G: 2.8046 D(x): 0.8501 D(G(z)): 0.2477 / 0.0751\n",
      "[17/25][15/79] Loss_D: 0.6682 Loss_G: 4.0613 D(x): 0.7816 D(G(z)): 0.2915 / 0.0244\n",
      "[17/25][16/79] Loss_D: 0.3462 Loss_G: 3.1703 D(x): 0.7871 D(G(z)): 0.0777 / 0.0531\n",
      "[17/25][17/79] Loss_D: 0.7276 Loss_G: 2.3795 D(x): 0.7205 D(G(z)): 0.2733 / 0.1093\n",
      "[17/25][18/79] Loss_D: 0.5008 Loss_G: 2.1633 D(x): 0.7669 D(G(z)): 0.1750 / 0.1409\n",
      "[17/25][19/79] Loss_D: 0.4450 Loss_G: 3.6412 D(x): 0.9105 D(G(z)): 0.2774 / 0.0339\n",
      "[17/25][20/79] Loss_D: 0.2915 Loss_G: 3.3097 D(x): 0.8166 D(G(z)): 0.0693 / 0.0499\n",
      "[17/25][21/79] Loss_D: 0.4768 Loss_G: 1.5459 D(x): 0.7157 D(G(z)): 0.0897 / 0.2607\n",
      "[17/25][22/79] Loss_D: 2.0372 Loss_G: 6.7509 D(x): 0.9868 D(G(z)): 0.8330 / 0.0017\n",
      "[17/25][23/79] Loss_D: 2.6704 Loss_G: 0.7720 D(x): 0.1191 D(G(z)): 0.0036 / 0.5142\n",
      "[17/25][24/79] Loss_D: 1.6393 Loss_G: 4.9974 D(x): 0.9692 D(G(z)): 0.7377 / 0.0137\n",
      "[17/25][25/79] Loss_D: 1.1294 Loss_G: 2.7315 D(x): 0.4187 D(G(z)): 0.0336 / 0.0973\n",
      "[17/25][26/79] Loss_D: 0.5942 Loss_G: 1.9067 D(x): 0.7864 D(G(z)): 0.2378 / 0.2018\n",
      "[17/25][27/79] Loss_D: 0.7198 Loss_G: 2.8003 D(x): 0.8071 D(G(z)): 0.3416 / 0.0829\n",
      "[17/25][28/79] Loss_D: 1.0243 Loss_G: 2.3744 D(x): 0.6165 D(G(z)): 0.3161 / 0.1234\n",
      "[17/25][29/79] Loss_D: 1.0132 Loss_G: 2.6700 D(x): 0.6907 D(G(z)): 0.3845 / 0.0945\n",
      "[17/25][30/79] Loss_D: 1.1067 Loss_G: 1.2032 D(x): 0.4958 D(G(z)): 0.2055 / 0.3353\n",
      "[17/25][31/79] Loss_D: 1.1845 Loss_G: 2.9633 D(x): 0.8042 D(G(z)): 0.5526 / 0.0734\n",
      "[17/25][32/79] Loss_D: 0.8314 Loss_G: 2.0006 D(x): 0.5621 D(G(z)): 0.1088 / 0.1718\n",
      "[17/25][33/79] Loss_D: 0.4990 Loss_G: 2.5124 D(x): 0.8611 D(G(z)): 0.2630 / 0.1090\n",
      "[17/25][34/79] Loss_D: 0.8220 Loss_G: 2.3681 D(x): 0.6995 D(G(z)): 0.3240 / 0.1130\n",
      "[17/25][35/79] Loss_D: 0.5349 Loss_G: 2.2492 D(x): 0.7373 D(G(z)): 0.1676 / 0.1300\n",
      "[17/25][36/79] Loss_D: 0.4866 Loss_G: 3.1901 D(x): 0.8858 D(G(z)): 0.2848 / 0.0524\n",
      "[17/25][37/79] Loss_D: 0.5410 Loss_G: 2.2545 D(x): 0.6900 D(G(z)): 0.1231 / 0.1301\n",
      "[17/25][38/79] Loss_D: 0.5712 Loss_G: 2.3286 D(x): 0.7991 D(G(z)): 0.2650 / 0.1186\n",
      "[17/25][39/79] Loss_D: 0.6931 Loss_G: 3.8583 D(x): 0.8409 D(G(z)): 0.3650 / 0.0302\n",
      "[17/25][40/79] Loss_D: 1.1098 Loss_G: 1.1088 D(x): 0.4100 D(G(z)): 0.0870 / 0.3891\n",
      "[17/25][41/79] Loss_D: 1.1100 Loss_G: 2.9308 D(x): 0.8021 D(G(z)): 0.5434 / 0.0691\n",
      "[17/25][42/79] Loss_D: 0.6480 Loss_G: 2.7299 D(x): 0.6561 D(G(z)): 0.1433 / 0.0866\n",
      "[17/25][43/79] Loss_D: 0.4808 Loss_G: 2.7342 D(x): 0.8199 D(G(z)): 0.2172 / 0.0848\n",
      "[17/25][44/79] Loss_D: 0.5067 Loss_G: 2.7350 D(x): 0.7694 D(G(z)): 0.1745 / 0.0869\n",
      "[17/25][45/79] Loss_D: 0.6260 Loss_G: 2.4113 D(x): 0.7366 D(G(z)): 0.2237 / 0.1118\n",
      "[17/25][46/79] Loss_D: 0.5066 Loss_G: 3.4566 D(x): 0.8662 D(G(z)): 0.2784 / 0.0441\n",
      "[17/25][47/79] Loss_D: 0.4437 Loss_G: 3.0635 D(x): 0.7570 D(G(z)): 0.1152 / 0.0735\n",
      "[17/25][48/79] Loss_D: 0.2976 Loss_G: 2.7864 D(x): 0.8562 D(G(z)): 0.1196 / 0.0766\n",
      "[17/25][49/79] Loss_D: 0.4633 Loss_G: 3.8083 D(x): 0.8908 D(G(z)): 0.2717 / 0.0325\n",
      "[17/25][50/79] Loss_D: 0.9780 Loss_G: 1.3047 D(x): 0.5127 D(G(z)): 0.1502 / 0.3176\n",
      "[17/25][51/79] Loss_D: 1.1936 Loss_G: 4.6615 D(x): 0.8717 D(G(z)): 0.6038 / 0.0174\n",
      "[17/25][52/79] Loss_D: 0.7964 Loss_G: 2.4126 D(x): 0.5669 D(G(z)): 0.0553 / 0.1327\n",
      "[17/25][53/79] Loss_D: 0.7976 Loss_G: 4.0888 D(x): 0.8242 D(G(z)): 0.3980 / 0.0236\n",
      "[17/25][54/79] Loss_D: 0.4657 Loss_G: 2.9098 D(x): 0.7318 D(G(z)): 0.0985 / 0.0808\n",
      "[17/25][55/79] Loss_D: 0.6019 Loss_G: 2.7799 D(x): 0.8090 D(G(z)): 0.2893 / 0.0776\n",
      "[17/25][56/79] Loss_D: 0.4930 Loss_G: 4.1527 D(x): 0.8755 D(G(z)): 0.2778 / 0.0215\n",
      "[17/25][57/79] Loss_D: 1.4100 Loss_G: 0.8672 D(x): 0.3249 D(G(z)): 0.0879 / 0.4453\n",
      "[17/25][58/79] Loss_D: 1.2432 Loss_G: 4.6457 D(x): 0.9264 D(G(z)): 0.6516 / 0.0135\n",
      "[17/25][59/79] Loss_D: 1.0918 Loss_G: 2.3652 D(x): 0.3989 D(G(z)): 0.0492 / 0.1252\n",
      "[17/25][60/79] Loss_D: 0.5275 Loss_G: 2.2829 D(x): 0.8428 D(G(z)): 0.2589 / 0.1462\n",
      "[17/25][61/79] Loss_D: 0.4777 Loss_G: 4.0896 D(x): 0.9765 D(G(z)): 0.3274 / 0.0267\n",
      "[17/25][62/79] Loss_D: 0.4382 Loss_G: 3.3369 D(x): 0.7476 D(G(z)): 0.0851 / 0.0514\n",
      "[17/25][63/79] Loss_D: 0.5568 Loss_G: 2.1227 D(x): 0.7451 D(G(z)): 0.1361 / 0.1690\n",
      "[17/25][64/79] Loss_D: 0.5748 Loss_G: 3.4144 D(x): 0.9527 D(G(z)): 0.3791 / 0.0450\n",
      "[17/25][65/79] Loss_D: 0.6283 Loss_G: 2.5184 D(x): 0.6487 D(G(z)): 0.1281 / 0.1064\n",
      "[17/25][66/79] Loss_D: 0.7710 Loss_G: 2.4281 D(x): 0.7688 D(G(z)): 0.3287 / 0.1197\n",
      "[17/25][67/79] Loss_D: 0.3221 Loss_G: 3.4164 D(x): 0.8950 D(G(z)): 0.1769 / 0.0417\n",
      "[17/25][68/79] Loss_D: 0.7805 Loss_G: 1.6420 D(x): 0.5583 D(G(z)): 0.1136 / 0.2389\n",
      "[17/25][69/79] Loss_D: 0.9011 Loss_G: 3.0767 D(x): 0.8584 D(G(z)): 0.4844 / 0.0617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/25][70/79] Loss_D: 0.4569 Loss_G: 3.2388 D(x): 0.7781 D(G(z)): 0.1556 / 0.0545\n",
      "[17/25][71/79] Loss_D: 0.3456 Loss_G: 3.1112 D(x): 0.8261 D(G(z)): 0.1232 / 0.0596\n",
      "[17/25][72/79] Loss_D: 0.5501 Loss_G: 1.9836 D(x): 0.7101 D(G(z)): 0.1459 / 0.1725\n",
      "[17/25][73/79] Loss_D: 0.6263 Loss_G: 3.7563 D(x): 0.8953 D(G(z)): 0.3697 / 0.0310\n",
      "[17/25][74/79] Loss_D: 0.2967 Loss_G: 3.8983 D(x): 0.8009 D(G(z)): 0.0504 / 0.0289\n",
      "[17/25][75/79] Loss_D: 0.2082 Loss_G: 3.2891 D(x): 0.9021 D(G(z)): 0.0928 / 0.0482\n",
      "[17/25][76/79] Loss_D: 0.2759 Loss_G: 3.0172 D(x): 0.8813 D(G(z)): 0.1308 / 0.0651\n",
      "[17/25][77/79] Loss_D: 0.5359 Loss_G: 2.0758 D(x): 0.7237 D(G(z)): 0.1482 / 0.1637\n",
      "[17/25][78/79] Loss_D: 0.6124 Loss_G: 3.2345 D(x): 0.7787 D(G(z)): 0.2597 / 0.0432\n",
      "[18/25][0/79] Loss_D: 0.3681 Loss_G: 4.1049 D(x): 0.9443 D(G(z)): 0.2496 / 0.0238\n",
      "[18/25][1/79] Loss_D: 0.4374 Loss_G: 3.1694 D(x): 0.7129 D(G(z)): 0.0468 / 0.0615\n",
      "[18/25][2/79] Loss_D: 0.2950 Loss_G: 3.3164 D(x): 0.9620 D(G(z)): 0.2148 / 0.0498\n",
      "[18/25][3/79] Loss_D: 0.3226 Loss_G: 3.1362 D(x): 0.8432 D(G(z)): 0.1229 / 0.0579\n",
      "[18/25][4/79] Loss_D: 0.3718 Loss_G: 2.9218 D(x): 0.8278 D(G(z)): 0.1500 / 0.0766\n",
      "[18/25][5/79] Loss_D: 0.3145 Loss_G: 3.4122 D(x): 0.9055 D(G(z)): 0.1814 / 0.0461\n",
      "[18/25][6/79] Loss_D: 0.5635 Loss_G: 1.7654 D(x): 0.6552 D(G(z)): 0.0814 / 0.2111\n",
      "[18/25][7/79] Loss_D: 0.5270 Loss_G: 4.1707 D(x): 0.9655 D(G(z)): 0.3548 / 0.0219\n",
      "[18/25][8/79] Loss_D: 0.3965 Loss_G: 4.0416 D(x): 0.8356 D(G(z)): 0.1631 / 0.0248\n",
      "[18/25][9/79] Loss_D: 0.6996 Loss_G: 1.8642 D(x): 0.6192 D(G(z)): 0.1270 / 0.2043\n",
      "[18/25][10/79] Loss_D: 1.3943 Loss_G: 6.9940 D(x): 0.8763 D(G(z)): 0.6637 / 0.0019\n",
      "[18/25][11/79] Loss_D: 0.9958 Loss_G: 3.1683 D(x): 0.4416 D(G(z)): 0.0210 / 0.0731\n",
      "[18/25][12/79] Loss_D: 0.5333 Loss_G: 1.6339 D(x): 0.7173 D(G(z)): 0.1348 / 0.2568\n",
      "[18/25][13/79] Loss_D: 1.4144 Loss_G: 4.8758 D(x): 0.9146 D(G(z)): 0.6502 / 0.0133\n",
      "[18/25][14/79] Loss_D: 0.8094 Loss_G: 2.6865 D(x): 0.5574 D(G(z)): 0.0617 / 0.0974\n",
      "[18/25][15/79] Loss_D: 0.5237 Loss_G: 2.7430 D(x): 0.8475 D(G(z)): 0.2404 / 0.0917\n",
      "[18/25][16/79] Loss_D: 0.3687 Loss_G: 4.1317 D(x): 0.8729 D(G(z)): 0.1856 / 0.0233\n",
      "[18/25][17/79] Loss_D: 0.5025 Loss_G: 2.6924 D(x): 0.7175 D(G(z)): 0.1107 / 0.0953\n",
      "[18/25][18/79] Loss_D: 0.5926 Loss_G: 4.0753 D(x): 0.8281 D(G(z)): 0.3029 / 0.0256\n",
      "[18/25][19/79] Loss_D: 0.3614 Loss_G: 3.2531 D(x): 0.7850 D(G(z)): 0.0914 / 0.0585\n",
      "[18/25][20/79] Loss_D: 0.4641 Loss_G: 2.1145 D(x): 0.7354 D(G(z)): 0.1080 / 0.1550\n",
      "[18/25][21/79] Loss_D: 0.5021 Loss_G: 3.6907 D(x): 0.9449 D(G(z)): 0.3301 / 0.0376\n",
      "[18/25][22/79] Loss_D: 0.4799 Loss_G: 2.8687 D(x): 0.7410 D(G(z)): 0.1274 / 0.0806\n",
      "[18/25][23/79] Loss_D: 0.4722 Loss_G: 4.0258 D(x): 0.8882 D(G(z)): 0.2656 / 0.0285\n",
      "[18/25][24/79] Loss_D: 0.5075 Loss_G: 3.5032 D(x): 0.7897 D(G(z)): 0.1985 / 0.0463\n",
      "[18/25][25/79] Loss_D: 0.3858 Loss_G: 2.8697 D(x): 0.7831 D(G(z)): 0.1045 / 0.0832\n",
      "[18/25][26/79] Loss_D: 0.5980 Loss_G: 2.5926 D(x): 0.7759 D(G(z)): 0.2317 / 0.1032\n",
      "[18/25][27/79] Loss_D: 0.5121 Loss_G: 4.3419 D(x): 0.8756 D(G(z)): 0.2824 / 0.0196\n",
      "[18/25][28/79] Loss_D: 0.6804 Loss_G: 3.0729 D(x): 0.6612 D(G(z)): 0.1738 / 0.0617\n",
      "[18/25][29/79] Loss_D: 0.7413 Loss_G: 1.9959 D(x): 0.6613 D(G(z)): 0.2228 / 0.1611\n",
      "[18/25][30/79] Loss_D: 0.8714 Loss_G: 4.9487 D(x): 0.9088 D(G(z)): 0.4851 / 0.0119\n",
      "[18/25][31/79] Loss_D: 1.3191 Loss_G: 0.5972 D(x): 0.3684 D(G(z)): 0.0626 / 0.5927\n",
      "[18/25][32/79] Loss_D: 1.5406 Loss_G: 5.7626 D(x): 0.9588 D(G(z)): 0.7163 / 0.0054\n",
      "[18/25][33/79] Loss_D: 1.5459 Loss_G: 2.4204 D(x): 0.2882 D(G(z)): 0.0228 / 0.1399\n",
      "[18/25][34/79] Loss_D: 0.5989 Loss_G: 3.0791 D(x): 0.8713 D(G(z)): 0.3193 / 0.0694\n",
      "[18/25][35/79] Loss_D: 0.6507 Loss_G: 3.2737 D(x): 0.7347 D(G(z)): 0.2412 / 0.0540\n",
      "[18/25][36/79] Loss_D: 0.5078 Loss_G: 3.2770 D(x): 0.7666 D(G(z)): 0.1749 / 0.0516\n",
      "[18/25][37/79] Loss_D: 0.4444 Loss_G: 3.4214 D(x): 0.8368 D(G(z)): 0.2079 / 0.0465\n",
      "[18/25][38/79] Loss_D: 0.5771 Loss_G: 2.9433 D(x): 0.7594 D(G(z)): 0.2197 / 0.0771\n",
      "[18/25][39/79] Loss_D: 0.5031 Loss_G: 2.7515 D(x): 0.7585 D(G(z)): 0.1673 / 0.0813\n",
      "[18/25][40/79] Loss_D: 0.5229 Loss_G: 4.5005 D(x): 0.9195 D(G(z)): 0.3135 / 0.0162\n",
      "[18/25][41/79] Loss_D: 0.4137 Loss_G: 3.6273 D(x): 0.7431 D(G(z)): 0.0519 / 0.0417\n",
      "[18/25][42/79] Loss_D: 0.4454 Loss_G: 2.2052 D(x): 0.7758 D(G(z)): 0.1503 / 0.1354\n",
      "[18/25][43/79] Loss_D: 0.5689 Loss_G: 3.9691 D(x): 0.9074 D(G(z)): 0.3428 / 0.0276\n",
      "[18/25][44/79] Loss_D: 1.0027 Loss_G: 1.6373 D(x): 0.4666 D(G(z)): 0.0757 / 0.2702\n",
      "[18/25][45/79] Loss_D: 1.0748 Loss_G: 4.5487 D(x): 0.9503 D(G(z)): 0.5956 / 0.0166\n",
      "[18/25][46/79] Loss_D: 0.9157 Loss_G: 2.9730 D(x): 0.4991 D(G(z)): 0.0337 / 0.0779\n",
      "[18/25][47/79] Loss_D: 0.4082 Loss_G: 2.4023 D(x): 0.8556 D(G(z)): 0.1984 / 0.1245\n",
      "[18/25][48/79] Loss_D: 0.4074 Loss_G: 3.4794 D(x): 0.9230 D(G(z)): 0.2377 / 0.0521\n",
      "[18/25][49/79] Loss_D: 0.2998 Loss_G: 3.7144 D(x): 0.9008 D(G(z)): 0.1412 / 0.0405\n",
      "[18/25][50/79] Loss_D: 0.3499 Loss_G: 3.2899 D(x): 0.8243 D(G(z)): 0.1187 / 0.0545\n",
      "[18/25][51/79] Loss_D: 0.6540 Loss_G: 2.3949 D(x): 0.7516 D(G(z)): 0.2439 / 0.1192\n",
      "[18/25][52/79] Loss_D: 0.6930 Loss_G: 2.1861 D(x): 0.7200 D(G(z)): 0.2561 / 0.1455\n",
      "[18/25][53/79] Loss_D: 1.0131 Loss_G: 3.9453 D(x): 0.8120 D(G(z)): 0.4902 / 0.0299\n",
      "[18/25][54/79] Loss_D: 1.8471 Loss_G: 1.0530 D(x): 0.2299 D(G(z)): 0.0456 / 0.3907\n",
      "[18/25][55/79] Loss_D: 1.2681 Loss_G: 3.5371 D(x): 0.9374 D(G(z)): 0.6507 / 0.0442\n",
      "[18/25][56/79] Loss_D: 0.2764 Loss_G: 4.7163 D(x): 0.8846 D(G(z)): 0.1154 / 0.0147\n",
      "[18/25][57/79] Loss_D: 0.6605 Loss_G: 2.8287 D(x): 0.5879 D(G(z)): 0.0309 / 0.0896\n",
      "[18/25][58/79] Loss_D: 0.6341 Loss_G: 1.6391 D(x): 0.7616 D(G(z)): 0.2196 / 0.2461\n",
      "[18/25][59/79] Loss_D: 0.6464 Loss_G: 3.6479 D(x): 0.9497 D(G(z)): 0.4021 / 0.0420\n",
      "[18/25][60/79] Loss_D: 0.2428 Loss_G: 4.5936 D(x): 0.9236 D(G(z)): 0.1317 / 0.0156\n",
      "[18/25][61/79] Loss_D: 0.8804 Loss_G: 1.8588 D(x): 0.5386 D(G(z)): 0.0467 / 0.2057\n",
      "[18/25][62/79] Loss_D: 0.6479 Loss_G: 3.0253 D(x): 0.8959 D(G(z)): 0.3802 / 0.0640\n",
      "[18/25][63/79] Loss_D: 0.6366 Loss_G: 3.6252 D(x): 0.7620 D(G(z)): 0.2467 / 0.0362\n",
      "[18/25][64/79] Loss_D: 0.4296 Loss_G: 2.8239 D(x): 0.7648 D(G(z)): 0.1164 / 0.0824\n",
      "[18/25][65/79] Loss_D: 0.5369 Loss_G: 2.4870 D(x): 0.7879 D(G(z)): 0.2306 / 0.1058\n",
      "[18/25][66/79] Loss_D: 0.6480 Loss_G: 3.6020 D(x): 0.8400 D(G(z)): 0.3303 / 0.0390\n",
      "[18/25][67/79] Loss_D: 0.2035 Loss_G: 4.3258 D(x): 0.9339 D(G(z)): 0.1200 / 0.0188\n",
      "[18/25][68/79] Loss_D: 1.7866 Loss_G: 0.5822 D(x): 0.2998 D(G(z)): 0.2547 / 0.5870\n",
      "[18/25][69/79] Loss_D: 1.4275 Loss_G: 3.3991 D(x): 0.8088 D(G(z)): 0.6548 / 0.0485\n",
      "[18/25][70/79] Loss_D: 1.0819 Loss_G: 3.1147 D(x): 0.5527 D(G(z)): 0.2704 / 0.0657\n",
      "[18/25][71/79] Loss_D: 0.5443 Loss_G: 4.0085 D(x): 0.8697 D(G(z)): 0.2972 / 0.0270\n",
      "[18/25][72/79] Loss_D: 0.7201 Loss_G: 1.6927 D(x): 0.5682 D(G(z)): 0.0682 / 0.2168\n",
      "[18/25][73/79] Loss_D: 0.7615 Loss_G: 2.9832 D(x): 0.8769 D(G(z)): 0.4335 / 0.0639\n",
      "[18/25][74/79] Loss_D: 0.4407 Loss_G: 3.7601 D(x): 0.8376 D(G(z)): 0.2070 / 0.0363\n",
      "[18/25][75/79] Loss_D: 0.5148 Loss_G: 2.4989 D(x): 0.7082 D(G(z)): 0.1164 / 0.1145\n",
      "[18/25][76/79] Loss_D: 0.9631 Loss_G: 2.1515 D(x): 0.7210 D(G(z)): 0.4102 / 0.1510\n",
      "[18/25][77/79] Loss_D: 1.1157 Loss_G: 1.3500 D(x): 0.5455 D(G(z)): 0.3160 / 0.3011\n",
      "[18/25][78/79] Loss_D: 1.2485 Loss_G: 3.7813 D(x): 0.7153 D(G(z)): 0.5180 / 0.0633\n",
      "[19/25][0/79] Loss_D: 0.7459 Loss_G: 3.5807 D(x): 0.7657 D(G(z)): 0.3079 / 0.0426\n",
      "[19/25][1/79] Loss_D: 0.6380 Loss_G: 2.3911 D(x): 0.6833 D(G(z)): 0.1579 / 0.1320\n",
      "[19/25][2/79] Loss_D: 0.5336 Loss_G: 2.8640 D(x): 0.8097 D(G(z)): 0.2379 / 0.0829\n",
      "[19/25][3/79] Loss_D: 0.6844 Loss_G: 1.8497 D(x): 0.7110 D(G(z)): 0.2334 / 0.1975\n",
      "[19/25][4/79] Loss_D: 0.7867 Loss_G: 3.0537 D(x): 0.7489 D(G(z)): 0.3480 / 0.0669\n",
      "[19/25][5/79] Loss_D: 0.6342 Loss_G: 3.0997 D(x): 0.7548 D(G(z)): 0.2485 / 0.0647\n",
      "[19/25][6/79] Loss_D: 0.5052 Loss_G: 2.4006 D(x): 0.7409 D(G(z)): 0.1583 / 0.1164\n",
      "[19/25][7/79] Loss_D: 0.8113 Loss_G: 2.9198 D(x): 0.7137 D(G(z)): 0.3246 / 0.0758\n",
      "[19/25][8/79] Loss_D: 0.8643 Loss_G: 1.6540 D(x): 0.6025 D(G(z)): 0.2273 / 0.2287\n",
      "[19/25][9/79] Loss_D: 0.8067 Loss_G: 4.7614 D(x): 0.9038 D(G(z)): 0.4664 / 0.0124\n",
      "[19/25][10/79] Loss_D: 1.2458 Loss_G: 1.7048 D(x): 0.3709 D(G(z)): 0.0437 / 0.2131\n",
      "[19/25][11/79] Loss_D: 0.6951 Loss_G: 2.0871 D(x): 0.8000 D(G(z)): 0.3357 / 0.1577\n",
      "[19/25][12/79] Loss_D: 0.4200 Loss_G: 3.5235 D(x): 0.8969 D(G(z)): 0.2412 / 0.0418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/25][13/79] Loss_D: 1.0500 Loss_G: 1.0736 D(x): 0.4660 D(G(z)): 0.1233 / 0.3895\n",
      "[19/25][14/79] Loss_D: 0.9889 Loss_G: 4.1015 D(x): 0.9580 D(G(z)): 0.5619 / 0.0299\n",
      "[19/25][15/79] Loss_D: 0.5586 Loss_G: 2.5144 D(x): 0.6482 D(G(z)): 0.0626 / 0.1141\n",
      "[19/25][16/79] Loss_D: 0.7441 Loss_G: 1.5049 D(x): 0.6415 D(G(z)): 0.1971 / 0.2704\n",
      "[19/25][17/79] Loss_D: 0.7648 Loss_G: 4.4436 D(x): 0.8987 D(G(z)): 0.4335 / 0.0183\n",
      "[19/25][18/79] Loss_D: 0.6485 Loss_G: 2.5938 D(x): 0.6027 D(G(z)): 0.0572 / 0.1152\n",
      "[19/25][19/79] Loss_D: 0.6273 Loss_G: 2.9990 D(x): 0.8961 D(G(z)): 0.3600 / 0.0678\n",
      "[19/25][20/79] Loss_D: 0.4308 Loss_G: 4.3653 D(x): 0.8900 D(G(z)): 0.2399 / 0.0198\n",
      "[19/25][21/79] Loss_D: 1.0396 Loss_G: 1.6117 D(x): 0.4322 D(G(z)): 0.0760 / 0.2529\n",
      "[19/25][22/79] Loss_D: 0.8525 Loss_G: 3.8973 D(x): 0.9263 D(G(z)): 0.4820 / 0.0304\n",
      "[19/25][23/79] Loss_D: 1.1635 Loss_G: 1.5689 D(x): 0.4035 D(G(z)): 0.1075 / 0.2536\n",
      "[19/25][24/79] Loss_D: 0.6731 Loss_G: 2.6878 D(x): 0.8917 D(G(z)): 0.3862 / 0.0901\n",
      "[19/25][25/79] Loss_D: 0.4833 Loss_G: 4.1640 D(x): 0.9188 D(G(z)): 0.3073 / 0.0226\n",
      "[19/25][26/79] Loss_D: 0.8140 Loss_G: 2.1111 D(x): 0.5608 D(G(z)): 0.1178 / 0.1561\n",
      "[19/25][27/79] Loss_D: 0.4411 Loss_G: 3.0743 D(x): 0.9322 D(G(z)): 0.2923 / 0.0617\n",
      "[19/25][28/79] Loss_D: 0.6703 Loss_G: 2.2708 D(x): 0.6568 D(G(z)): 0.1304 / 0.1369\n",
      "[19/25][29/79] Loss_D: 0.5294 Loss_G: 2.1971 D(x): 0.7850 D(G(z)): 0.2081 / 0.1417\n",
      "[19/25][30/79] Loss_D: 0.7366 Loss_G: 4.7555 D(x): 0.9315 D(G(z)): 0.4507 / 0.0130\n",
      "[19/25][31/79] Loss_D: 0.5107 Loss_G: 3.7003 D(x): 0.6633 D(G(z)): 0.0441 / 0.0410\n",
      "[19/25][32/79] Loss_D: 0.3543 Loss_G: 2.4661 D(x): 0.7867 D(G(z)): 0.0829 / 0.1244\n",
      "[19/25][33/79] Loss_D: 0.6588 Loss_G: 2.5092 D(x): 0.8067 D(G(z)): 0.2996 / 0.1169\n",
      "[19/25][34/79] Loss_D: 0.4289 Loss_G: 3.8990 D(x): 0.9224 D(G(z)): 0.2642 / 0.0307\n",
      "[19/25][35/79] Loss_D: 0.3849 Loss_G: 3.3340 D(x): 0.8015 D(G(z)): 0.1341 / 0.0478\n",
      "[19/25][36/79] Loss_D: 1.4305 Loss_G: 0.3535 D(x): 0.3499 D(G(z)): 0.1886 / 0.7300\n",
      "[19/25][37/79] Loss_D: 2.7960 Loss_G: 4.0397 D(x): 0.9819 D(G(z)): 0.9055 / 0.0362\n",
      "[19/25][38/79] Loss_D: 0.6892 Loss_G: 2.4831 D(x): 0.6097 D(G(z)): 0.0836 / 0.1236\n",
      "[19/25][39/79] Loss_D: 0.7201 Loss_G: 1.2492 D(x): 0.6756 D(G(z)): 0.2111 / 0.3446\n",
      "[19/25][40/79] Loss_D: 1.5726 Loss_G: 3.4726 D(x): 0.7933 D(G(z)): 0.6587 / 0.0507\n",
      "[19/25][41/79] Loss_D: 1.9872 Loss_G: 0.8021 D(x): 0.2693 D(G(z)): 0.1177 / 0.5037\n",
      "[19/25][42/79] Loss_D: 1.6102 Loss_G: 3.1101 D(x): 0.8760 D(G(z)): 0.6904 / 0.0599\n",
      "[19/25][43/79] Loss_D: 1.2201 Loss_G: 1.8181 D(x): 0.4330 D(G(z)): 0.1642 / 0.2087\n",
      "[19/25][44/79] Loss_D: 1.1958 Loss_G: 1.3545 D(x): 0.5696 D(G(z)): 0.3838 / 0.2876\n",
      "[19/25][45/79] Loss_D: 0.8054 Loss_G: 3.4368 D(x): 0.8231 D(G(z)): 0.4201 / 0.0408\n",
      "[19/25][46/79] Loss_D: 1.2619 Loss_G: 1.1286 D(x): 0.3747 D(G(z)): 0.0906 / 0.3652\n",
      "[19/25][47/79] Loss_D: 0.9682 Loss_G: 3.0030 D(x): 0.9001 D(G(z)): 0.5329 / 0.0683\n",
      "[19/25][48/79] Loss_D: 0.7909 Loss_G: 2.3724 D(x): 0.5950 D(G(z)): 0.1628 / 0.1267\n",
      "[19/25][49/79] Loss_D: 0.7161 Loss_G: 1.8020 D(x): 0.6991 D(G(z)): 0.2504 / 0.1892\n",
      "[19/25][50/79] Loss_D: 0.7182 Loss_G: 2.5285 D(x): 0.7810 D(G(z)): 0.3409 / 0.0943\n",
      "[19/25][51/79] Loss_D: 0.6020 Loss_G: 2.4417 D(x): 0.7230 D(G(z)): 0.1918 / 0.1128\n",
      "[19/25][52/79] Loss_D: 0.9055 Loss_G: 2.5387 D(x): 0.6947 D(G(z)): 0.3601 / 0.0959\n",
      "[19/25][53/79] Loss_D: 0.6054 Loss_G: 2.7239 D(x): 0.7632 D(G(z)): 0.2413 / 0.0852\n",
      "[19/25][54/79] Loss_D: 0.8361 Loss_G: 1.7867 D(x): 0.6079 D(G(z)): 0.2012 / 0.2074\n",
      "[19/25][55/79] Loss_D: 1.0554 Loss_G: 3.0937 D(x): 0.8175 D(G(z)): 0.5277 / 0.0610\n",
      "[19/25][56/79] Loss_D: 0.6109 Loss_G: 3.2271 D(x): 0.7009 D(G(z)): 0.1782 / 0.0538\n",
      "[19/25][57/79] Loss_D: 0.6997 Loss_G: 2.4100 D(x): 0.6985 D(G(z)): 0.2153 / 0.1228\n",
      "[19/25][58/79] Loss_D: 1.2477 Loss_G: 2.6252 D(x): 0.6098 D(G(z)): 0.4115 / 0.0914\n",
      "[19/25][59/79] Loss_D: 0.6677 Loss_G: 2.5135 D(x): 0.6936 D(G(z)): 0.1941 / 0.1148\n",
      "[19/25][60/79] Loss_D: 0.7273 Loss_G: 2.7387 D(x): 0.7828 D(G(z)): 0.3386 / 0.0865\n",
      "[19/25][61/79] Loss_D: 0.7527 Loss_G: 2.8063 D(x): 0.7137 D(G(z)): 0.2906 / 0.0751\n",
      "[19/25][62/79] Loss_D: 1.2889 Loss_G: 2.2655 D(x): 0.5845 D(G(z)): 0.4242 / 0.1280\n",
      "[19/25][63/79] Loss_D: 1.2088 Loss_G: 1.1694 D(x): 0.4858 D(G(z)): 0.2929 / 0.3611\n",
      "[19/25][64/79] Loss_D: 0.8040 Loss_G: 3.5730 D(x): 0.9383 D(G(z)): 0.4805 / 0.0387\n",
      "[19/25][65/79] Loss_D: 1.1120 Loss_G: 1.4268 D(x): 0.4756 D(G(z)): 0.1867 / 0.2801\n",
      "[19/25][66/79] Loss_D: 0.9762 Loss_G: 2.7025 D(x): 0.7884 D(G(z)): 0.4707 / 0.0953\n",
      "[19/25][67/79] Loss_D: 1.0323 Loss_G: 1.9871 D(x): 0.5512 D(G(z)): 0.2565 / 0.1811\n",
      "[19/25][68/79] Loss_D: 0.6723 Loss_G: 3.1676 D(x): 0.8669 D(G(z)): 0.3837 / 0.0537\n",
      "[19/25][69/79] Loss_D: 0.6581 Loss_G: 2.6121 D(x): 0.6837 D(G(z)): 0.1873 / 0.0942\n",
      "[19/25][70/79] Loss_D: 1.1425 Loss_G: 1.4063 D(x): 0.5243 D(G(z)): 0.2962 / 0.3004\n",
      "[19/25][71/79] Loss_D: 0.8425 Loss_G: 2.0540 D(x): 0.7160 D(G(z)): 0.3566 / 0.1624\n",
      "[19/25][72/79] Loss_D: 0.6759 Loss_G: 3.5156 D(x): 0.9159 D(G(z)): 0.4201 / 0.0438\n",
      "[19/25][73/79] Loss_D: 0.7477 Loss_G: 3.1139 D(x): 0.7287 D(G(z)): 0.2960 / 0.0576\n",
      "[19/25][74/79] Loss_D: 1.3651 Loss_G: 1.4369 D(x): 0.3817 D(G(z)): 0.1788 / 0.2898\n",
      "[19/25][75/79] Loss_D: 1.0041 Loss_G: 2.5403 D(x): 0.8131 D(G(z)): 0.4943 / 0.1051\n",
      "[19/25][76/79] Loss_D: 0.8341 Loss_G: 3.1898 D(x): 0.7245 D(G(z)): 0.3447 / 0.0592\n",
      "[19/25][77/79] Loss_D: 1.1504 Loss_G: 1.4590 D(x): 0.4395 D(G(z)): 0.1728 / 0.2624\n",
      "[19/25][78/79] Loss_D: 0.9021 Loss_G: 4.5035 D(x): 0.8827 D(G(z)): 0.5128 / 0.0166\n",
      "[20/25][0/79] Loss_D: 0.3099 Loss_G: 4.0458 D(x): 0.8577 D(G(z)): 0.1181 / 0.0366\n",
      "[20/25][1/79] Loss_D: 0.3942 Loss_G: 3.0644 D(x): 0.7756 D(G(z)): 0.0876 / 0.0738\n",
      "[20/25][2/79] Loss_D: 0.4918 Loss_G: 2.4910 D(x): 0.8079 D(G(z)): 0.2141 / 0.1160\n",
      "[20/25][3/79] Loss_D: 0.6811 Loss_G: 2.4075 D(x): 0.7470 D(G(z)): 0.2778 / 0.1258\n",
      "[20/25][4/79] Loss_D: 0.5485 Loss_G: 3.5423 D(x): 0.8844 D(G(z)): 0.3161 / 0.0453\n",
      "[20/25][5/79] Loss_D: 0.6813 Loss_G: 3.1610 D(x): 0.7786 D(G(z)): 0.3016 / 0.0613\n",
      "[20/25][6/79] Loss_D: 0.7452 Loss_G: 2.2468 D(x): 0.6224 D(G(z)): 0.1747 / 0.1449\n",
      "[20/25][7/79] Loss_D: 0.8500 Loss_G: 2.9633 D(x): 0.7536 D(G(z)): 0.3708 / 0.0715\n",
      "[20/25][8/79] Loss_D: 0.9071 Loss_G: 1.9238 D(x): 0.5801 D(G(z)): 0.2125 / 0.1830\n",
      "[20/25][9/79] Loss_D: 0.7954 Loss_G: 3.4804 D(x): 0.8322 D(G(z)): 0.4248 / 0.0402\n",
      "[20/25][10/79] Loss_D: 0.7778 Loss_G: 2.5394 D(x): 0.6036 D(G(z)): 0.1731 / 0.1118\n",
      "[20/25][11/79] Loss_D: 1.0411 Loss_G: 3.2054 D(x): 0.7053 D(G(z)): 0.4388 / 0.0560\n",
      "[20/25][12/79] Loss_D: 0.5873 Loss_G: 3.0783 D(x): 0.7141 D(G(z)): 0.1851 / 0.0679\n",
      "[20/25][13/79] Loss_D: 0.5158 Loss_G: 3.1363 D(x): 0.7883 D(G(z)): 0.2137 / 0.0640\n",
      "[20/25][14/79] Loss_D: 0.5561 Loss_G: 2.2376 D(x): 0.7040 D(G(z)): 0.1421 / 0.1285\n",
      "[20/25][15/79] Loss_D: 0.9995 Loss_G: 2.1853 D(x): 0.6739 D(G(z)): 0.3734 / 0.1396\n",
      "[20/25][16/79] Loss_D: 0.5552 Loss_G: 2.7833 D(x): 0.7720 D(G(z)): 0.2261 / 0.0780\n",
      "[20/25][17/79] Loss_D: 0.5417 Loss_G: 2.4375 D(x): 0.7562 D(G(z)): 0.1926 / 0.1165\n",
      "[20/25][18/79] Loss_D: 0.7042 Loss_G: 2.7349 D(x): 0.8040 D(G(z)): 0.3469 / 0.0850\n",
      "[20/25][19/79] Loss_D: 0.4990 Loss_G: 2.6654 D(x): 0.7753 D(G(z)): 0.1832 / 0.0937\n",
      "[20/25][20/79] Loss_D: 0.4138 Loss_G: 2.6816 D(x): 0.8323 D(G(z)): 0.1846 / 0.0924\n",
      "[20/25][21/79] Loss_D: 0.5846 Loss_G: 2.5267 D(x): 0.7823 D(G(z)): 0.2519 / 0.0992\n",
      "[20/25][22/79] Loss_D: 0.8878 Loss_G: 2.4398 D(x): 0.6666 D(G(z)): 0.3197 / 0.1188\n",
      "[20/25][23/79] Loss_D: 0.8767 Loss_G: 3.2170 D(x): 0.7577 D(G(z)): 0.3936 / 0.0556\n",
      "[20/25][24/79] Loss_D: 0.9265 Loss_G: 1.6644 D(x): 0.5087 D(G(z)): 0.1153 / 0.2299\n",
      "[20/25][25/79] Loss_D: 1.9117 Loss_G: 3.4012 D(x): 0.6518 D(G(z)): 0.7253 / 0.0455\n",
      "[20/25][26/79] Loss_D: 1.1224 Loss_G: 2.0450 D(x): 0.4365 D(G(z)): 0.1058 / 0.1797\n",
      "[20/25][27/79] Loss_D: 0.8106 Loss_G: 4.1692 D(x): 0.9489 D(G(z)): 0.4915 / 0.0254\n",
      "[20/25][28/79] Loss_D: 0.3225 Loss_G: 3.7446 D(x): 0.7925 D(G(z)): 0.0661 / 0.0353\n",
      "[20/25][29/79] Loss_D: 0.2689 Loss_G: 2.6377 D(x): 0.8544 D(G(z)): 0.0931 / 0.0900\n",
      "[20/25][30/79] Loss_D: 0.6867 Loss_G: 3.4774 D(x): 0.9131 D(G(z)): 0.4150 / 0.0422\n",
      "[20/25][31/79] Loss_D: 0.7735 Loss_G: 2.0491 D(x): 0.6042 D(G(z)): 0.1734 / 0.1576\n",
      "[20/25][32/79] Loss_D: 0.8959 Loss_G: 1.4769 D(x): 0.6164 D(G(z)): 0.2555 / 0.2785\n",
      "[20/25][33/79] Loss_D: 1.6975 Loss_G: 5.4117 D(x): 0.8658 D(G(z)): 0.7232 / 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/25][34/79] Loss_D: 2.5424 Loss_G: 1.0724 D(x): 0.1079 D(G(z)): 0.0142 / 0.4022\n",
      "[20/25][35/79] Loss_D: 1.6175 Loss_G: 5.2824 D(x): 0.9415 D(G(z)): 0.6991 / 0.0089\n",
      "[20/25][36/79] Loss_D: 1.4073 Loss_G: 1.3257 D(x): 0.3290 D(G(z)): 0.0332 / 0.3212\n",
      "[20/25][37/79] Loss_D: 1.4519 Loss_G: 3.0288 D(x): 0.8739 D(G(z)): 0.6571 / 0.0755\n",
      "[20/25][38/79] Loss_D: 1.1366 Loss_G: 2.8229 D(x): 0.5404 D(G(z)): 0.2965 / 0.0872\n",
      "[20/25][39/79] Loss_D: 1.0935 Loss_G: 1.0606 D(x): 0.4751 D(G(z)): 0.1448 / 0.4169\n",
      "[20/25][40/79] Loss_D: 1.1743 Loss_G: 2.5539 D(x): 0.8055 D(G(z)): 0.5469 / 0.1041\n",
      "[20/25][41/79] Loss_D: 0.6578 Loss_G: 2.4572 D(x): 0.6635 D(G(z)): 0.1661 / 0.1085\n",
      "[20/25][42/79] Loss_D: 0.6691 Loss_G: 2.6062 D(x): 0.7937 D(G(z)): 0.3006 / 0.0998\n",
      "[20/25][43/79] Loss_D: 0.5582 Loss_G: 2.3620 D(x): 0.7002 D(G(z)): 0.1183 / 0.1232\n",
      "[20/25][44/79] Loss_D: 0.8855 Loss_G: 2.0901 D(x): 0.7586 D(G(z)): 0.3976 / 0.1563\n",
      "[20/25][45/79] Loss_D: 0.7156 Loss_G: 2.5961 D(x): 0.7422 D(G(z)): 0.3011 / 0.0952\n",
      "[20/25][46/79] Loss_D: 0.6762 Loss_G: 2.4767 D(x): 0.7430 D(G(z)): 0.2645 / 0.1079\n",
      "[20/25][47/79] Loss_D: 1.0843 Loss_G: 1.0000 D(x): 0.4693 D(G(z)): 0.1584 / 0.4021\n",
      "[20/25][48/79] Loss_D: 1.2304 Loss_G: 2.8196 D(x): 0.8533 D(G(z)): 0.5941 / 0.0807\n",
      "[20/25][49/79] Loss_D: 0.8879 Loss_G: 2.3038 D(x): 0.5693 D(G(z)): 0.1865 / 0.1346\n",
      "[20/25][50/79] Loss_D: 0.7898 Loss_G: 2.0536 D(x): 0.6844 D(G(z)): 0.2885 / 0.1639\n",
      "[20/25][51/79] Loss_D: 0.6108 Loss_G: 2.5607 D(x): 0.7750 D(G(z)): 0.2584 / 0.1028\n",
      "[20/25][52/79] Loss_D: 0.6780 Loss_G: 2.2429 D(x): 0.7049 D(G(z)): 0.2273 / 0.1275\n",
      "[20/25][53/79] Loss_D: 0.6331 Loss_G: 2.6374 D(x): 0.7649 D(G(z)): 0.2646 / 0.0934\n",
      "[20/25][54/79] Loss_D: 0.6222 Loss_G: 2.3571 D(x): 0.7122 D(G(z)): 0.2101 / 0.1263\n",
      "[20/25][55/79] Loss_D: 0.5708 Loss_G: 2.7702 D(x): 0.7978 D(G(z)): 0.2488 / 0.0867\n",
      "[20/25][56/79] Loss_D: 0.5710 Loss_G: 2.3176 D(x): 0.7113 D(G(z)): 0.1652 / 0.1236\n",
      "[20/25][57/79] Loss_D: 0.5899 Loss_G: 2.8655 D(x): 0.8557 D(G(z)): 0.3192 / 0.0775\n",
      "[20/25][58/79] Loss_D: 0.8782 Loss_G: 2.9939 D(x): 0.7070 D(G(z)): 0.3633 / 0.0695\n",
      "[20/25][59/79] Loss_D: 1.1971 Loss_G: 1.7111 D(x): 0.4989 D(G(z)): 0.2872 / 0.2257\n",
      "[20/25][60/79] Loss_D: 0.6030 Loss_G: 2.5528 D(x): 0.8385 D(G(z)): 0.3146 / 0.0996\n",
      "[20/25][61/79] Loss_D: 0.7348 Loss_G: 2.6276 D(x): 0.7240 D(G(z)): 0.2833 / 0.0938\n",
      "[20/25][62/79] Loss_D: 0.4660 Loss_G: 3.3058 D(x): 0.8675 D(G(z)): 0.2395 / 0.0509\n",
      "[20/25][63/79] Loss_D: 0.5314 Loss_G: 2.7078 D(x): 0.7324 D(G(z)): 0.1588 / 0.0869\n",
      "[20/25][64/79] Loss_D: 0.6573 Loss_G: 2.7310 D(x): 0.7769 D(G(z)): 0.2701 / 0.0936\n",
      "[20/25][65/79] Loss_D: 0.8420 Loss_G: 2.3964 D(x): 0.6247 D(G(z)): 0.2432 / 0.1261\n",
      "[20/25][66/79] Loss_D: 0.7966 Loss_G: 2.3895 D(x): 0.7090 D(G(z)): 0.3143 / 0.1198\n",
      "[20/25][67/79] Loss_D: 0.5594 Loss_G: 3.2037 D(x): 0.8424 D(G(z)): 0.2782 / 0.0636\n",
      "[20/25][68/79] Loss_D: 0.2202 Loss_G: 3.7210 D(x): 0.9138 D(G(z)): 0.1142 / 0.0350\n",
      "[20/25][69/79] Loss_D: 0.5430 Loss_G: 2.4335 D(x): 0.6896 D(G(z)): 0.0900 / 0.1296\n",
      "[20/25][70/79] Loss_D: 0.6151 Loss_G: 2.2897 D(x): 0.8219 D(G(z)): 0.2947 / 0.1300\n",
      "[20/25][71/79] Loss_D: 0.5038 Loss_G: 3.0617 D(x): 0.8829 D(G(z)): 0.2850 / 0.0627\n",
      "[20/25][72/79] Loss_D: 0.6219 Loss_G: 2.1356 D(x): 0.6721 D(G(z)): 0.1567 / 0.1446\n",
      "[20/25][73/79] Loss_D: 0.7186 Loss_G: 3.0934 D(x): 0.8802 D(G(z)): 0.4100 / 0.0629\n",
      "[20/25][74/79] Loss_D: 0.6399 Loss_G: 2.9368 D(x): 0.7127 D(G(z)): 0.2150 / 0.0751\n",
      "[20/25][75/79] Loss_D: 0.6801 Loss_G: 2.2255 D(x): 0.7205 D(G(z)): 0.2295 / 0.1391\n",
      "[20/25][76/79] Loss_D: 0.6571 Loss_G: 3.1274 D(x): 0.8210 D(G(z)): 0.3425 / 0.0600\n",
      "[20/25][77/79] Loss_D: 1.0190 Loss_G: 1.5310 D(x): 0.5184 D(G(z)): 0.2283 / 0.2659\n",
      "[20/25][78/79] Loss_D: 0.7048 Loss_G: 4.0569 D(x): 0.7621 D(G(z)): 0.3127 / 0.0224\n",
      "[21/25][0/79] Loss_D: 0.8424 Loss_G: 4.1257 D(x): 0.8867 D(G(z)): 0.4387 / 0.0368\n",
      "[21/25][1/79] Loss_D: 0.9288 Loss_G: 2.2974 D(x): 0.5176 D(G(z)): 0.0883 / 0.1525\n",
      "[21/25][2/79] Loss_D: 1.1344 Loss_G: 1.8651 D(x): 0.6086 D(G(z)): 0.3762 / 0.2096\n",
      "[21/25][3/79] Loss_D: 1.1601 Loss_G: 3.8310 D(x): 0.7773 D(G(z)): 0.5117 / 0.0409\n",
      "[21/25][4/79] Loss_D: 1.0707 Loss_G: 1.2710 D(x): 0.4612 D(G(z)): 0.0854 / 0.3619\n",
      "[21/25][5/79] Loss_D: 1.4386 Loss_G: 4.6531 D(x): 0.9232 D(G(z)): 0.6740 / 0.0166\n",
      "[21/25][6/79] Loss_D: 0.9103 Loss_G: 2.8893 D(x): 0.4928 D(G(z)): 0.0447 / 0.0885\n",
      "[21/25][7/79] Loss_D: 0.5505 Loss_G: 1.5734 D(x): 0.7237 D(G(z)): 0.1385 / 0.2589\n",
      "[21/25][8/79] Loss_D: 0.8074 Loss_G: 2.8587 D(x): 0.8718 D(G(z)): 0.4492 / 0.0758\n",
      "[21/25][9/79] Loss_D: 0.8312 Loss_G: 2.2835 D(x): 0.6313 D(G(z)): 0.2229 / 0.1358\n",
      "[21/25][10/79] Loss_D: 0.7487 Loss_G: 2.3025 D(x): 0.7537 D(G(z)): 0.3097 / 0.1281\n",
      "[21/25][11/79] Loss_D: 0.5745 Loss_G: 3.1396 D(x): 0.8221 D(G(z)): 0.2684 / 0.0707\n",
      "[21/25][12/79] Loss_D: 0.6270 Loss_G: 2.0517 D(x): 0.6582 D(G(z)): 0.1421 / 0.1615\n",
      "[21/25][13/79] Loss_D: 1.0372 Loss_G: 2.2594 D(x): 0.7018 D(G(z)): 0.4282 / 0.1302\n",
      "[21/25][14/79] Loss_D: 0.4742 Loss_G: 2.6664 D(x): 0.8004 D(G(z)): 0.1899 / 0.0934\n",
      "[21/25][15/79] Loss_D: 0.6299 Loss_G: 2.4146 D(x): 0.7358 D(G(z)): 0.2326 / 0.1141\n",
      "[21/25][16/79] Loss_D: 0.8336 Loss_G: 1.8212 D(x): 0.6076 D(G(z)): 0.2359 / 0.1916\n",
      "[21/25][17/79] Loss_D: 0.9633 Loss_G: 2.5283 D(x): 0.7097 D(G(z)): 0.3856 / 0.1057\n",
      "[21/25][18/79] Loss_D: 1.0548 Loss_G: 3.3931 D(x): 0.7217 D(G(z)): 0.4548 / 0.0457\n",
      "[21/25][19/79] Loss_D: 0.8576 Loss_G: 1.8429 D(x): 0.5051 D(G(z)): 0.0575 / 0.1982\n",
      "[21/25][20/79] Loss_D: 0.7399 Loss_G: 2.3678 D(x): 0.8462 D(G(z)): 0.3880 / 0.1237\n",
      "[21/25][21/79] Loss_D: 0.5389 Loss_G: 3.1352 D(x): 0.8177 D(G(z)): 0.2568 / 0.0601\n",
      "[21/25][22/79] Loss_D: 0.5115 Loss_G: 2.3027 D(x): 0.6861 D(G(z)): 0.0720 / 0.1245\n",
      "[21/25][23/79] Loss_D: 0.5618 Loss_G: 2.4244 D(x): 0.8520 D(G(z)): 0.2969 / 0.1173\n",
      "[21/25][24/79] Loss_D: 0.4686 Loss_G: 3.0806 D(x): 0.8351 D(G(z)): 0.2201 / 0.0634\n",
      "[21/25][25/79] Loss_D: 0.7028 Loss_G: 2.1713 D(x): 0.7009 D(G(z)): 0.2244 / 0.1488\n",
      "[21/25][26/79] Loss_D: 0.6757 Loss_G: 3.4057 D(x): 0.8842 D(G(z)): 0.3704 / 0.0442\n",
      "[21/25][27/79] Loss_D: 0.6714 Loss_G: 2.4113 D(x): 0.6527 D(G(z)): 0.1442 / 0.1252\n",
      "[21/25][28/79] Loss_D: 0.7664 Loss_G: 1.8461 D(x): 0.6730 D(G(z)): 0.2374 / 0.1945\n",
      "[21/25][29/79] Loss_D: 0.9358 Loss_G: 4.1749 D(x): 0.8117 D(G(z)): 0.4608 / 0.0193\n",
      "[21/25][30/79] Loss_D: 0.7330 Loss_G: 2.0270 D(x): 0.5566 D(G(z)): 0.0671 / 0.1892\n",
      "[21/25][31/79] Loss_D: 0.7328 Loss_G: 3.0403 D(x): 0.8099 D(G(z)): 0.3354 / 0.0718\n",
      "[21/25][32/79] Loss_D: 0.4234 Loss_G: 3.1412 D(x): 0.8090 D(G(z)): 0.1738 / 0.0567\n",
      "[21/25][33/79] Loss_D: 0.4639 Loss_G: 2.7384 D(x): 0.7877 D(G(z)): 0.1679 / 0.0924\n",
      "[21/25][34/79] Loss_D: 0.3794 Loss_G: 3.5410 D(x): 0.9024 D(G(z)): 0.2159 / 0.0449\n",
      "[21/25][35/79] Loss_D: 0.5501 Loss_G: 1.9984 D(x): 0.6917 D(G(z)): 0.1156 / 0.1648\n",
      "[21/25][36/79] Loss_D: 0.8464 Loss_G: 4.2256 D(x): 0.8631 D(G(z)): 0.4507 / 0.0241\n",
      "[21/25][37/79] Loss_D: 0.4906 Loss_G: 3.2876 D(x): 0.7119 D(G(z)): 0.0971 / 0.0563\n",
      "[21/25][38/79] Loss_D: 0.6820 Loss_G: 1.9102 D(x): 0.6528 D(G(z)): 0.1638 / 0.1913\n",
      "[21/25][39/79] Loss_D: 0.9925 Loss_G: 4.5930 D(x): 0.9230 D(G(z)): 0.5263 / 0.0184\n",
      "[21/25][40/79] Loss_D: 0.7956 Loss_G: 2.5570 D(x): 0.5528 D(G(z)): 0.0945 / 0.1144\n",
      "[21/25][41/79] Loss_D: 0.9034 Loss_G: 3.5130 D(x): 0.8655 D(G(z)): 0.4658 / 0.0514\n",
      "[21/25][42/79] Loss_D: 0.6229 Loss_G: 2.5479 D(x): 0.6432 D(G(z)): 0.1083 / 0.1095\n",
      "[21/25][43/79] Loss_D: 0.4661 Loss_G: 2.9422 D(x): 0.8700 D(G(z)): 0.2499 / 0.0728\n",
      "[21/25][44/79] Loss_D: 0.5725 Loss_G: 3.5986 D(x): 0.7864 D(G(z)): 0.2417 / 0.0380\n",
      "[21/25][45/79] Loss_D: 0.6913 Loss_G: 2.7605 D(x): 0.7115 D(G(z)): 0.2434 / 0.0856\n",
      "[21/25][46/79] Loss_D: 0.5488 Loss_G: 2.1490 D(x): 0.7222 D(G(z)): 0.1505 / 0.1411\n",
      "[21/25][47/79] Loss_D: 1.1397 Loss_G: 3.7141 D(x): 0.7361 D(G(z)): 0.5027 / 0.0375\n",
      "[21/25][48/79] Loss_D: 0.8295 Loss_G: 1.8581 D(x): 0.5770 D(G(z)): 0.1548 / 0.1887\n",
      "[21/25][49/79] Loss_D: 0.7042 Loss_G: 2.5795 D(x): 0.7944 D(G(z)): 0.3315 / 0.0937\n",
      "[21/25][50/79] Loss_D: 0.6509 Loss_G: 3.6645 D(x): 0.8303 D(G(z)): 0.3261 / 0.0367\n",
      "[21/25][51/79] Loss_D: 0.9524 Loss_G: 1.1933 D(x): 0.4771 D(G(z)): 0.0751 / 0.3581\n",
      "[21/25][52/79] Loss_D: 1.2266 Loss_G: 3.8656 D(x): 0.8810 D(G(z)): 0.6012 / 0.0334\n",
      "[21/25][53/79] Loss_D: 0.7651 Loss_G: 2.3198 D(x): 0.5821 D(G(z)): 0.1059 / 0.1368\n",
      "[21/25][54/79] Loss_D: 0.4624 Loss_G: 3.4726 D(x): 0.9300 D(G(z)): 0.2935 / 0.0474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/25][55/79] Loss_D: 0.4378 Loss_G: 3.4845 D(x): 0.8073 D(G(z)): 0.1666 / 0.0434\n",
      "[21/25][56/79] Loss_D: 0.6355 Loss_G: 1.9032 D(x): 0.6372 D(G(z)): 0.1143 / 0.1862\n",
      "[21/25][57/79] Loss_D: 1.1388 Loss_G: 4.3053 D(x): 0.9218 D(G(z)): 0.5799 / 0.0261\n",
      "[21/25][58/79] Loss_D: 1.2304 Loss_G: 1.1510 D(x): 0.3974 D(G(z)): 0.0596 / 0.4041\n",
      "[21/25][59/79] Loss_D: 1.0751 Loss_G: 4.4885 D(x): 0.9576 D(G(z)): 0.5807 / 0.0205\n",
      "[21/25][60/79] Loss_D: 0.6506 Loss_G: 3.5503 D(x): 0.6220 D(G(z)): 0.0938 / 0.0462\n",
      "[21/25][61/79] Loss_D: 0.5187 Loss_G: 2.3466 D(x): 0.7429 D(G(z)): 0.1524 / 0.1285\n",
      "[21/25][62/79] Loss_D: 0.8093 Loss_G: 3.9133 D(x): 0.8171 D(G(z)): 0.3914 / 0.0325\n",
      "[21/25][63/79] Loss_D: 0.7560 Loss_G: 2.4582 D(x): 0.6277 D(G(z)): 0.1766 / 0.1253\n",
      "[21/25][64/79] Loss_D: 1.3282 Loss_G: 1.4582 D(x): 0.5098 D(G(z)): 0.3862 / 0.2728\n",
      "[21/25][65/79] Loss_D: 1.1513 Loss_G: 4.5298 D(x): 0.8352 D(G(z)): 0.5678 / 0.0170\n",
      "[21/25][66/79] Loss_D: 1.1949 Loss_G: 1.8522 D(x): 0.3967 D(G(z)): 0.0549 / 0.2038\n",
      "[21/25][67/79] Loss_D: 0.7641 Loss_G: 3.2760 D(x): 0.8804 D(G(z)): 0.4227 / 0.0577\n",
      "[21/25][68/79] Loss_D: 0.4575 Loss_G: 3.3526 D(x): 0.8105 D(G(z)): 0.1815 / 0.0567\n",
      "[21/25][69/79] Loss_D: 0.4462 Loss_G: 2.7334 D(x): 0.7951 D(G(z)): 0.1521 / 0.0874\n",
      "[21/25][70/79] Loss_D: 0.6544 Loss_G: 2.3168 D(x): 0.7198 D(G(z)): 0.2173 / 0.1345\n",
      "[21/25][71/79] Loss_D: 0.8013 Loss_G: 3.6316 D(x): 0.8206 D(G(z)): 0.3896 / 0.0372\n",
      "[21/25][72/79] Loss_D: 0.8589 Loss_G: 1.7700 D(x): 0.5449 D(G(z)): 0.1269 / 0.2213\n",
      "[21/25][73/79] Loss_D: 0.8163 Loss_G: 3.5834 D(x): 0.8588 D(G(z)): 0.4462 / 0.0409\n",
      "[21/25][74/79] Loss_D: 0.5739 Loss_G: 2.8869 D(x): 0.7020 D(G(z)): 0.1386 / 0.0778\n",
      "[21/25][75/79] Loss_D: 0.3896 Loss_G: 2.7554 D(x): 0.8183 D(G(z)): 0.1464 / 0.0894\n",
      "[21/25][76/79] Loss_D: 0.6645 Loss_G: 3.2335 D(x): 0.8238 D(G(z)): 0.3330 / 0.0570\n",
      "[21/25][77/79] Loss_D: 0.5180 Loss_G: 2.6640 D(x): 0.7342 D(G(z)): 0.1470 / 0.0925\n",
      "[21/25][78/79] Loss_D: 0.8164 Loss_G: 6.2870 D(x): 0.8199 D(G(z)): 0.4282 / 0.0030\n",
      "[22/25][0/79] Loss_D: 0.6988 Loss_G: 2.2554 D(x): 0.6090 D(G(z)): 0.0588 / 0.1706\n",
      "[22/25][1/79] Loss_D: 1.2380 Loss_G: 2.3768 D(x): 0.7332 D(G(z)): 0.5103 / 0.1374\n",
      "[22/25][2/79] Loss_D: 0.9824 Loss_G: 1.9865 D(x): 0.5856 D(G(z)): 0.2509 / 0.1858\n",
      "[22/25][3/79] Loss_D: 1.0449 Loss_G: 3.6427 D(x): 0.7884 D(G(z)): 0.4740 / 0.0378\n",
      "[22/25][4/79] Loss_D: 1.1693 Loss_G: 1.3441 D(x): 0.4239 D(G(z)): 0.1184 / 0.3301\n",
      "[22/25][5/79] Loss_D: 1.1599 Loss_G: 3.7312 D(x): 0.9067 D(G(z)): 0.5798 / 0.0372\n",
      "[22/25][6/79] Loss_D: 0.7324 Loss_G: 2.3870 D(x): 0.6018 D(G(z)): 0.0923 / 0.1487\n",
      "[22/25][7/79] Loss_D: 0.8495 Loss_G: 1.9765 D(x): 0.7411 D(G(z)): 0.3243 / 0.1974\n",
      "[22/25][8/79] Loss_D: 0.6442 Loss_G: 3.4470 D(x): 0.8594 D(G(z)): 0.3497 / 0.0441\n",
      "[22/25][9/79] Loss_D: 0.6433 Loss_G: 2.4062 D(x): 0.6353 D(G(z)): 0.0957 / 0.1269\n",
      "[22/25][10/79] Loss_D: 0.8035 Loss_G: 1.9685 D(x): 0.7151 D(G(z)): 0.3100 / 0.1748\n",
      "[22/25][11/79] Loss_D: 0.5327 Loss_G: 3.4456 D(x): 0.8832 D(G(z)): 0.3059 / 0.0444\n",
      "[22/25][12/79] Loss_D: 0.6508 Loss_G: 2.3965 D(x): 0.6672 D(G(z)): 0.1540 / 0.1223\n",
      "[22/25][13/79] Loss_D: 0.6255 Loss_G: 2.7923 D(x): 0.8048 D(G(z)): 0.2947 / 0.0804\n",
      "[22/25][14/79] Loss_D: 0.7273 Loss_G: 2.2259 D(x): 0.6812 D(G(z)): 0.2244 / 0.1515\n",
      "[22/25][15/79] Loss_D: 0.7199 Loss_G: 2.4794 D(x): 0.7611 D(G(z)): 0.3226 / 0.1072\n",
      "[22/25][16/79] Loss_D: 0.6912 Loss_G: 2.0384 D(x): 0.6751 D(G(z)): 0.2121 / 0.1508\n",
      "[22/25][17/79] Loss_D: 0.6995 Loss_G: 3.7546 D(x): 0.8937 D(G(z)): 0.3997 / 0.0314\n",
      "[22/25][18/79] Loss_D: 0.8274 Loss_G: 1.7689 D(x): 0.5290 D(G(z)): 0.0616 / 0.2030\n",
      "[22/25][19/79] Loss_D: 0.6622 Loss_G: 2.5977 D(x): 0.8550 D(G(z)): 0.3511 / 0.1012\n",
      "[22/25][20/79] Loss_D: 0.7970 Loss_G: 2.8621 D(x): 0.7244 D(G(z)): 0.3163 / 0.0761\n",
      "[22/25][21/79] Loss_D: 0.6314 Loss_G: 2.3332 D(x): 0.6969 D(G(z)): 0.1837 / 0.1234\n",
      "[22/25][22/79] Loss_D: 0.5729 Loss_G: 3.3766 D(x): 0.8694 D(G(z)): 0.3161 / 0.0536\n",
      "[22/25][23/79] Loss_D: 0.7132 Loss_G: 2.4899 D(x): 0.6464 D(G(z)): 0.1813 / 0.1094\n",
      "[22/25][24/79] Loss_D: 0.9909 Loss_G: 1.7236 D(x): 0.5719 D(G(z)): 0.2613 / 0.2212\n",
      "[22/25][25/79] Loss_D: 0.6982 Loss_G: 3.6510 D(x): 0.8429 D(G(z)): 0.3635 / 0.0361\n",
      "[22/25][26/79] Loss_D: 0.6317 Loss_G: 2.6091 D(x): 0.6706 D(G(z)): 0.1491 / 0.0983\n",
      "[22/25][27/79] Loss_D: 0.4541 Loss_G: 2.9265 D(x): 0.8587 D(G(z)): 0.2406 / 0.0744\n",
      "[22/25][28/79] Loss_D: 0.5147 Loss_G: 2.5128 D(x): 0.7560 D(G(z)): 0.1748 / 0.1094\n",
      "[22/25][29/79] Loss_D: 0.5899 Loss_G: 3.8184 D(x): 0.9139 D(G(z)): 0.3497 / 0.0349\n",
      "[22/25][30/79] Loss_D: 0.6823 Loss_G: 2.3441 D(x): 0.6085 D(G(z)): 0.1019 / 0.1261\n",
      "[22/25][31/79] Loss_D: 0.6179 Loss_G: 2.3433 D(x): 0.8089 D(G(z)): 0.2726 / 0.1278\n",
      "[22/25][32/79] Loss_D: 0.4060 Loss_G: 3.5255 D(x): 0.9099 D(G(z)): 0.2492 / 0.0412\n",
      "[22/25][33/79] Loss_D: 0.7247 Loss_G: 2.1434 D(x): 0.6485 D(G(z)): 0.1834 / 0.1531\n",
      "[22/25][34/79] Loss_D: 0.6736 Loss_G: 3.6073 D(x): 0.8805 D(G(z)): 0.3774 / 0.0388\n",
      "[22/25][35/79] Loss_D: 0.8357 Loss_G: 2.1158 D(x): 0.5656 D(G(z)): 0.1472 / 0.1602\n",
      "[22/25][36/79] Loss_D: 0.7929 Loss_G: 3.5798 D(x): 0.8435 D(G(z)): 0.4179 / 0.0403\n",
      "[22/25][37/79] Loss_D: 0.9500 Loss_G: 1.8834 D(x): 0.5803 D(G(z)): 0.2289 / 0.2031\n",
      "[22/25][38/79] Loss_D: 0.8194 Loss_G: 2.3391 D(x): 0.7291 D(G(z)): 0.3312 / 0.1226\n",
      "[22/25][39/79] Loss_D: 0.5983 Loss_G: 3.9665 D(x): 0.9014 D(G(z)): 0.3494 / 0.0298\n",
      "[22/25][40/79] Loss_D: 1.2109 Loss_G: 1.6386 D(x): 0.3962 D(G(z)): 0.0650 / 0.2339\n",
      "[22/25][41/79] Loss_D: 0.8685 Loss_G: 3.0202 D(x): 0.8754 D(G(z)): 0.4618 / 0.0721\n",
      "[22/25][42/79] Loss_D: 0.5535 Loss_G: 2.7517 D(x): 0.7296 D(G(z)): 0.1703 / 0.0997\n",
      "[22/25][43/79] Loss_D: 0.5016 Loss_G: 2.2970 D(x): 0.7844 D(G(z)): 0.1904 / 0.1330\n",
      "[22/25][44/79] Loss_D: 0.5448 Loss_G: 3.1607 D(x): 0.8943 D(G(z)): 0.3169 / 0.0560\n",
      "[22/25][45/79] Loss_D: 0.5616 Loss_G: 2.2258 D(x): 0.6863 D(G(z)): 0.1134 / 0.1469\n",
      "[22/25][46/79] Loss_D: 0.5637 Loss_G: 3.2464 D(x): 0.8697 D(G(z)): 0.3079 / 0.0579\n",
      "[22/25][47/79] Loss_D: 0.5800 Loss_G: 2.5840 D(x): 0.7179 D(G(z)): 0.1771 / 0.1009\n",
      "[22/25][48/79] Loss_D: 0.4708 Loss_G: 2.3212 D(x): 0.7643 D(G(z)): 0.1517 / 0.1351\n",
      "[22/25][49/79] Loss_D: 0.6148 Loss_G: 3.7728 D(x): 0.9149 D(G(z)): 0.3766 / 0.0318\n",
      "[22/25][50/79] Loss_D: 0.7824 Loss_G: 2.1649 D(x): 0.5726 D(G(z)): 0.1066 / 0.1588\n",
      "[22/25][51/79] Loss_D: 0.8637 Loss_G: 2.9316 D(x): 0.8033 D(G(z)): 0.4145 / 0.0719\n",
      "[22/25][52/79] Loss_D: 0.4647 Loss_G: 3.2768 D(x): 0.7978 D(G(z)): 0.1772 / 0.0523\n",
      "[22/25][53/79] Loss_D: 0.5286 Loss_G: 2.4309 D(x): 0.7393 D(G(z)): 0.1664 / 0.1257\n",
      "[22/25][54/79] Loss_D: 0.6944 Loss_G: 2.6535 D(x): 0.7576 D(G(z)): 0.2845 / 0.0930\n",
      "[22/25][55/79] Loss_D: 0.5636 Loss_G: 2.6122 D(x): 0.7687 D(G(z)): 0.2170 / 0.1037\n",
      "[22/25][56/79] Loss_D: 0.5849 Loss_G: 2.2767 D(x): 0.7362 D(G(z)): 0.1937 / 0.1229\n",
      "[22/25][57/79] Loss_D: 0.6304 Loss_G: 3.8788 D(x): 0.8978 D(G(z)): 0.3722 / 0.0282\n",
      "[22/25][58/79] Loss_D: 0.6619 Loss_G: 2.3165 D(x): 0.6138 D(G(z)): 0.0951 / 0.1245\n",
      "[22/25][59/79] Loss_D: 0.8380 Loss_G: 2.5566 D(x): 0.7235 D(G(z)): 0.3525 / 0.1013\n",
      "[22/25][60/79] Loss_D: 0.5118 Loss_G: 2.5182 D(x): 0.7450 D(G(z)): 0.1558 / 0.1081\n",
      "[22/25][61/79] Loss_D: 0.7403 Loss_G: 3.0997 D(x): 0.7995 D(G(z)): 0.3523 / 0.0601\n",
      "[22/25][62/79] Loss_D: 0.4779 Loss_G: 2.7256 D(x): 0.7643 D(G(z)): 0.1605 / 0.0825\n",
      "[22/25][63/79] Loss_D: 0.7523 Loss_G: 1.6753 D(x): 0.6549 D(G(z)): 0.2053 / 0.2287\n",
      "[22/25][64/79] Loss_D: 0.8762 Loss_G: 4.1490 D(x): 0.8714 D(G(z)): 0.4790 / 0.0232\n",
      "[22/25][65/79] Loss_D: 0.6831 Loss_G: 2.4565 D(x): 0.6574 D(G(z)): 0.1381 / 0.1121\n",
      "[22/25][66/79] Loss_D: 0.6912 Loss_G: 2.1434 D(x): 0.7241 D(G(z)): 0.2377 / 0.1530\n",
      "[22/25][67/79] Loss_D: 0.5287 Loss_G: 3.5690 D(x): 0.8181 D(G(z)): 0.2320 / 0.0442\n",
      "[22/25][68/79] Loss_D: 0.7463 Loss_G: 2.1912 D(x): 0.6887 D(G(z)): 0.2362 / 0.1492\n",
      "[22/25][69/79] Loss_D: 0.8045 Loss_G: 3.7230 D(x): 0.7856 D(G(z)): 0.3703 / 0.0374\n",
      "[22/25][70/79] Loss_D: 0.7012 Loss_G: 1.9578 D(x): 0.6238 D(G(z)): 0.1338 / 0.1867\n",
      "[22/25][71/79] Loss_D: 0.6996 Loss_G: 3.7124 D(x): 0.8358 D(G(z)): 0.3677 / 0.0325\n",
      "[22/25][72/79] Loss_D: 0.9825 Loss_G: 1.1367 D(x): 0.5035 D(G(z)): 0.1243 / 0.3664\n",
      "[22/25][73/79] Loss_D: 1.0302 Loss_G: 4.8672 D(x): 0.9319 D(G(z)): 0.5700 / 0.0115\n",
      "[22/25][74/79] Loss_D: 0.7742 Loss_G: 1.4501 D(x): 0.5285 D(G(z)): 0.0332 / 0.3056\n",
      "[22/25][75/79] Loss_D: 1.1877 Loss_G: 5.2302 D(x): 0.9103 D(G(z)): 0.5954 / 0.0095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/25][76/79] Loss_D: 1.4021 Loss_G: 1.6657 D(x): 0.3238 D(G(z)): 0.0223 / 0.2531\n",
      "[22/25][77/79] Loss_D: 0.7893 Loss_G: 4.2191 D(x): 0.9374 D(G(z)): 0.4700 / 0.0227\n",
      "[22/25][78/79] Loss_D: 0.4532 Loss_G: 2.3157 D(x): 0.6715 D(G(z)): 0.0302 / 0.1176\n",
      "[23/25][0/79] Loss_D: 0.9218 Loss_G: 4.1948 D(x): 0.9231 D(G(z)): 0.4864 / 0.0265\n",
      "[23/25][1/79] Loss_D: 0.9403 Loss_G: 1.6424 D(x): 0.5235 D(G(z)): 0.0972 / 0.2562\n",
      "[23/25][2/79] Loss_D: 0.9364 Loss_G: 2.9925 D(x): 0.8763 D(G(z)): 0.4558 / 0.0857\n",
      "[23/25][3/79] Loss_D: 0.5282 Loss_G: 3.2571 D(x): 0.7750 D(G(z)): 0.1932 / 0.0582\n",
      "[23/25][4/79] Loss_D: 0.3974 Loss_G: 3.1301 D(x): 0.8296 D(G(z)): 0.1664 / 0.0602\n",
      "[23/25][5/79] Loss_D: 0.9842 Loss_G: 1.3906 D(x): 0.5337 D(G(z)): 0.1718 / 0.2864\n",
      "[23/25][6/79] Loss_D: 1.0125 Loss_G: 4.1777 D(x): 0.8837 D(G(z)): 0.5459 / 0.0221\n",
      "[23/25][7/79] Loss_D: 1.0688 Loss_G: 1.8949 D(x): 0.4646 D(G(z)): 0.1230 / 0.2106\n",
      "[23/25][8/79] Loss_D: 0.7308 Loss_G: 2.3098 D(x): 0.7535 D(G(z)): 0.2828 / 0.1464\n",
      "[23/25][9/79] Loss_D: 0.5942 Loss_G: 4.1162 D(x): 0.8981 D(G(z)): 0.3260 / 0.0298\n",
      "[23/25][10/79] Loss_D: 0.7735 Loss_G: 1.8726 D(x): 0.5691 D(G(z)): 0.1008 / 0.1973\n",
      "[23/25][11/79] Loss_D: 0.7077 Loss_G: 2.4084 D(x): 0.7945 D(G(z)): 0.3215 / 0.1313\n",
      "[23/25][12/79] Loss_D: 0.6390 Loss_G: 3.2706 D(x): 0.8168 D(G(z)): 0.2959 / 0.0541\n",
      "[23/25][13/79] Loss_D: 0.7764 Loss_G: 1.7110 D(x): 0.5782 D(G(z)): 0.0910 / 0.2500\n",
      "[23/25][14/79] Loss_D: 0.8067 Loss_G: 3.1763 D(x): 0.9111 D(G(z)): 0.4678 / 0.0561\n",
      "[23/25][15/79] Loss_D: 0.5351 Loss_G: 2.5502 D(x): 0.7109 D(G(z)): 0.1346 / 0.1095\n",
      "[23/25][16/79] Loss_D: 0.6066 Loss_G: 1.9466 D(x): 0.7336 D(G(z)): 0.2071 / 0.1929\n",
      "[23/25][17/79] Loss_D: 0.7256 Loss_G: 3.4098 D(x): 0.8676 D(G(z)): 0.3905 / 0.0463\n",
      "[23/25][18/79] Loss_D: 0.9310 Loss_G: 1.3514 D(x): 0.5198 D(G(z)): 0.1379 / 0.3152\n",
      "[23/25][19/79] Loss_D: 0.6392 Loss_G: 3.1118 D(x): 0.9156 D(G(z)): 0.3827 / 0.0626\n",
      "[23/25][20/79] Loss_D: 0.5103 Loss_G: 2.9280 D(x): 0.7774 D(G(z)): 0.1947 / 0.0716\n",
      "[23/25][21/79] Loss_D: 0.7184 Loss_G: 2.2679 D(x): 0.7074 D(G(z)): 0.2596 / 0.1426\n",
      "[23/25][22/79] Loss_D: 0.7606 Loss_G: 2.2442 D(x): 0.6942 D(G(z)): 0.2646 / 0.1423\n",
      "[23/25][23/79] Loss_D: 0.4676 Loss_G: 2.6986 D(x): 0.8248 D(G(z)): 0.2158 / 0.0886\n",
      "[23/25][24/79] Loss_D: 0.5407 Loss_G: 3.3436 D(x): 0.8332 D(G(z)): 0.2610 / 0.0552\n",
      "[23/25][25/79] Loss_D: 0.8355 Loss_G: 1.3888 D(x): 0.5904 D(G(z)): 0.1848 / 0.2897\n",
      "[23/25][26/79] Loss_D: 0.7472 Loss_G: 3.0485 D(x): 0.8131 D(G(z)): 0.3590 / 0.0717\n",
      "[23/25][27/79] Loss_D: 0.4580 Loss_G: 3.9037 D(x): 0.8465 D(G(z)): 0.2138 / 0.0364\n",
      "[23/25][28/79] Loss_D: 0.6056 Loss_G: 2.0385 D(x): 0.6549 D(G(z)): 0.0694 / 0.1857\n",
      "[23/25][29/79] Loss_D: 0.8871 Loss_G: 3.2804 D(x): 0.8366 D(G(z)): 0.4423 / 0.0567\n",
      "[23/25][30/79] Loss_D: 0.7050 Loss_G: 2.1971 D(x): 0.6389 D(G(z)): 0.1556 / 0.1480\n",
      "[23/25][31/79] Loss_D: 0.7189 Loss_G: 3.7355 D(x): 0.8605 D(G(z)): 0.3815 / 0.0328\n",
      "[23/25][32/79] Loss_D: 0.6178 Loss_G: 2.2922 D(x): 0.6484 D(G(z)): 0.1105 / 0.1264\n",
      "[23/25][33/79] Loss_D: 0.5071 Loss_G: 2.1612 D(x): 0.7649 D(G(z)): 0.1772 / 0.1563\n",
      "[23/25][34/79] Loss_D: 0.6842 Loss_G: 3.3654 D(x): 0.8587 D(G(z)): 0.3737 / 0.0478\n",
      "[23/25][35/79] Loss_D: 0.8497 Loss_G: 2.2770 D(x): 0.6127 D(G(z)): 0.2251 / 0.1381\n",
      "[23/25][36/79] Loss_D: 0.6703 Loss_G: 1.8181 D(x): 0.7078 D(G(z)): 0.2083 / 0.2031\n",
      "[23/25][37/79] Loss_D: 0.6419 Loss_G: 4.0238 D(x): 0.9273 D(G(z)): 0.4037 / 0.0226\n",
      "[23/25][38/79] Loss_D: 1.0044 Loss_G: 1.3671 D(x): 0.4612 D(G(z)): 0.0619 / 0.2944\n",
      "[23/25][39/79] Loss_D: 0.9481 Loss_G: 4.5339 D(x): 0.9293 D(G(z)): 0.5411 / 0.0143\n",
      "[23/25][40/79] Loss_D: 1.3578 Loss_G: 1.4907 D(x): 0.3291 D(G(z)): 0.0296 / 0.2812\n",
      "[23/25][41/79] Loss_D: 0.8365 Loss_G: 3.3602 D(x): 0.8830 D(G(z)): 0.4700 / 0.0430\n",
      "[23/25][42/79] Loss_D: 0.4845 Loss_G: 2.8379 D(x): 0.7474 D(G(z)): 0.1488 / 0.0787\n",
      "[23/25][43/79] Loss_D: 0.8501 Loss_G: 1.0246 D(x): 0.5697 D(G(z)): 0.1881 / 0.4038\n",
      "[23/25][44/79] Loss_D: 1.1997 Loss_G: 4.8954 D(x): 0.9162 D(G(z)): 0.6126 / 0.0123\n",
      "[23/25][45/79] Loss_D: 0.8964 Loss_G: 2.4282 D(x): 0.5052 D(G(z)): 0.0600 / 0.1275\n",
      "[23/25][46/79] Loss_D: 0.4463 Loss_G: 2.4292 D(x): 0.8607 D(G(z)): 0.2322 / 0.1222\n",
      "[23/25][47/79] Loss_D: 0.4798 Loss_G: 3.4035 D(x): 0.8694 D(G(z)): 0.2669 / 0.0436\n",
      "[23/25][48/79] Loss_D: 0.5808 Loss_G: 2.2684 D(x): 0.7192 D(G(z)): 0.1914 / 0.1268\n",
      "[23/25][49/79] Loss_D: 1.0000 Loss_G: 1.5601 D(x): 0.6211 D(G(z)): 0.3507 / 0.2385\n",
      "[23/25][50/79] Loss_D: 0.9656 Loss_G: 3.2565 D(x): 0.7924 D(G(z)): 0.4791 / 0.0504\n",
      "[23/25][51/79] Loss_D: 0.6183 Loss_G: 2.0052 D(x): 0.6172 D(G(z)): 0.0841 / 0.1709\n",
      "[23/25][52/79] Loss_D: 0.7161 Loss_G: 2.7182 D(x): 0.8472 D(G(z)): 0.3696 / 0.1033\n",
      "[23/25][53/79] Loss_D: 0.4965 Loss_G: 3.0855 D(x): 0.7970 D(G(z)): 0.2057 / 0.0669\n",
      "[23/25][54/79] Loss_D: 0.3487 Loss_G: 2.8771 D(x): 0.8514 D(G(z)): 0.1529 / 0.0739\n",
      "[23/25][55/79] Loss_D: 0.7628 Loss_G: 1.6403 D(x): 0.6536 D(G(z)): 0.2378 / 0.2293\n",
      "[23/25][56/79] Loss_D: 0.6862 Loss_G: 2.6890 D(x): 0.8110 D(G(z)): 0.3374 / 0.0909\n",
      "[23/25][57/79] Loss_D: 0.7708 Loss_G: 2.2421 D(x): 0.6749 D(G(z)): 0.2520 / 0.1384\n",
      "[23/25][58/79] Loss_D: 0.7502 Loss_G: 2.5838 D(x): 0.7500 D(G(z)): 0.3246 / 0.0935\n",
      "[23/25][59/79] Loss_D: 0.7828 Loss_G: 1.7343 D(x): 0.6224 D(G(z)): 0.2052 / 0.2028\n",
      "[23/25][60/79] Loss_D: 0.8641 Loss_G: 3.3827 D(x): 0.8009 D(G(z)): 0.4326 / 0.0451\n",
      "[23/25][61/79] Loss_D: 0.8636 Loss_G: 1.4754 D(x): 0.5421 D(G(z)): 0.1317 / 0.2779\n",
      "[23/25][62/79] Loss_D: 0.5349 Loss_G: 3.3076 D(x): 0.9100 D(G(z)): 0.3312 / 0.0458\n",
      "[23/25][63/79] Loss_D: 0.3437 Loss_G: 3.1842 D(x): 0.8192 D(G(z)): 0.1222 / 0.0552\n",
      "[23/25][64/79] Loss_D: 0.4475 Loss_G: 1.8683 D(x): 0.7444 D(G(z)): 0.1088 / 0.1948\n",
      "[23/25][65/79] Loss_D: 0.6677 Loss_G: 3.6066 D(x): 0.8824 D(G(z)): 0.3841 / 0.0378\n",
      "[23/25][66/79] Loss_D: 0.7520 Loss_G: 1.8205 D(x): 0.5550 D(G(z)): 0.0667 / 0.1916\n",
      "[23/25][67/79] Loss_D: 0.6292 Loss_G: 3.0299 D(x): 0.9001 D(G(z)): 0.3715 / 0.0661\n",
      "[23/25][68/79] Loss_D: 0.5057 Loss_G: 2.6348 D(x): 0.7502 D(G(z)): 0.1633 / 0.0989\n",
      "[23/25][69/79] Loss_D: 0.5529 Loss_G: 2.6727 D(x): 0.7900 D(G(z)): 0.2458 / 0.0890\n",
      "[23/25][70/79] Loss_D: 0.7219 Loss_G: 2.2680 D(x): 0.7125 D(G(z)): 0.2685 / 0.1396\n",
      "[23/25][71/79] Loss_D: 0.6469 Loss_G: 2.5644 D(x): 0.7470 D(G(z)): 0.2500 / 0.1042\n",
      "[23/25][72/79] Loss_D: 0.6470 Loss_G: 2.2740 D(x): 0.7342 D(G(z)): 0.2282 / 0.1376\n",
      "[23/25][73/79] Loss_D: 0.6473 Loss_G: 3.5626 D(x): 0.8261 D(G(z)): 0.3292 / 0.0406\n",
      "[23/25][74/79] Loss_D: 0.7820 Loss_G: 1.4731 D(x): 0.5663 D(G(z)): 0.1248 / 0.2746\n",
      "[23/25][75/79] Loss_D: 0.4837 Loss_G: 3.5030 D(x): 0.9249 D(G(z)): 0.3059 / 0.0389\n",
      "[23/25][76/79] Loss_D: 0.4194 Loss_G: 2.9881 D(x): 0.7896 D(G(z)): 0.1400 / 0.0665\n",
      "[23/25][77/79] Loss_D: 0.5372 Loss_G: 1.4005 D(x): 0.7127 D(G(z)): 0.1376 / 0.2942\n",
      "[23/25][78/79] Loss_D: 0.6661 Loss_G: 5.9363 D(x): 0.9211 D(G(z)): 0.4168 / 0.0041\n",
      "[24/25][0/79] Loss_D: 0.8937 Loss_G: 1.0653 D(x): 0.5316 D(G(z)): 0.1026 / 0.4091\n",
      "[24/25][1/79] Loss_D: 1.0582 Loss_G: 4.9642 D(x): 0.9265 D(G(z)): 0.5730 / 0.0117\n",
      "[24/25][2/79] Loss_D: 0.8592 Loss_G: 1.4634 D(x): 0.4828 D(G(z)): 0.0321 / 0.2951\n",
      "[24/25][3/79] Loss_D: 0.8079 Loss_G: 3.1449 D(x): 0.8605 D(G(z)): 0.4245 / 0.0602\n",
      "[24/25][4/79] Loss_D: 0.7168 Loss_G: 2.3403 D(x): 0.6577 D(G(z)): 0.1792 / 0.1234\n",
      "[24/25][5/79] Loss_D: 0.7778 Loss_G: 1.8073 D(x): 0.6638 D(G(z)): 0.2393 / 0.2017\n",
      "[24/25][6/79] Loss_D: 0.8416 Loss_G: 3.4540 D(x): 0.8114 D(G(z)): 0.4104 / 0.0394\n",
      "[24/25][7/79] Loss_D: 0.7905 Loss_G: 2.0276 D(x): 0.6176 D(G(z)): 0.1835 / 0.1657\n",
      "[24/25][8/79] Loss_D: 0.9438 Loss_G: 2.0241 D(x): 0.6577 D(G(z)): 0.3171 / 0.1670\n",
      "[24/25][9/79] Loss_D: 0.7079 Loss_G: 3.1294 D(x): 0.7695 D(G(z)): 0.3209 / 0.0576\n",
      "[24/25][10/79] Loss_D: 0.8546 Loss_G: 1.7451 D(x): 0.5936 D(G(z)): 0.1980 / 0.2148\n",
      "[24/25][11/79] Loss_D: 0.6728 Loss_G: 4.5613 D(x): 0.9455 D(G(z)): 0.4224 / 0.0151\n",
      "[24/25][12/79] Loss_D: 0.8356 Loss_G: 2.2163 D(x): 0.5492 D(G(z)): 0.1324 / 0.1415\n",
      "[24/25][13/79] Loss_D: 0.8156 Loss_G: 1.1359 D(x): 0.6228 D(G(z)): 0.2157 / 0.3593\n",
      "[24/25][14/79] Loss_D: 1.1460 Loss_G: 4.5935 D(x): 0.9269 D(G(z)): 0.5919 / 0.0166\n",
      "[24/25][15/79] Loss_D: 0.7518 Loss_G: 2.5823 D(x): 0.5495 D(G(z)): 0.0343 / 0.1091\n",
      "[24/25][16/79] Loss_D: 0.5242 Loss_G: 1.9929 D(x): 0.8160 D(G(z)): 0.2333 / 0.1836\n",
      "[24/25][17/79] Loss_D: 0.8117 Loss_G: 3.6409 D(x): 0.8783 D(G(z)): 0.4427 / 0.0418\n",
      "[24/25][18/79] Loss_D: 0.8155 Loss_G: 2.0110 D(x): 0.5333 D(G(z)): 0.0764 / 0.1731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/25][19/79] Loss_D: 0.8865 Loss_G: 3.0315 D(x): 0.8901 D(G(z)): 0.4414 / 0.0711\n",
      "[24/25][20/79] Loss_D: 0.8164 Loss_G: 1.7633 D(x): 0.5761 D(G(z)): 0.1437 / 0.2205\n",
      "[24/25][21/79] Loss_D: 0.8900 Loss_G: 2.5906 D(x): 0.8018 D(G(z)): 0.4425 / 0.0899\n",
      "[24/25][22/79] Loss_D: 1.0159 Loss_G: 2.5346 D(x): 0.6385 D(G(z)): 0.3451 / 0.0989\n",
      "[24/25][23/79] Loss_D: 1.1413 Loss_G: 1.2475 D(x): 0.4789 D(G(z)): 0.1835 / 0.3581\n",
      "[24/25][24/79] Loss_D: 1.0217 Loss_G: 3.8056 D(x): 0.8749 D(G(z)): 0.5022 / 0.0305\n",
      "[24/25][25/79] Loss_D: 0.6005 Loss_G: 2.4334 D(x): 0.6614 D(G(z)): 0.1061 / 0.1256\n",
      "[24/25][26/79] Loss_D: 0.5442 Loss_G: 3.2216 D(x): 0.8477 D(G(z)): 0.2691 / 0.0566\n",
      "[24/25][27/79] Loss_D: 0.8271 Loss_G: 1.2739 D(x): 0.5987 D(G(z)): 0.1882 / 0.3144\n",
      "[24/25][28/79] Loss_D: 0.8584 Loss_G: 4.4426 D(x): 0.9256 D(G(z)): 0.4989 / 0.0168\n",
      "[24/25][29/79] Loss_D: 0.8754 Loss_G: 1.1367 D(x): 0.5018 D(G(z)): 0.0689 / 0.3572\n",
      "[24/25][30/79] Loss_D: 0.9969 Loss_G: 4.7466 D(x): 0.8426 D(G(z)): 0.5077 / 0.0126\n",
      "[24/25][31/79] Loss_D: 0.7865 Loss_G: 1.9590 D(x): 0.5224 D(G(z)): 0.0400 / 0.1942\n",
      "[24/25][32/79] Loss_D: 0.6576 Loss_G: 2.5746 D(x): 0.8616 D(G(z)): 0.3405 / 0.1062\n",
      "[24/25][33/79] Loss_D: 0.6227 Loss_G: 4.2449 D(x): 0.8846 D(G(z)): 0.3566 / 0.0201\n",
      "[24/25][34/79] Loss_D: 0.9911 Loss_G: 1.8023 D(x): 0.4499 D(G(z)): 0.0566 / 0.2170\n",
      "[24/25][35/79] Loss_D: 0.7528 Loss_G: 3.4212 D(x): 0.8611 D(G(z)): 0.3982 / 0.0437\n",
      "[24/25][36/79] Loss_D: 0.4551 Loss_G: 2.6518 D(x): 0.7403 D(G(z)): 0.1078 / 0.0944\n",
      "[24/25][37/79] Loss_D: 0.5477 Loss_G: 3.1275 D(x): 0.8729 D(G(z)): 0.3034 / 0.0606\n",
      "[24/25][38/79] Loss_D: 0.4458 Loss_G: 2.8740 D(x): 0.7587 D(G(z)): 0.1158 / 0.0719\n",
      "[24/25][39/79] Loss_D: 0.3586 Loss_G: 3.2065 D(x): 0.8987 D(G(z)): 0.2039 / 0.0537\n",
      "[24/25][40/79] Loss_D: 0.5053 Loss_G: 2.4370 D(x): 0.7483 D(G(z)): 0.1617 / 0.1183\n",
      "[24/25][41/79] Loss_D: 0.4620 Loss_G: 3.1222 D(x): 0.8838 D(G(z)): 0.2605 / 0.0595\n",
      "[24/25][42/79] Loss_D: 0.7223 Loss_G: 1.8582 D(x): 0.6334 D(G(z)): 0.1742 / 0.1903\n",
      "[24/25][43/79] Loss_D: 0.8481 Loss_G: 3.8505 D(x): 0.8538 D(G(z)): 0.4427 / 0.0307\n",
      "[24/25][44/79] Loss_D: 0.5523 Loss_G: 2.6574 D(x): 0.6752 D(G(z)): 0.0908 / 0.1002\n",
      "[24/25][45/79] Loss_D: 0.8223 Loss_G: 1.9837 D(x): 0.6844 D(G(z)): 0.2937 / 0.1781\n",
      "[24/25][46/79] Loss_D: 0.6004 Loss_G: 3.2375 D(x): 0.8278 D(G(z)): 0.3020 / 0.0516\n",
      "[24/25][47/79] Loss_D: 0.6618 Loss_G: 2.4360 D(x): 0.6869 D(G(z)): 0.1895 / 0.1220\n",
      "[24/25][48/79] Loss_D: 0.5290 Loss_G: 2.6135 D(x): 0.7949 D(G(z)): 0.2268 / 0.0968\n",
      "[24/25][49/79] Loss_D: 0.6104 Loss_G: 3.0390 D(x): 0.8027 D(G(z)): 0.2871 / 0.0663\n",
      "[24/25][50/79] Loss_D: 0.4969 Loss_G: 3.0748 D(x): 0.8105 D(G(z)): 0.2132 / 0.0618\n",
      "[24/25][51/79] Loss_D: 0.8545 Loss_G: 1.7277 D(x): 0.6331 D(G(z)): 0.2531 / 0.2260\n",
      "[24/25][52/79] Loss_D: 0.6449 Loss_G: 3.5044 D(x): 0.8774 D(G(z)): 0.3462 / 0.0448\n",
      "[24/25][53/79] Loss_D: 1.1744 Loss_G: 1.0427 D(x): 0.4388 D(G(z)): 0.1569 / 0.4023\n",
      "[24/25][54/79] Loss_D: 1.1613 Loss_G: 3.4805 D(x): 0.8208 D(G(z)): 0.5606 / 0.0458\n",
      "[24/25][55/79] Loss_D: 0.5415 Loss_G: 2.8338 D(x): 0.6973 D(G(z)): 0.1237 / 0.0787\n",
      "[24/25][56/79] Loss_D: 0.5876 Loss_G: 1.7413 D(x): 0.7229 D(G(z)): 0.1778 / 0.2154\n",
      "[24/25][57/79] Loss_D: 0.6008 Loss_G: 3.7611 D(x): 0.9324 D(G(z)): 0.3807 / 0.0318\n",
      "[24/25][58/79] Loss_D: 0.9380 Loss_G: 1.4257 D(x): 0.5019 D(G(z)): 0.1000 / 0.2785\n",
      "[24/25][59/79] Loss_D: 0.7535 Loss_G: 3.7030 D(x): 0.8945 D(G(z)): 0.4443 / 0.0345\n",
      "[24/25][60/79] Loss_D: 1.1254 Loss_G: 1.3840 D(x): 0.4493 D(G(z)): 0.1038 / 0.3439\n",
      "[24/25][61/79] Loss_D: 1.0456 Loss_G: 3.9302 D(x): 0.9224 D(G(z)): 0.5680 / 0.0278\n",
      "[24/25][62/79] Loss_D: 0.6507 Loss_G: 2.4162 D(x): 0.6176 D(G(z)): 0.0754 / 0.1246\n",
      "[24/25][63/79] Loss_D: 0.5955 Loss_G: 3.2505 D(x): 0.8919 D(G(z)): 0.3353 / 0.0557\n",
      "[24/25][64/79] Loss_D: 0.4294 Loss_G: 3.1307 D(x): 0.8219 D(G(z)): 0.1767 / 0.0609\n",
      "[24/25][65/79] Loss_D: 0.9306 Loss_G: 1.0232 D(x): 0.5151 D(G(z)): 0.1443 / 0.4199\n",
      "[24/25][66/79] Loss_D: 1.4787 Loss_G: 3.9217 D(x): 0.8797 D(G(z)): 0.6822 / 0.0250\n",
      "[24/25][67/79] Loss_D: 0.7328 Loss_G: 2.4862 D(x): 0.5687 D(G(z)): 0.0544 / 0.1049\n",
      "[24/25][68/79] Loss_D: 0.4485 Loss_G: 1.7121 D(x): 0.7973 D(G(z)): 0.1733 / 0.2223\n",
      "[24/25][69/79] Loss_D: 1.0109 Loss_G: 4.4497 D(x): 0.8914 D(G(z)): 0.5236 / 0.0164\n",
      "[24/25][70/79] Loss_D: 1.1226 Loss_G: 1.2368 D(x): 0.4074 D(G(z)): 0.0470 / 0.3378\n",
      "[24/25][71/79] Loss_D: 1.0039 Loss_G: 3.3545 D(x): 0.8890 D(G(z)): 0.5315 / 0.0473\n",
      "[24/25][72/79] Loss_D: 0.8863 Loss_G: 1.3170 D(x): 0.5377 D(G(z)): 0.1480 / 0.3114\n",
      "[24/25][73/79] Loss_D: 1.1992 Loss_G: 2.3533 D(x): 0.6432 D(G(z)): 0.4633 / 0.1188\n",
      "[24/25][74/79] Loss_D: 0.5958 Loss_G: 3.3386 D(x): 0.8047 D(G(z)): 0.2704 / 0.0472\n",
      "[24/25][75/79] Loss_D: 0.7275 Loss_G: 1.7339 D(x): 0.5995 D(G(z)): 0.1313 / 0.2249\n",
      "[24/25][76/79] Loss_D: 0.5892 Loss_G: 2.4879 D(x): 0.8156 D(G(z)): 0.2893 / 0.1037\n",
      "[24/25][77/79] Loss_D: 0.4457 Loss_G: 3.5595 D(x): 0.8778 D(G(z)): 0.2521 / 0.0367\n",
      "[24/25][78/79] Loss_D: 1.3182 Loss_G: 0.4392 D(x): 0.3543 D(G(z)): 0.0900 / 0.6760\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(niter):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################                                                                                                                                                                                                              \n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))                                                                                                                                                                             \n",
    "        ###########################                                                                                                                                                                                                               \n",
    "        # train with real                                                                                                                                                                                                                         \n",
    "        netD.zero_grad()\n",
    "        real_cpu, _ = data\n",
    "        batch_size = real_cpu.size(0)\n",
    "        if torch.cuda.is_available():\n",
    "            real_cpu = real_cpu.cuda()\n",
    "        input.resize_as_(real_cpu).copy_(real_cpu)\n",
    "        label.resize_(batch_size).fill_(real_label)\n",
    "        inputv = Variable(input)\n",
    "        labelv = Variable(label)\n",
    "\n",
    "        output = netD(inputv)\n",
    "        errD_real = criterion(output, labelv)\n",
    "        errD_real.backward()\n",
    "        D_x = output.data.mean()\n",
    "\n",
    "        # train with fake                                                                                                                                                                                                                         \n",
    "        noise.resize_(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "        noisev = Variable(noise)\n",
    "        fake = netG(noisev)\n",
    "        labelv = Variable(label.fill_(fake_label))\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, labelv)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.data.mean()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################                                                                                                                                                                                                              \n",
    "        # (2) Update G network: maximize log(D(G(z)))                                                                                                                                                                                             \n",
    "        ###########################                                                                                                                                                                                                               \n",
    "        netG.zero_grad()\n",
    "        labelv = Variable(label.fill_(real_label))  # fake labels are real for generator cost                                                                                                                                                     \n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, labelv)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.data.mean()\n",
    "        optimizerG.step()\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, niter, i, len(dataloader),\n",
    "                 errD.data[0], errG.data[0], D_x, D_G_z1, D_G_z2))\n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(real_cpu,\n",
    "                    '%s/real_samples.png' % outf,\n",
    "                    normalize=True)\n",
    "            fake = netG(fixed_noise)\n",
    "            vutils.save_image(fake.data,\n",
    "                    '%s/fake_samples_epoch_%03d.png' % (outf, epoch),\n",
    "                    normalize=True)\n",
    "\n",
    "    # do checkpointing                                                                                                                                                                                                                            \n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outf, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real image score: [ 0.35653681]\n"
     ]
    }
   ],
   "source": [
    "# run discriminator against image (real label = 1, fake label = 0)\n",
    "# - test against real image first\n",
    "test_input = Variable(test_sample[0])\n",
    "if torch.cuda.is_available():\n",
    "    test_input = test_input.cuda()\n",
    "test_output = netD(test_input)\n",
    "print('Real image score: ' + str(test_output.cpu().data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake image score: [ 0.35356945]\n",
      "Fake image score: [ 0.42508337]\n",
      "Fake image score: [ 0.75277853]\n",
      "Fake image score: [ 0.72136933]\n",
      "Fake image score: [ 0.81679088]\n",
      "Fake image score: [ 0.18896869]\n",
      "Fake image score: [ 0.06997858]\n",
      "Fake image score: [ 0.12582691]\n",
      "Fake image score: [ 0.63120371]\n",
      "Fake image score: [ 0.46244285]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Integer subplot specification must be a three digit number.  Not 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5b05ab15105d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtest_fake_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_fake_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fake image score: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_fake_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUnnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_fake_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msubplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m     \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0mbyebye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m                 raise ValueError(\"Integer subplot specification must \" +\n\u001b[1;32m    988\u001b[0m                                  \u001b[0;34m\"be a three digit number.  \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m                                  \"Not {n:d}\".format(n=len(args)))\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSubplotBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Integer subplot specification must be a three digit number.  Not 4"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADoAAAA3CAYAAABdJVn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f625cac8da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# - test against fake images\n",
    "plt.figure()\n",
    "for i in range(1,11):\n",
    "    test_noise = torch.FloatTensor(1, nz, 1, 1).normal_(0,1)\n",
    "    test_noisev = Variable(test_noise)\n",
    "    if torch.cuda.is_available():\n",
    "        test_noisev = test_noisev.cuda()\n",
    "    test_fake_input = netG(test_noisev)\n",
    "    test_fake_output = netD(test_fake_input)\n",
    "    print('Fake image score: ' + str(test_fake_output.cpu().data.numpy()))\n",
    "    plt.subplot(i*100+55)\n",
    "    plt.imshow(Unnormalize(test_fake_input.cpu().data.numpy()[0].transpose(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.3689\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fixed_noise_input = netG(fixed_noise[0].unsqueeze(0))\n",
    "fixed_noise_output = netD(fixed_noise_input)\n",
    "print(fixed_noise_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f625cbdc048>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f625fd7ada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Unnormalize(fixed_noise_input.cpu().data.numpy()[0].transpose(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
